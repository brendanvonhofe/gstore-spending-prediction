{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch.nn.functional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim\n",
    "import numpy.random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas\n",
    "import copy\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, cat_cols, cont_cols, embeds):\n",
    "        super(Net, self).__init__()\n",
    "        self.cat_cols = cat_cols\n",
    "        self.cont_cols = cont_cols\n",
    "        self.embed = embeds\n",
    "        \n",
    "        #Embed the categoricals\n",
    "        self.embedLayer = torch.nn.ModuleList([torch.nn.Embedding(i, 100) for i in self.embed])\n",
    "        \n",
    "        #normalize the numericals\n",
    "        self.bn_layer = torch.nn.BatchNorm1d(len(self.cont_cols))\n",
    "        \n",
    "        # Linear Layers\n",
    "        self.fc1 = torch.nn.Linear(len(self.embed) * 100 + len(cont_cols), 50)\n",
    "        self.fc2 = torch.nn.Linear(50, 1)\n",
    "    def forward(self, x):\n",
    "        # Embedding Layer\n",
    "        cat_encoded = [embedLayer(x[:, i+4].long()) for i, embedLayer in enumerate(self.embedLayer)]\n",
    "        cat_encoded = torch.cat(cat_encoded, 1)\n",
    "        cont_normalized = self.bn_layer(x[:, :4])\n",
    "        x = torch.cat([cat_encoded, cont_normalized], 1)\n",
    "        \n",
    "        # Linear Layers\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.df.iloc[idx, :]\n",
    "        x = item[['visitNumber', 'visitStartTime', 'hits', 'pageviews', 'newVisits', 'bounces', \n",
    "                  'channelGrouping', 'browser', 'operatingSystem', 'isMobile', 'deviceCategory', 'continent', \n",
    "                  'subContinent', 'country', 'region', 'city', 'networkDomain']].values.astype(np.float32)\n",
    "        y = item[['transactionRevenue']].values.astype(np.float32)\n",
    "        return {'x': torch.from_numpy(x), 'y': torch.from_numpy(y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bread/anaconda3/envs/pytorch/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedLayer): ModuleList(\n",
      "    (0): Embedding(2, 100)\n",
      "    (1): Embedding(2, 100)\n",
      "    (2): Embedding(8, 100)\n",
      "    (3): Embedding(54, 100)\n",
      "    (4): Embedding(20, 100)\n",
      "    (5): Embedding(2, 100)\n",
      "    (6): Embedding(3, 100)\n",
      "    (7): Embedding(6, 100)\n",
      "    (8): Embedding(23, 100)\n",
      "    (9): Embedding(222, 100)\n",
      "    (10): Embedding(376, 100)\n",
      "    (11): Embedding(649, 100)\n",
      "    (12): Embedding(28064, 100)\n",
      "  )\n",
      "  (bn_layer): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=1304, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = pandas.read_csv(\"train_df.csv\")\n",
    "\n",
    "tr = {'mean': 0.22711817076655114, 'std': 2.0037093202285647} \n",
    "\n",
    "cont_cols = ['visitNumber', 'visitStartTime', 'hits', 'pageviews']\n",
    "cat_cols = ['newVisits', 'bounces', 'channelGrouping', 'browser', 'operatingSystem', 'isMobile', \n",
    "       'deviceCategory', 'continent', 'subContinent', 'country', 'region', 'city', 'networkDomain']\n",
    "\n",
    "#label encode the categorical variables\n",
    "label_encoders = {}\n",
    "for cat_col in cat_cols:\n",
    "    label_encoders[cat_col] = LabelEncoder()\n",
    "    data[cat_col] = label_encoders[cat_col].fit_transform(data[cat_col])\n",
    "\n",
    "#create testing and training set\n",
    "msk = numpy.random.rand(len(data)) < 0.8\n",
    "training_data = data[msk]\n",
    "testing_data = data[~msk]\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "train_ds = GDataset(training_data)\n",
    "test_ds = GDataset(testing_data)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "dataloaders = {'train': train_dl, 'val': test_dl}\n",
    "dataset_sizes = {'train': len(training_data), 'val': len(testing_data)}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embeddings = [data[col].nunique() for col in cat_cols]\n",
    "num_epochs=5\n",
    "\n",
    "outputId = \"fullVisitorId\"\n",
    "output = \"transactionRevenue\"\n",
    "net = Net(cat_cols, cont_cols, embeddings)\n",
    "model = net.to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "Loss at step 0: 0.0008147250046022236\n",
      "Loss at step 1: 0.0008255068678408861\n",
      "Loss at step 2: 0.0011360312346369028\n",
      "Loss at step 3: 0.0010994693730026484\n",
      "Loss at step 4: 0.0008290652185678482\n",
      "Loss at step 5: 0.0009450821671634912\n",
      "Loss at step 6: 0.0007418543100357056\n",
      "Loss at step 7: 0.0010385385248810053\n",
      "Loss at step 8: 0.0010465615196153522\n",
      "Loss at step 9: 0.0010449700057506561\n",
      "Loss at step 10: 0.0010517798364162445\n",
      "Loss at step 11: 0.0009664817480370402\n",
      "Loss at step 12: 0.001222106977365911\n",
      "Loss at step 13: 0.0010391859104856849\n",
      "Loss at step 14: 0.0010192332556471229\n",
      "Loss at step 15: 0.0011897293152287602\n",
      "Loss at step 16: 0.0009945209603756666\n",
      "Loss at step 17: 0.0007809235830791295\n",
      "Loss at step 18: 0.0008547096513211727\n",
      "Loss at step 19: 0.000863875902723521\n",
      "Loss at step 20: 0.0008993305964395404\n",
      "Loss at step 21: 0.0010832517873495817\n",
      "Loss at step 22: 0.000928671914152801\n",
      "Loss at step 23: 0.0007846430526115\n",
      "Loss at step 24: 0.0011296826414763927\n",
      "Loss at step 25: 0.0010614204220473766\n",
      "Loss at step 26: 0.0010780347511172295\n",
      "Loss at step 27: 0.0007724068127572536\n",
      "Loss at step 28: 0.0010332796955481172\n",
      "Loss at step 29: 0.0009489128715358675\n",
      "Loss at step 30: 0.001066317898221314\n",
      "Loss at step 31: 0.0006106852670200169\n",
      "Loss at step 32: 0.0009135299478657544\n",
      "Loss at step 33: 0.0010870295809581876\n",
      "Loss at step 34: 0.0006842843722552061\n",
      "Loss at step 35: 0.0008152375812642276\n",
      "Loss at step 36: 0.001139820902608335\n",
      "Loss at step 37: 0.0009662897791713476\n",
      "Loss at step 38: 0.0010235493537038565\n",
      "Loss at step 39: 0.0009086435311473906\n",
      "Loss at step 40: 0.0008431588066741824\n",
      "Loss at step 41: 0.0009114150889217854\n",
      "Loss at step 42: 0.0008867172291502357\n",
      "Loss at step 43: 0.00113031012006104\n",
      "Loss at step 44: 0.0009059617295861244\n",
      "Loss at step 45: 0.0008792689768597484\n",
      "Loss at step 46: 0.000740820134524256\n",
      "Loss at step 47: 0.0010264579905197024\n",
      "Loss at step 48: 0.001065072021447122\n",
      "Loss at step 49: 0.0011889776214957237\n",
      "Loss at step 50: 0.0009310210589319468\n",
      "Loss at step 51: 0.0011320014018565416\n",
      "Loss at step 52: 0.0008177989511750638\n",
      "Loss at step 53: 0.0009336548391729593\n",
      "Loss at step 54: 0.0008650277741253376\n",
      "Loss at step 55: 0.0008508142782375216\n",
      "Loss at step 56: 0.0007332491804845631\n",
      "Loss at step 57: 0.0009642572258599102\n",
      "Loss at step 58: 0.0007294684182852507\n",
      "Loss at step 59: 0.0010144098196178675\n",
      "Loss at step 60: 0.0012220201315358281\n",
      "Loss at step 61: 0.0009712745668366551\n",
      "Loss at step 62: 0.0010174335911870003\n",
      "Loss at step 63: 0.0008620937587693334\n",
      "Loss at step 64: 0.0007100970833562315\n",
      "Loss at step 65: 0.0007816294673830271\n",
      "Loss at step 66: 0.0008381621446460485\n",
      "Loss at step 67: 0.0010062691289931536\n",
      "Loss at step 68: 0.0010838477173820138\n",
      "Loss at step 69: 0.0010359779698774219\n",
      "Loss at step 70: 0.0010134406620636582\n",
      "Loss at step 71: 0.0008641795138828456\n",
      "Loss at step 72: 0.0009673546301200986\n",
      "Loss at step 73: 0.0008971838979050517\n",
      "Loss at step 74: 0.0011372276348993182\n",
      "Loss at step 75: 0.000798652705270797\n",
      "Loss at step 76: 0.0008847153512760997\n",
      "Loss at step 77: 0.0010863060597330332\n",
      "Loss at step 78: 0.0009487589122727513\n",
      "Loss at step 79: 0.0009860072750598192\n",
      "Loss at step 80: 0.0009879349963739514\n",
      "Loss at step 81: 0.00110799097456038\n",
      "Loss at step 82: 0.0009839526610448956\n",
      "Loss at step 83: 0.0012534765992313623\n",
      "Loss at step 84: 0.0010227870661765337\n",
      "Loss at step 85: 0.000954754592385143\n",
      "Loss at step 86: 0.0009135180152952671\n",
      "Loss at step 87: 0.0010169507004320621\n",
      "Loss at step 88: 0.000978538184426725\n",
      "Loss at step 89: 0.0011088342871516943\n",
      "Loss at step 90: 0.000987535691820085\n",
      "Loss at step 91: 0.0008106243913061917\n",
      "Loss at step 92: 0.0008446714491583407\n",
      "Loss at step 93: 0.0008866399293765426\n",
      "Loss at step 94: 0.0008095737430267036\n",
      "Loss at step 95: 0.0007772970711812377\n",
      "Loss at step 96: 0.0010506861144676805\n",
      "Loss at step 97: 0.0010078797349706292\n",
      "Loss at step 98: 0.0011083338176831603\n",
      "Loss at step 99: 0.0009168116375803947\n",
      "Loss at step 100: 0.0010457122698426247\n",
      "Loss at step 101: 0.0008758989279158413\n",
      "Loss at step 102: 0.0009220942156389356\n",
      "Loss at step 103: 0.0009601789060980082\n",
      "Loss at step 104: 0.0008679868187755346\n",
      "Loss at step 105: 0.0008605864713899791\n",
      "Loss at step 106: 0.001138984807766974\n",
      "Loss at step 107: 0.0007152066682465374\n",
      "Loss at step 108: 0.0009187489631585777\n",
      "Loss at step 109: 0.0007905038073658943\n",
      "Loss at step 110: 0.0010127940913662314\n",
      "Loss at step 111: 0.0009539328748360276\n",
      "Loss at step 112: 0.001026405137963593\n",
      "Loss at step 113: 0.0009127017692662776\n",
      "Loss at step 114: 0.0010300998110324144\n",
      "Loss at step 115: 0.0008932238561101258\n",
      "Loss at step 116: 0.0006756003713235259\n",
      "Loss at step 117: 0.0009789002360776067\n",
      "Loss at step 118: 0.0007820770842954516\n",
      "Loss at step 119: 0.0008692988776601851\n",
      "Loss at step 120: 0.0009246213594451547\n",
      "Loss at step 121: 0.0008540416602045298\n",
      "Loss at step 122: 0.0007311160443350673\n",
      "Loss at step 123: 0.0010467057581990957\n",
      "Loss at step 124: 0.0007664298755116761\n",
      "Loss at step 125: 0.0011858127545565367\n",
      "Loss at step 126: 0.0007054337183944881\n",
      "Loss at step 127: 0.0009112483821809292\n",
      "Loss at step 128: 0.001011466491036117\n",
      "Loss at step 129: 0.0009280656813643873\n",
      "Loss at step 130: 0.0009546246146783233\n",
      "Loss at step 131: 0.0010068186093121767\n",
      "Loss at step 132: 0.0009697687928564847\n",
      "Loss at step 133: 0.0009451148798689246\n",
      "Loss at step 134: 0.0006493507535196841\n",
      "Loss at step 135: 0.0008876188076101243\n",
      "Loss at step 136: 0.0008796578040346503\n",
      "Loss at step 137: 0.001006782054901123\n",
      "Loss at step 138: 0.0010560129303485155\n",
      "Loss at step 139: 0.000993346911855042\n",
      "Loss at step 140: 0.0012057037092745304\n",
      "Loss at step 141: 0.0010361267486587167\n",
      "Loss at step 142: 0.0010159562807530165\n",
      "Loss at step 143: 0.0009277357603423297\n",
      "Loss at step 144: 0.0009372238419018686\n",
      "Loss at step 145: 0.0010061349021270871\n",
      "Loss at step 146: 0.0010906350798904896\n",
      "Loss at step 147: 0.0007437624735757709\n",
      "Loss at step 148: 0.0010195031063631177\n",
      "Loss at step 149: 0.0006588814430870116\n",
      "Loss at step 150: 0.000864835106767714\n",
      "Loss at step 151: 0.00072619499405846\n",
      "Loss at step 152: 0.0008779481286183\n",
      "Loss at step 153: 0.0007760776206851006\n",
      "Loss at step 154: 0.0010590578895062208\n",
      "Loss at step 155: 0.0010642040288075805\n",
      "Loss at step 156: 0.0008484307327307761\n",
      "Loss at step 157: 0.0009674339089542627\n",
      "Loss at step 158: 0.0008188494248315692\n",
      "Loss at step 159: 0.0010025956435129046\n",
      "Loss at step 160: 0.0008639656007289886\n",
      "Loss at step 161: 0.0007740086875855923\n",
      "Loss at step 162: 0.000776055094320327\n",
      "Loss at step 163: 0.0011967410100623965\n",
      "Loss at step 164: 0.000938503653742373\n",
      "Loss at step 165: 0.0009201213251799345\n",
      "Loss at step 166: 0.0010792197426781058\n",
      "Loss at step 167: 0.0010396885918453336\n",
      "Loss at step 168: 0.0009776183869689703\n",
      "Loss at step 169: 0.0009960082825273275\n",
      "Loss at step 170: 0.0011273360578343272\n",
      "Loss at step 171: 0.0009396740351803601\n",
      "Loss at step 172: 0.0010111680021509528\n",
      "Loss at step 173: 0.0010520623764023185\n",
      "Loss at step 174: 0.000858432671520859\n",
      "Loss at step 175: 0.000618465302977711\n",
      "Loss at step 176: 0.00071495067095384\n",
      "Loss at step 177: 0.0010523886885493994\n",
      "Loss at step 178: 0.0010002695489674807\n",
      "Loss at step 179: 0.0010734314564615488\n",
      "Loss at step 180: 0.0007514413446187973\n",
      "Loss at step 181: 0.0010112692834809422\n",
      "Loss at step 182: 0.0009893772657960653\n",
      "Loss at step 183: 0.0008513802895322442\n",
      "Loss at step 184: 0.0010183481499552727\n",
      "Loss at step 185: 0.0010914906160905957\n",
      "Loss at step 186: 0.001128355273976922\n",
      "Loss at step 187: 0.0008921051048673689\n",
      "Loss at step 188: 0.0010222061537206173\n",
      "Loss at step 189: 0.0009268241701647639\n",
      "Loss at step 190: 0.0008385218679904938\n",
      "Loss at step 191: 0.0007565338746644557\n",
      "Loss at step 192: 0.0011264517670497298\n",
      "Loss at step 193: 0.0009373922948725522\n",
      "Loss at step 194: 0.0011512766359373927\n",
      "Loss at step 195: 0.0009073732071556151\n",
      "Loss at step 196: 0.0009485709597356617\n",
      "Loss at step 197: 0.0007090622675605118\n",
      "Loss at step 198: 0.0009248228161595762\n",
      "Loss at step 199: 0.0008871620520949364\n",
      "Loss at step 200: 0.0008518787217326462\n",
      "Loss at step 201: 0.0008900637039914727\n",
      "Loss at step 202: 0.0008317906758747995\n",
      "Loss at step 203: 0.0007999121444299817\n",
      "Loss at step 204: 0.000908505404368043\n",
      "Loss at step 205: 0.0008324390510097146\n",
      "Loss at step 206: 0.0008580744615755975\n",
      "Loss at step 207: 0.001004953752271831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 208: 0.0006938055157661438\n",
      "Loss at step 209: 0.0008991117938421667\n",
      "Loss at step 210: 0.0008296779706142843\n",
      "Loss at step 211: 0.0007416413282044232\n",
      "Loss at step 212: 0.0009733423357829452\n",
      "Loss at step 213: 0.001034919056110084\n",
      "Loss at step 214: 0.0009085851488634944\n",
      "Loss at step 215: 0.0010549187427386642\n",
      "Loss at step 216: 0.0009162560454569757\n",
      "Loss at step 217: 0.0008799838833510876\n",
      "Loss at step 218: 0.0009866445325314999\n",
      "Loss at step 219: 0.000849766714964062\n",
      "Loss at step 220: 0.001005413243547082\n",
      "Loss at step 221: 0.001095828483812511\n",
      "Loss at step 222: 0.0009167730459012091\n",
      "Loss at step 223: 0.0009240621002390981\n",
      "Loss at step 224: 0.0011656826827675104\n",
      "Loss at step 225: 0.000747008016332984\n",
      "Loss at step 226: 0.0009019779390655458\n",
      "Loss at step 227: 0.0009533293778076768\n",
      "Loss at step 228: 0.0010083012748509645\n",
      "Loss at step 229: 0.0008722301572561264\n",
      "Loss at step 230: 0.0009670233121141791\n",
      "Loss at step 231: 0.0006777939270250499\n",
      "Loss at step 232: 0.0008927374728955328\n",
      "Loss at step 233: 0.0010151158785447478\n",
      "Loss at step 234: 0.0010320000583305955\n",
      "Loss at step 235: 0.0007465093513019383\n",
      "Loss at step 236: 0.0009443563176319003\n",
      "Loss at step 237: 0.0008816061890684068\n",
      "Loss at step 238: 0.0009309629094786942\n",
      "Loss at step 239: 0.0009732177713885903\n",
      "Loss at step 240: 0.0009688792051747441\n",
      "Loss at step 241: 0.0008331651915796101\n",
      "Loss at step 242: 0.0009322529076598585\n",
      "Loss at step 243: 0.0008437694632448256\n",
      "Loss at step 244: 0.0009120720787905157\n",
      "Loss at step 245: 0.0010285851312801242\n",
      "Loss at step 246: 0.0009979839669540524\n",
      "Loss at step 247: 0.000772317813243717\n",
      "Loss at step 248: 0.0010829941602423787\n",
      "Loss at step 249: 0.0010801827302202582\n",
      "Loss at step 250: 0.0011483752168715\n",
      "Loss at step 251: 0.0008905544527806342\n",
      "Loss at step 252: 0.0008169710054062307\n",
      "Loss at step 253: 0.0008053743513301015\n",
      "Loss at step 254: 0.0011873695766553283\n",
      "Loss at step 255: 0.001010602107271552\n",
      "Loss at step 256: 0.0008263465715572238\n",
      "Loss at step 257: 0.001013910979963839\n",
      "Loss at step 258: 0.0010071563301607966\n",
      "Loss at step 259: 0.0009912478271871805\n",
      "Loss at step 260: 0.0008615635451860726\n",
      "Loss at step 261: 0.0008725179941393435\n",
      "Loss at step 262: 0.0008819716749712825\n",
      "Loss at step 263: 0.0010540460934862494\n",
      "Loss at step 264: 0.0008643327746540308\n",
      "Loss at step 265: 0.0008302427013404667\n",
      "Loss at step 266: 0.0007590145105496049\n",
      "Loss at step 267: 0.0008591593359597027\n",
      "Loss at step 268: 0.0009037062991410494\n",
      "Loss at step 269: 0.001024181372486055\n",
      "Loss at step 270: 0.0008982400177046657\n",
      "Loss at step 271: 0.000963949307333678\n",
      "Loss at step 272: 0.0009998173918575048\n",
      "Loss at step 273: 0.0009358514798805118\n",
      "Loss at step 274: 0.0008457931107841432\n",
      "Loss at step 275: 0.000981986289843917\n",
      "Loss at step 276: 0.0009917246643453836\n",
      "Loss at step 277: 0.000741714087780565\n",
      "Loss at step 278: 0.0008665758068673313\n",
      "Loss at step 279: 0.0011413354659453034\n",
      "Loss at step 280: 0.000839057145640254\n",
      "Loss at step 281: 0.0008739893091842532\n",
      "Loss at step 282: 0.000761519477237016\n",
      "Loss at step 283: 0.0008753256988711655\n",
      "Loss at step 284: 0.0009466421324759722\n",
      "Loss at step 285: 0.0007882356876507401\n",
      "Loss at step 286: 0.0010261990828439593\n",
      "Loss at step 287: 0.000844475522171706\n",
      "Loss at step 288: 0.0010061917128041387\n",
      "Loss at step 289: 0.0010080210631713271\n",
      "Loss at step 290: 0.0008580710855312645\n",
      "Loss at step 291: 0.0007465829839929938\n",
      "Loss at step 292: 0.0007215628866106272\n",
      "Loss at step 293: 0.0008961943676695228\n",
      "Loss at step 294: 0.0008051075856201351\n",
      "Loss at step 295: 0.0009026440675370395\n",
      "Loss at step 296: 0.0006127087399363518\n",
      "Loss at step 297: 0.0007346037309616804\n",
      "Loss at step 298: 0.0008637328865006566\n",
      "Loss at step 299: 0.0009506436763331294\n",
      "Loss at step 300: 0.0008808649145066738\n",
      "Loss at step 301: 0.0008901105611585081\n",
      "Loss at step 302: 0.0010697778780013323\n",
      "Loss at step 303: 0.0008386962581425905\n",
      "Loss at step 304: 0.0008098658290691674\n",
      "Loss at step 305: 0.0009559660102240741\n",
      "Loss at step 306: 0.0009648583363741636\n",
      "Loss at step 307: 0.0008144112653099\n",
      "Loss at step 308: 0.0009441312286071479\n",
      "Loss at step 309: 0.000953987764660269\n",
      "Loss at step 310: 0.0009469453361816704\n",
      "Loss at step 311: 0.0008654691046103835\n",
      "Loss at step 312: 0.0008974556694738567\n",
      "Loss at step 313: 0.001049778307788074\n",
      "Loss at step 314: 0.0010496217291802168\n",
      "Loss at step 315: 0.0008413116447627544\n",
      "Loss at step 316: 0.0011266580550000072\n",
      "Loss at step 317: 0.000974879483692348\n",
      "Loss at step 318: 0.0009742612601257861\n",
      "Loss at step 319: 0.0007761329179629683\n",
      "Loss at step 320: 0.0009511300013400614\n",
      "Loss at step 321: 0.0009038850548677146\n",
      "Loss at step 322: 0.0009711364982649684\n",
      "Loss at step 323: 0.000924022460822016\n",
      "Loss at step 324: 0.0007465897360816598\n",
      "Loss at step 325: 0.0008923557470552623\n",
      "Loss at step 326: 0.0008992021903395653\n",
      "Loss at step 327: 0.0010577437933534384\n",
      "Loss at step 328: 0.0009127736557275057\n",
      "Loss at step 329: 0.0010935775935649872\n",
      "Loss at step 330: 0.0009313751361332834\n",
      "Loss at step 331: 0.000976824900135398\n",
      "Loss at step 332: 0.001090615289285779\n",
      "Loss at step 333: 0.0008189963991753757\n",
      "Loss at step 334: 0.0007532428717240691\n",
      "Loss at step 335: 0.0009612521389499307\n",
      "Loss at step 336: 0.0010176245123147964\n",
      "Loss at step 337: 0.0009361517732031643\n",
      "Loss at step 338: 0.0010325562907382846\n",
      "Loss at step 339: 0.0009239724604412913\n",
      "Loss at step 340: 0.0008805762627162039\n",
      "Loss at step 341: 0.0009498082217760384\n",
      "Loss at step 342: 0.0009083424811251462\n",
      "Loss at step 343: 0.000840510765556246\n",
      "Loss at step 344: 0.000963778467848897\n",
      "Loss at step 345: 0.0009163983631879091\n",
      "Loss at step 346: 0.0009084834600798786\n",
      "Loss at step 347: 0.0009358423994854093\n",
      "Loss at step 348: 0.0009392361389473081\n",
      "Loss at step 349: 0.000805828720331192\n",
      "Loss at step 350: 0.0004141804529353976\n",
      "Loss at step 351: 0.0009710695594549179\n",
      "Loss at step 352: 0.0006660328945145011\n",
      "Loss at step 353: 0.0008503602584823966\n",
      "Loss at step 354: 0.0009273302857764065\n",
      "Loss at step 355: 0.0008515059598721564\n",
      "Loss at step 356: 0.0008425702690146863\n",
      "Loss at step 357: 0.000962757330853492\n",
      "Loss at step 358: 0.0008846628479659557\n",
      "Loss at step 359: 0.0009095578570850194\n",
      "Loss at step 360: 0.0008484569261781871\n",
      "Loss at step 361: 0.0009504995541647077\n",
      "Loss at step 362: 0.0009492355166003108\n",
      "Loss at step 363: 0.0007413182174786925\n",
      "Loss at step 364: 0.0009478388819843531\n",
      "Loss at step 365: 0.0010819222079589963\n",
      "Loss at step 366: 0.0008157156407833099\n",
      "Loss at step 367: 0.0010239185066893697\n",
      "Loss at step 368: 0.0008726002997718751\n",
      "Loss at step 369: 0.0010832304833456874\n",
      "Loss at step 370: 0.0010809398954734206\n",
      "Loss at step 371: 0.0010485550155863166\n",
      "Loss at step 372: 0.0009826647583395243\n",
      "Loss at step 373: 0.000890321156475693\n",
      "Loss at step 374: 0.0008312381687574089\n",
      "Loss at step 375: 0.0006819871487095952\n",
      "Loss at step 376: 0.0010969853028655052\n",
      "Loss at step 377: 0.0009105452336370945\n",
      "Loss at step 378: 0.00108534493483603\n",
      "Loss at step 379: 0.0009984537027776241\n",
      "Loss at step 380: 0.0010312722297385335\n",
      "Loss at step 381: 0.0009166172239929438\n",
      "Loss at step 382: 0.000894141907338053\n",
      "Loss at step 383: 0.0010275701060891151\n",
      "Loss at step 384: 0.0006376832607202232\n",
      "Loss at step 385: 0.0007815838907845318\n",
      "Loss at step 386: 0.0008284326759167016\n",
      "Loss at step 387: 0.0010466650128364563\n",
      "Loss at step 388: 0.000923281884752214\n",
      "Loss at step 389: 0.000809708668384701\n",
      "Loss at step 390: 0.0007930183201096952\n",
      "Loss at step 391: 0.0007891480927355587\n",
      "Loss at step 392: 0.0009491239907220006\n",
      "Loss at step 393: 0.0011023209663107991\n",
      "Loss at step 394: 0.0008778195478953421\n",
      "Loss at step 395: 0.0007108046556822956\n",
      "Loss at step 396: 0.0009052252280525863\n",
      "Loss at step 397: 0.0011272048577666283\n",
      "Loss at step 398: 0.001016463851556182\n",
      "Loss at step 399: 0.0007868926622904837\n",
      "Loss at step 400: 0.0010262394789606333\n",
      "Loss at step 401: 0.0008386576664634049\n",
      "Loss at step 402: 0.0008854497573338449\n",
      "Loss at step 403: 0.0009072184329852462\n",
      "Loss at step 404: 0.0008825333206914365\n",
      "Loss at step 405: 0.0009704980766400695\n",
      "Loss at step 406: 0.0010350511875003576\n",
      "Loss at step 407: 0.0006843677838332951\n",
      "Loss at step 408: 0.0008820926304906607\n",
      "Loss at step 409: 0.0008996100514195859\n",
      "Loss at step 410: 0.000999740674160421\n",
      "Loss at step 411: 0.0009748184820637107\n",
      "Loss at step 412: 0.000896940880920738\n",
      "Loss at step 413: 0.0008237553993239999\n",
      "Loss at step 414: 0.0010178392985835671\n",
      "Loss at step 415: 0.0008343023946508765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 416: 0.0008172695524990559\n",
      "Loss at step 417: 0.0011851738672703505\n",
      "Loss at step 418: 0.0009435032843612134\n",
      "Loss at step 419: 0.0008730081026442349\n",
      "Loss at step 420: 0.000770679849665612\n",
      "Loss at step 421: 0.0010367920622229576\n",
      "Loss at step 422: 0.000776427797973156\n",
      "Loss at step 423: 0.0008796538459137082\n",
      "Loss at step 424: 0.0009742709808051586\n",
      "Loss at step 425: 0.0008425645646639168\n",
      "Loss at step 426: 0.0011620365548878908\n",
      "Loss at step 427: 0.0008661432657390833\n",
      "Loss at step 428: 0.0009204113157466054\n",
      "Loss at step 429: 0.0007510194554924965\n",
      "Loss at step 430: 0.0009047690546140075\n",
      "Loss at step 431: 0.0010342784225940704\n",
      "Loss at step 432: 0.0009018280543386936\n",
      "Loss at step 433: 0.0006372581119649112\n",
      "Loss at step 434: 0.0008463160484097898\n",
      "Loss at step 435: 0.0009896603878587484\n",
      "Loss at step 436: 0.0009829822229221463\n",
      "Loss at step 437: 0.0007752534002065659\n",
      "Loss at step 438: 0.0007608502637594938\n",
      "Loss at step 439: 0.0009177004103548825\n",
      "Loss at step 440: 0.0010337007697671652\n",
      "Loss at step 441: 0.0010406473884359002\n",
      "Loss at step 442: 0.0008364854147657752\n",
      "Loss at step 443: 0.0007459021871909499\n",
      "Loss at step 444: 0.0009253706666640937\n",
      "Loss at step 445: 0.0010623272974044085\n",
      "Loss at step 446: 0.0009313357877545059\n",
      "Loss at step 447: 0.0008071242482401431\n",
      "Loss at step 448: 0.0007032101857475936\n",
      "Loss at step 449: 0.0007617437513545156\n",
      "Loss at step 450: 0.0009355716174468398\n",
      "Loss at step 451: 0.0008358695777133107\n",
      "Loss at step 452: 0.0008571055950596929\n",
      "Loss at step 453: 0.0009568792884238064\n",
      "Loss at step 454: 0.0006388238398358226\n",
      "Loss at step 455: 0.0009759834501892328\n",
      "Loss at step 456: 0.0007483736844733357\n",
      "Loss at step 457: 0.0009310429450124502\n",
      "Loss at step 458: 0.0010092437732964754\n",
      "Loss at step 459: 0.0010555677581578493\n",
      "Loss at step 460: 0.0009681290830485523\n",
      "Loss at step 461: 0.0008575161918997765\n",
      "Loss at step 462: 0.0009168626274913549\n",
      "Loss at step 463: 0.0010559881338849664\n",
      "Loss at step 464: 0.0008223125478252769\n",
      "Loss at step 465: 0.0005155871040187776\n",
      "Loss at step 466: 0.000952632341068238\n",
      "Loss at step 467: 0.0010506230173632503\n",
      "Loss at step 468: 0.0009077446884475648\n",
      "Loss at step 469: 0.0009645550744608045\n",
      "Loss at step 470: 0.0007956784684211016\n",
      "Loss at step 471: 0.001100027933716774\n",
      "Loss at step 472: 0.0009130696416832507\n",
      "Loss at step 473: 0.0009099552407860756\n",
      "Loss at step 474: 0.0008662188774906099\n",
      "Loss at step 475: 0.0007842734921723604\n",
      "Loss at step 476: 0.0009135470609180629\n",
      "Loss at step 477: 0.0008611820521764457\n",
      "Loss at step 478: 0.0007848501554690301\n",
      "Loss at step 479: 0.0009461963782086968\n",
      "Loss at step 480: 0.000889166200067848\n",
      "Loss at step 481: 0.0009673572494648397\n",
      "Loss at step 482: 0.0010006589582189918\n",
      "Loss at step 483: 0.0008186933118849993\n",
      "Loss at step 484: 0.0008055846556089818\n",
      "Loss at step 485: 0.0009565060026943684\n",
      "Loss at step 486: 0.001038366579450667\n",
      "Loss at step 487: 0.0010216415394097567\n",
      "Loss at step 488: 0.0009531620307825506\n",
      "Loss at step 489: 0.0007945939432829618\n",
      "Loss at step 490: 0.0010365055641159415\n",
      "Loss at step 491: 0.0009403681033290923\n",
      "Loss at step 492: 0.0008980365237221122\n",
      "Loss at step 493: 0.0010088221170008183\n",
      "Loss at step 494: 0.0008296726737171412\n",
      "Loss at step 495: 0.0008615107508376241\n",
      "Loss at step 496: 0.0008988526533357799\n",
      "Loss at step 497: 0.0009065716294571757\n",
      "Loss at step 498: 0.0008488845778629184\n",
      "Loss at step 499: 0.0010537926573306322\n",
      "Loss at step 500: 0.001034008921124041\n",
      "Loss at step 501: 0.0010425262153148651\n",
      "Loss at step 502: 0.0006706916610710323\n",
      "Loss at step 503: 0.0009485410409979522\n",
      "Loss at step 504: 0.0009307610453106463\n",
      "Loss at step 505: 0.0008955586235970259\n",
      "Loss at step 506: 0.000788939418271184\n",
      "Loss at step 507: 0.0008597125415690243\n",
      "Loss at step 508: 0.0009161745547316968\n",
      "Loss at step 509: 0.0008142058504745364\n",
      "Loss at step 510: 0.000889965274836868\n",
      "Loss at step 511: 0.0008099418482743204\n",
      "Loss at step 512: 0.000990703934803605\n",
      "Loss at step 513: 0.000792094855569303\n",
      "Loss at step 514: 0.0010132152820006013\n",
      "Loss at step 515: 0.0008724055369384587\n",
      "Loss at step 516: 0.0007076689507812262\n",
      "Loss at step 517: 0.0009494607802480459\n",
      "Loss at step 518: 0.0009183055371977389\n",
      "Loss at step 519: 0.0009295502677559853\n",
      "Loss at step 520: 0.0008125590393319726\n",
      "Loss at step 521: 0.0009156854939647019\n",
      "Loss at step 522: 0.0009893495589494705\n",
      "Loss at step 523: 0.0008174358517862856\n",
      "Loss at step 524: 0.0006188507541082799\n",
      "Loss at step 525: 0.000992045970633626\n",
      "Loss at step 526: 0.0009566045482642949\n",
      "Loss at step 527: 0.0008517733658663929\n",
      "Loss at step 528: 0.0009077261784113944\n",
      "Loss at step 529: 0.0008974745869636536\n",
      "Loss at step 530: 0.0008889787131920457\n",
      "Loss at step 531: 0.0009971910621970892\n",
      "Loss at step 532: 0.000909599824808538\n",
      "Loss at step 533: 0.0008417380158789456\n",
      "Loss at step 534: 0.0009787310846149921\n",
      "Loss at step 535: 0.0006312978221103549\n",
      "Loss at step 536: 0.0010317025007680058\n",
      "Loss at step 537: 0.0008462862460874021\n",
      "Loss at step 538: 0.0009534047567285597\n",
      "Loss at step 539: 0.0009486495400778949\n",
      "Loss at step 540: 0.001010050647892058\n",
      "Loss at step 541: 0.0009825763991102576\n",
      "Loss at step 542: 0.0009461300214752555\n",
      "Loss at step 543: 0.0008442313992418349\n",
      "Loss at step 544: 0.0007519946666434407\n",
      "Loss at step 545: 0.0009082170436158776\n",
      "Loss at step 546: 0.000917319324798882\n",
      "Loss at step 547: 0.000985717517323792\n",
      "Loss at step 548: 0.0007543343235738575\n",
      "Loss at step 549: 0.000896114856004715\n",
      "Loss at step 550: 0.0008738809847272933\n",
      "Loss at step 551: 0.0010174476774409413\n",
      "Loss at step 552: 0.0005951303173787892\n",
      "Loss at step 553: 0.0009512911783531308\n",
      "Loss at step 554: 0.0010217741364613175\n",
      "Loss at step 555: 0.0009480884182266891\n",
      "Loss at step 556: 0.0009150991099886596\n",
      "Loss at step 557: 0.0009645464597269893\n",
      "Loss at step 558: 0.0010855472646653652\n",
      "Loss at step 559: 0.000922428269404918\n",
      "Loss at step 560: 0.0009299690136685967\n",
      "Loss at step 561: 0.0009147412492893636\n",
      "Loss at step 562: 0.0009145577205345035\n",
      "Loss at step 563: 0.0009288883884437382\n",
      "Loss at step 564: 0.0008733698050491512\n",
      "Loss at step 565: 0.0008228631922975183\n",
      "Loss at step 566: 0.0009571985574439168\n",
      "Loss at step 567: 0.0010548310820013285\n",
      "Loss at step 568: 0.0008149078930728137\n",
      "Loss at step 569: 0.0007899380871094763\n",
      "Loss at step 570: 0.0009312985348515213\n",
      "Loss at step 571: 0.0008140630088746548\n",
      "Loss at step 572: 0.0009031108929775655\n",
      "Loss at step 573: 0.0007510097348131239\n",
      "Loss at step 574: 0.0008939796825870872\n",
      "Loss at step 575: 0.0008204071782529354\n",
      "Loss at step 576: 0.0010461353231221437\n",
      "Loss at step 577: 0.0007141738897189498\n",
      "Loss at step 578: 0.0009322284604422748\n",
      "Loss at step 579: 0.0007874806760810316\n",
      "Loss at step 580: 0.0009179293410852551\n",
      "Loss at step 581: 0.0009761040564626455\n",
      "Loss at step 582: 0.0009618185576982796\n",
      "Loss at step 583: 0.0009454573155380785\n",
      "Loss at step 584: 0.0009220590000040829\n",
      "Loss at step 585: 0.0009403852745890617\n",
      "Loss at step 586: 0.0007805448258295655\n",
      "Loss at step 587: 0.0008370181312784553\n",
      "Loss at step 588: 0.0010216464288532734\n",
      "Loss at step 589: 0.0007267646724358201\n",
      "Loss at step 590: 0.0010227329330518842\n",
      "Loss at step 591: 0.001015655929222703\n",
      "Loss at step 592: 0.0009456203551962972\n",
      "Loss at step 593: 0.0008276337757706642\n",
      "Loss at step 594: 0.0010131635935977101\n",
      "Loss at step 595: 0.0008195964037440717\n",
      "Loss at step 596: 0.0008096774108707905\n",
      "Loss at step 597: 0.0008455505594611168\n",
      "Loss at step 598: 0.0008034275379031897\n",
      "Loss at step 599: 0.0008306730887852609\n",
      "Loss at step 600: 0.0008633295074105263\n",
      "Loss at step 601: 0.000931694870814681\n",
      "Loss at step 602: 0.0007730656652711332\n",
      "Loss at step 603: 0.0009003038285300136\n",
      "Loss at step 604: 0.0010125550907105207\n",
      "Loss at step 605: 0.0008741568308323622\n",
      "Loss at step 606: 0.001108210883103311\n",
      "Loss at step 607: 0.0008633531397208571\n",
      "Loss at step 608: 0.000987555948086083\n",
      "Loss at step 609: 0.0007518843049183488\n",
      "Loss at step 610: 0.0009774238569661975\n",
      "Loss at step 611: 0.0010237902170047164\n",
      "Loss at step 612: 0.0008300519548356533\n",
      "Loss at step 613: 0.0006576293963007629\n",
      "Loss at step 614: 0.0008659552549943328\n",
      "Loss at step 615: 0.000861303647980094\n",
      "Loss at step 616: 0.0007604897837154567\n",
      "Loss at step 617: 0.0009103110642172396\n",
      "Loss at step 618: 0.000964034057687968\n",
      "Loss at step 619: 0.0009586939122527838\n",
      "Loss at step 620: 0.000936576456297189\n",
      "Loss at step 621: 0.000829164229799062\n",
      "Loss at step 622: 0.0009445057366974652\n",
      "Loss at step 623: 0.0008254963904619217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 624: 0.0008276551379822195\n",
      "Loss at step 625: 0.0008501489646732807\n",
      "Loss at step 626: 0.0008305311785079539\n",
      "Loss at step 627: 0.0007701712311245501\n",
      "Loss at step 628: 0.0009136355947703123\n",
      "Loss at step 629: 0.0007010410772636533\n",
      "Loss at step 630: 0.001147515489719808\n",
      "Loss at step 631: 0.0007109752623364329\n",
      "Loss at step 632: 0.0008741256897337735\n",
      "Loss at step 633: 0.0006853911909274757\n",
      "Loss at step 634: 0.0009003190789371729\n",
      "Loss at step 635: 0.0008213750552386045\n",
      "Loss at step 636: 0.0009062248864211142\n",
      "Loss at step 637: 0.0009029826032929122\n",
      "Loss at step 638: 0.0009565869113430381\n",
      "Loss at step 639: 0.0009173906873911619\n",
      "Loss at step 640: 0.0010960923973470926\n",
      "Loss at step 641: 0.001069276942871511\n",
      "Loss at step 642: 0.001112470286898315\n",
      "Loss at step 643: 0.0009176161256618798\n",
      "Loss at step 644: 0.0008278564782813191\n",
      "Loss at step 645: 0.0009136669686995447\n",
      "Loss at step 646: 0.0004894525627605617\n",
      "Loss at step 647: 0.0007333428366109729\n",
      "Loss at step 648: 0.000978321535512805\n",
      "Loss at step 649: 0.0008641500608064234\n",
      "Loss at step 650: 0.0008215451962314546\n",
      "Loss at step 651: 0.0008656057179905474\n",
      "Loss at step 652: 0.0009396558161824942\n",
      "Loss at step 653: 0.000734186265617609\n",
      "Loss at step 654: 0.0009069781517609954\n",
      "Loss at step 655: 0.0009386609308421612\n",
      "Loss at step 656: 0.0008671064279042184\n",
      "Loss at step 657: 0.0010133379837498069\n",
      "Loss at step 658: 0.0007847525994293392\n",
      "Loss at step 659: 0.001106259529478848\n",
      "Loss at step 660: 0.0008100811392068863\n",
      "Loss at step 661: 0.0009457170381210744\n",
      "Loss at step 662: 0.000805181625764817\n",
      "Loss at step 663: 0.0012222907971590757\n",
      "Loss at step 664: 0.0008334274752996862\n",
      "Loss at step 665: 0.0008191768429242074\n",
      "Loss at step 666: 0.0008096566889435053\n",
      "Loss at step 667: 0.0009614031296223402\n",
      "Loss at step 668: 0.0008473137859255075\n",
      "Loss at step 669: 0.0008878388907760382\n",
      "Loss at step 670: 0.0007015650044195354\n",
      "Loss at step 671: 0.0007062310469336808\n",
      "Loss at step 672: 0.000679665245115757\n",
      "Loss at step 673: 0.0008519615512341261\n",
      "Loss at step 674: 0.0010129790753126144\n",
      "Loss at step 675: 0.0007596006616950035\n",
      "Loss at step 676: 0.0009925481863319874\n",
      "Loss at step 677: 0.0007804243941791356\n",
      "Loss at step 678: 0.0005218954756855965\n",
      "Loss at step 679: 0.0010830548126250505\n",
      "Loss at step 680: 0.0009176795720122755\n",
      "Loss at step 681: 0.001002772245556116\n",
      "Loss at step 682: 0.0009867943590506911\n",
      "Loss at step 683: 0.0007196239894255996\n",
      "Loss at step 684: 0.0009606529492884874\n",
      "Loss at step 685: 0.0008695156429894269\n",
      "Loss at step 686: 0.0009777671657502651\n",
      "Loss at step 687: 0.000823848124127835\n",
      "Loss at step 688: 0.0008217071299441159\n",
      "Loss at step 689: 0.0009584053768776357\n",
      "Loss at step 690: 0.0007557730423286557\n",
      "Loss at step 691: 0.0007936906768009067\n",
      "Loss at step 692: 0.0006410097703337669\n",
      "Loss at step 693: 0.0008885070565156639\n",
      "Loss at step 694: 0.0008267884841188788\n",
      "Loss at step 695: 0.0009075659327208996\n",
      "Loss at step 696: 0.000943865510635078\n",
      "Loss at step 697: 0.000790848396718502\n",
      "Loss at step 698: 0.0010343310423195362\n",
      "Loss at step 699: 0.0010239414405077696\n",
      "Loss at step 700: 0.0007010160479694605\n",
      "Loss at step 701: 0.0008746592793613672\n",
      "Loss at step 702: 0.0008887180592864752\n",
      "Loss at step 703: 0.0006911596865393221\n",
      "Loss at step 704: 0.0009453059756197035\n",
      "Loss at step 705: 0.0006395187228918076\n",
      "train Loss: 0.0009\n",
      "Loss at step 0: 0.0009357422241009772\n",
      "Loss at step 1: 0.0010931318392977118\n",
      "Loss at step 2: 0.0008802352822385728\n",
      "Loss at step 3: 0.0008474798523820937\n",
      "Loss at step 4: 0.0012233988381922245\n",
      "Loss at step 5: 0.0007996202912181616\n",
      "Loss at step 6: 0.0008223448530770838\n",
      "Loss at step 7: 0.0008330075652338564\n",
      "Loss at step 8: 0.0007418898749165237\n",
      "Loss at step 9: 0.0009152404381893575\n",
      "Loss at step 10: 0.0009650095016695559\n",
      "Loss at step 11: 0.000854166632052511\n",
      "Loss at step 12: 0.0009558959282003343\n",
      "Loss at step 13: 0.0008069021278060973\n",
      "Loss at step 14: 0.0007831996772438288\n",
      "Loss at step 15: 0.0009149647667072713\n",
      "Loss at step 16: 0.0010188132291659713\n",
      "Loss at step 17: 0.0010280146962031722\n",
      "Loss at step 18: 0.0009623958030715585\n",
      "Loss at step 19: 0.0008092366042546928\n",
      "Loss at step 20: 0.0010383962653577328\n",
      "Loss at step 21: 0.0009004388120956719\n",
      "Loss at step 22: 0.0011211775708943605\n",
      "Loss at step 23: 0.0010145795531570911\n",
      "Loss at step 24: 0.0010738220298662782\n",
      "Loss at step 25: 0.000931252259761095\n",
      "Loss at step 26: 0.0008860567468218505\n",
      "Loss at step 27: 0.0009883895982056856\n",
      "Loss at step 28: 0.0010084835812449455\n",
      "Loss at step 29: 0.0008646498317830265\n",
      "Loss at step 30: 0.000992452958598733\n",
      "Loss at step 31: 0.000919664278626442\n",
      "Loss at step 32: 0.0010142882820218801\n",
      "Loss at step 33: 0.0008584843017160892\n",
      "Loss at step 34: 0.0008901982801035047\n",
      "Loss at step 35: 0.0008249148959293962\n",
      "Loss at step 36: 0.0009020183351822197\n",
      "Loss at step 37: 0.0009272365714423358\n",
      "Loss at step 38: 0.0010837055742740631\n",
      "Loss at step 39: 0.0009969884995371103\n",
      "Loss at step 40: 0.0009951372630894184\n",
      "Loss at step 41: 0.0010599697707220912\n",
      "Loss at step 42: 0.0009018778218887746\n",
      "Loss at step 43: 0.0009885368635877967\n",
      "Loss at step 44: 0.0008381187217310071\n",
      "Loss at step 45: 0.0010398966260254383\n",
      "Loss at step 46: 0.0009152911952696741\n",
      "Loss at step 47: 0.0007568267756141722\n",
      "Loss at step 48: 0.0011130825150758028\n",
      "Loss at step 49: 0.0011641063028946519\n",
      "Loss at step 50: 0.0010576335480436683\n",
      "Loss at step 51: 0.0010362749453634024\n",
      "Loss at step 52: 0.0009308135486207902\n",
      "Loss at step 53: 0.0009023108286783099\n",
      "Loss at step 54: 0.0006133433780632913\n",
      "Loss at step 55: 0.0009037086856551468\n",
      "Loss at step 56: 0.00078310671960935\n",
      "Loss at step 57: 0.0009857851546257734\n",
      "Loss at step 58: 0.000987380975857377\n",
      "Loss at step 59: 0.0010081360815092921\n",
      "Loss at step 60: 0.0007599460077472031\n",
      "Loss at step 61: 0.0010042641079053283\n",
      "Loss at step 62: 0.0008833680767565966\n",
      "Loss at step 63: 0.0008567643817514181\n",
      "Loss at step 64: 0.0009249723516404629\n",
      "Loss at step 65: 0.0007585519924759865\n",
      "Loss at step 66: 0.0006828569457866251\n",
      "Loss at step 67: 0.0009345542057417333\n",
      "Loss at step 68: 0.0009187419782392681\n",
      "Loss at step 69: 0.0009296080097556114\n",
      "Loss at step 70: 0.0008774593006819487\n",
      "Loss at step 71: 0.0009537444566376507\n",
      "Loss at step 72: 0.0009798910468816757\n",
      "Loss at step 73: 0.0007574479095637798\n",
      "Loss at step 74: 0.0008033219492062926\n",
      "Loss at step 75: 0.0009842966683208942\n",
      "Loss at step 76: 0.0010627236915752292\n",
      "Loss at step 77: 0.0010665950831025839\n",
      "Loss at step 78: 0.0010206374572589993\n",
      "Loss at step 79: 0.0009787902235984802\n",
      "Loss at step 80: 0.0009248043643310666\n",
      "Loss at step 81: 0.0007255175150930882\n",
      "Loss at step 82: 0.0009237235062755644\n",
      "Loss at step 83: 0.0011627698550000787\n",
      "Loss at step 84: 0.000915186305064708\n",
      "Loss at step 85: 0.0008002654649317265\n",
      "Loss at step 86: 0.0009290050365962088\n",
      "Loss at step 87: 0.0011157105909660459\n",
      "Loss at step 88: 0.0011156677501276135\n",
      "Loss at step 89: 0.00046045208000577986\n",
      "Loss at step 90: 0.0007780746673233807\n",
      "Loss at step 91: 0.0007006197120063007\n",
      "Loss at step 92: 0.0008424273692071438\n",
      "Loss at step 93: 0.0008450997993350029\n",
      "Loss at step 94: 0.0007410916150547564\n",
      "Loss at step 95: 0.000984257785603404\n",
      "Loss at step 96: 0.0010843930067494512\n",
      "Loss at step 97: 0.0010532729793339968\n",
      "Loss at step 98: 0.0009856721153482795\n",
      "Loss at step 99: 0.0009482467430643737\n",
      "Loss at step 100: 0.0008312331628985703\n",
      "Loss at step 101: 0.0009564877254888415\n",
      "Loss at step 102: 0.0008738607866689563\n",
      "Loss at step 103: 0.0008361964137293398\n",
      "Loss at step 104: 0.0008612748351879418\n",
      "Loss at step 105: 0.000983493635430932\n",
      "Loss at step 106: 0.0010199290700256824\n",
      "Loss at step 107: 0.0008954231743700802\n",
      "Loss at step 108: 0.0009664564277045429\n",
      "Loss at step 109: 0.0008398638456128538\n",
      "Loss at step 110: 0.0009247908601537347\n",
      "Loss at step 111: 0.0008774834568612278\n",
      "Loss at step 112: 0.0007188630406744778\n",
      "Loss at step 113: 0.000950609624851495\n",
      "Loss at step 114: 0.0009732361068017781\n",
      "Loss at step 115: 0.0009977547451853752\n",
      "Loss at step 116: 0.0008633872494101524\n",
      "Loss at step 117: 0.0008635962149128318\n",
      "Loss at step 118: 0.0006119034951552749\n",
      "Loss at step 119: 0.0007312443922273815\n",
      "Loss at step 120: 0.0007726643816567957\n",
      "Loss at step 121: 0.0008324845694005489\n",
      "Loss at step 122: 0.0009140908368863165\n",
      "Loss at step 123: 0.0007551235612481833\n",
      "Loss at step 124: 0.0007783938781358302\n",
      "Loss at step 125: 0.000800922978669405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 126: 0.001167149981483817\n",
      "Loss at step 127: 0.000803397735580802\n",
      "Loss at step 128: 0.0010130482260137796\n",
      "Loss at step 129: 0.0009749753517098725\n",
      "Loss at step 130: 0.0009302698308601975\n",
      "Loss at step 131: 0.0008698625606484711\n",
      "Loss at step 132: 0.0008522705174982548\n",
      "Loss at step 133: 0.0006103393970988691\n",
      "Loss at step 134: 0.0008580773719586432\n",
      "Loss at step 135: 0.0011689651291817427\n",
      "Loss at step 136: 0.0007870314875617623\n",
      "Loss at step 137: 0.0009526763460598886\n",
      "Loss at step 138: 0.0007961434894241393\n",
      "Loss at step 139: 0.0008532055071555078\n",
      "Loss at step 140: 0.0009533194825053215\n",
      "Loss at step 141: 0.0009023111779242754\n",
      "Loss at step 142: 0.0011871305759996176\n",
      "Loss at step 143: 0.001011616550385952\n",
      "Loss at step 144: 0.0009172602440230548\n",
      "Loss at step 145: 0.0009865124011412263\n",
      "Loss at step 146: 0.0009527609217911959\n",
      "Loss at step 147: 0.0010465746745467186\n",
      "Loss at step 148: 0.0009039560682140291\n",
      "Loss at step 149: 0.0009252704912796617\n",
      "Loss at step 150: 0.0009194610174745321\n",
      "Loss at step 151: 0.0008986619650386274\n",
      "Loss at step 152: 0.00085217016749084\n",
      "Loss at step 153: 0.0008503150311298668\n",
      "Loss at step 154: 0.0008937797392718494\n",
      "Loss at step 155: 0.0009235917241312563\n",
      "Loss at step 156: 0.0010767063358798623\n",
      "Loss at step 157: 0.0006914908881299198\n",
      "Loss at step 158: 0.0008740071207284927\n",
      "Loss at step 159: 0.0008581107831560075\n",
      "Loss at step 160: 0.0008706162334419787\n",
      "Loss at step 161: 0.0006404746090993285\n",
      "Loss at step 162: 0.0011592278024181724\n",
      "Loss at step 163: 0.0010483787627890706\n",
      "Loss at step 164: 0.0007279431447386742\n",
      "Loss at step 165: 0.0010044011287391186\n",
      "Loss at step 166: 0.0010057921754196286\n",
      "Loss at step 167: 0.0008713285787962377\n",
      "Loss at step 168: 0.0009015618124976754\n",
      "Loss at step 169: 0.0008922248962335289\n",
      "Loss at step 170: 0.0006046562921255827\n",
      "Loss at step 171: 0.0009039848227985203\n",
      "Loss at step 172: 0.0008672570693306625\n",
      "Loss at step 173: 0.0008917247178032994\n",
      "Loss at step 174: 0.000799989968072623\n",
      "Loss at step 175: 0.0009700078517198563\n",
      "Loss at step 176: 0.000831930956337601\n",
      "val Loss: 0.0009\n",
      "Epoch 1/4\n",
      "----------\n",
      "Loss at step 0: 0.0010869591496884823\n",
      "Loss at step 1: 0.0010969399008899927\n",
      "Loss at step 2: 0.0009440370486117899\n",
      "Loss at step 3: 0.0007121487287804484\n",
      "Loss at step 4: 0.0009630629210732877\n",
      "Loss at step 5: 0.0007971546147018671\n",
      "Loss at step 6: 0.0010076032485812902\n",
      "Loss at step 7: 0.0006982929189689457\n",
      "Loss at step 8: 0.00103097315877676\n",
      "Loss at step 9: 0.0006564938230440021\n",
      "Loss at step 10: 0.0009790483163669705\n",
      "Loss at step 11: 0.000911787967197597\n",
      "Loss at step 12: 0.000985408085398376\n",
      "Loss at step 13: 0.0010514298919588327\n",
      "Loss at step 14: 0.0008539685513824224\n",
      "Loss at step 15: 0.0008748301188461483\n",
      "Loss at step 16: 0.001017072587274015\n",
      "Loss at step 17: 0.0007570596062578261\n",
      "Loss at step 18: 0.0006414973177015781\n",
      "Loss at step 19: 0.0010113295866176486\n",
      "Loss at step 20: 0.0010003192583099008\n",
      "Loss at step 21: 0.0009860530262812972\n",
      "Loss at step 22: 0.0009532598196528852\n",
      "Loss at step 23: 0.0008630340453237295\n",
      "Loss at step 24: 0.0008028955198824406\n",
      "Loss at step 25: 0.0008793697343207896\n",
      "Loss at step 26: 0.0009252133313566446\n",
      "Loss at step 27: 0.0011322487844154239\n",
      "Loss at step 28: 0.0008490163017995656\n",
      "Loss at step 29: 0.000807258184067905\n",
      "Loss at step 30: 0.0008388738497160375\n",
      "Loss at step 31: 0.0007443611393682659\n",
      "Loss at step 32: 0.0008235358982346952\n",
      "Loss at step 33: 0.000775869470089674\n",
      "Loss at step 34: 0.0008170009241439402\n",
      "Loss at step 35: 0.0007815374992787838\n",
      "Loss at step 36: 0.0008057815721258521\n",
      "Loss at step 37: 0.0007788736838847399\n",
      "Loss at step 38: 0.0008068516617640853\n",
      "Loss at step 39: 0.000928554858546704\n",
      "Loss at step 40: 0.0009085306082852185\n",
      "Loss at step 41: 0.0008396395132876933\n",
      "Loss at step 42: 0.0006632955046370625\n",
      "Loss at step 43: 0.00091824762057513\n",
      "Loss at step 44: 0.0007438419852405787\n",
      "Loss at step 45: 0.0010688721667975187\n",
      "Loss at step 46: 0.0010702073341235518\n",
      "Loss at step 47: 0.0010992918396368623\n",
      "Loss at step 48: 0.0007272566435858607\n",
      "Loss at step 49: 0.0008794890600256622\n",
      "Loss at step 50: 0.0008132922812364995\n",
      "Loss at step 51: 0.0008089987677522004\n",
      "Loss at step 52: 0.0008599482825957239\n",
      "Loss at step 53: 0.000886440509930253\n",
      "Loss at step 54: 0.0008423131075687706\n",
      "Loss at step 55: 0.0008609950309619308\n",
      "Loss at step 56: 0.0010275723179802299\n",
      "Loss at step 57: 0.0010201380355283618\n",
      "Loss at step 58: 0.001086908159777522\n",
      "Loss at step 59: 0.0009113114210776985\n",
      "Loss at step 60: 0.0009141548653133214\n",
      "Loss at step 61: 0.0006194143206812441\n",
      "Loss at step 62: 0.0009167382377199829\n",
      "Loss at step 63: 0.0008167980122379959\n",
      "Loss at step 64: 0.0009215950849466026\n",
      "Loss at step 65: 0.0008293316350318491\n",
      "Loss at step 66: 0.0008296981686726213\n",
      "Loss at step 67: 0.0008365061949007213\n",
      "Loss at step 68: 0.001109693432226777\n",
      "Loss at step 69: 0.0010343227768316865\n",
      "Loss at step 70: 0.0010623836424201727\n",
      "Loss at step 71: 0.0010573292383924127\n",
      "Loss at step 72: 0.0008601903100498021\n",
      "Loss at step 73: 0.0008871976169757545\n",
      "Loss at step 74: 0.0009044945472851396\n",
      "Loss at step 75: 0.000850687560159713\n",
      "Loss at step 76: 0.0009290447342209518\n",
      "Loss at step 77: 0.0008751431596465409\n",
      "Loss at step 78: 0.000826043717097491\n",
      "Loss at step 79: 0.0009195143938995898\n",
      "Loss at step 80: 0.0010135238990187645\n",
      "Loss at step 81: 0.0007737708510830998\n",
      "Loss at step 82: 0.0010279578855261207\n",
      "Loss at step 83: 0.0006866116891615093\n",
      "Loss at step 84: 0.0009244391694664955\n",
      "Loss at step 85: 0.0007586043793708086\n",
      "Loss at step 86: 0.0008636271231807768\n",
      "Loss at step 87: 0.0009427617187611759\n",
      "Loss at step 88: 0.0009875096147879958\n",
      "Loss at step 89: 0.0008738727192394435\n",
      "Loss at step 90: 0.0008681161561980844\n",
      "Loss at step 91: 0.0011489030439406633\n",
      "Loss at step 92: 0.0007770285592414439\n",
      "Loss at step 93: 0.0009564583888277411\n",
      "Loss at step 94: 0.0007597451913170516\n",
      "Loss at step 95: 0.0008672312251292169\n",
      "Loss at step 96: 0.0009045271435752511\n",
      "Loss at step 97: 0.0009308010921813548\n",
      "Loss at step 98: 0.0008844908443279564\n",
      "Loss at step 99: 0.0009173997095786035\n",
      "Loss at step 100: 0.0007919202325865626\n",
      "Loss at step 101: 0.0007132014143280685\n",
      "Loss at step 102: 0.0007585129933431745\n",
      "Loss at step 103: 0.0009287092834711075\n",
      "Loss at step 104: 0.0006788134342059493\n",
      "Loss at step 105: 0.0007699144771322608\n",
      "Loss at step 106: 0.0008278724853880703\n",
      "Loss at step 107: 0.0008072689524851739\n",
      "Loss at step 108: 0.0007423557690344751\n",
      "Loss at step 109: 0.0008266764925792813\n",
      "Loss at step 110: 0.0007236385717988014\n",
      "Loss at step 111: 0.0008819470531307161\n",
      "Loss at step 112: 0.0009360414114780724\n",
      "Loss at step 113: 0.000726166064850986\n",
      "Loss at step 114: 0.0008910769247449934\n",
      "Loss at step 115: 0.0010409029200673103\n",
      "Loss at step 116: 0.0009806690504774451\n",
      "Loss at step 117: 0.0006784579600207508\n",
      "Loss at step 118: 0.0007251090719364583\n",
      "Loss at step 119: 0.0010494798189029098\n",
      "Loss at step 120: 0.00088337785564363\n",
      "Loss at step 121: 0.0008983750594779849\n",
      "Loss at step 122: 0.0009173188591375947\n",
      "Loss at step 123: 0.0009668043931014836\n",
      "Loss at step 124: 0.000852379307616502\n",
      "Loss at step 125: 0.0007707092445343733\n",
      "Loss at step 126: 0.0008525574230588973\n",
      "Loss at step 127: 0.0007078243070282042\n",
      "Loss at step 128: 0.0007966484990902245\n",
      "Loss at step 129: 0.0009459846769459546\n",
      "Loss at step 130: 0.0008332604193128645\n",
      "Loss at step 131: 0.0009520091698504984\n",
      "Loss at step 132: 0.0008040076936595142\n",
      "Loss at step 133: 0.0009311247849836946\n",
      "Loss at step 134: 0.0008886684663593769\n",
      "Loss at step 135: 0.0007440820336341858\n",
      "Loss at step 136: 0.000856383063364774\n",
      "Loss at step 137: 0.0010304319439455867\n",
      "Loss at step 138: 0.0008848695433698595\n",
      "Loss at step 139: 0.0008445474086329341\n",
      "Loss at step 140: 0.000962946331128478\n",
      "Loss at step 141: 0.0009332617046311498\n",
      "Loss at step 142: 0.0008782014483585954\n",
      "Loss at step 143: 0.0007559927180409431\n",
      "Loss at step 144: 0.0009219801286235452\n",
      "Loss at step 145: 0.0010451312409713864\n",
      "Loss at step 146: 0.0010987221030518413\n",
      "Loss at step 147: 0.0008655370329506695\n",
      "Loss at step 148: 0.0009924400364980102\n",
      "Loss at step 149: 0.0007736499537713826\n",
      "Loss at step 150: 0.0008447130676358938\n",
      "Loss at step 151: 0.0009382942225784063\n",
      "Loss at step 152: 0.0008191799861378968\n",
      "Loss at step 153: 0.0009061009041033685\n",
      "Loss at step 154: 0.0008557132678106427\n",
      "Loss at step 155: 0.0009876779513433576\n",
      "Loss at step 156: 0.0007767502684146166\n",
      "Loss at step 157: 0.0009131432743743062\n",
      "Loss at step 158: 0.0008138541015796363\n",
      "Loss at step 159: 0.000890963536221534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 160: 0.0008473183843307197\n",
      "Loss at step 161: 0.0006303490954451263\n",
      "Loss at step 162: 0.0008649596711620688\n",
      "Loss at step 163: 0.0009067008504644036\n",
      "Loss at step 164: 0.000737459515221417\n",
      "Loss at step 165: 0.0009519728482700884\n",
      "Loss at step 166: 0.0007761141750961542\n",
      "Loss at step 167: 0.0008715749718248844\n",
      "Loss at step 168: 0.0009606152889318764\n",
      "Loss at step 169: 0.000828221847768873\n",
      "Loss at step 170: 0.000955655297730118\n",
      "Loss at step 171: 0.0008405298576690257\n",
      "Loss at step 172: 0.0010432784911245108\n",
      "Loss at step 173: 0.0009360029944218695\n",
      "Loss at step 174: 0.0010711394716054201\n",
      "Loss at step 175: 0.0008978015393950045\n",
      "Loss at step 176: 0.0008644101326353848\n",
      "Loss at step 177: 0.0010269946651533246\n",
      "Loss at step 178: 0.00071511953137815\n",
      "Loss at step 179: 0.0009539340389892459\n",
      "Loss at step 180: 0.0008549714693799615\n",
      "Loss at step 181: 0.0007869598921388388\n",
      "Loss at step 182: 0.0009047365165315568\n",
      "Loss at step 183: 0.0008106246241368353\n",
      "Loss at step 184: 0.0008049866883084178\n",
      "Loss at step 185: 0.0009471249068155885\n",
      "Loss at step 186: 0.0008452162728644907\n",
      "Loss at step 187: 0.0008992656948976219\n",
      "Loss at step 188: 0.0008806200930848718\n",
      "Loss at step 189: 0.0009516882128082216\n",
      "Loss at step 190: 0.0006554723368026316\n",
      "Loss at step 191: 0.0009431613143533468\n",
      "Loss at step 192: 0.0008281003101728857\n",
      "Loss at step 193: 0.000778276240453124\n",
      "Loss at step 194: 0.0007690552738495171\n",
      "Loss at step 195: 0.0009043997852131724\n",
      "Loss at step 196: 0.0007059910567477345\n",
      "Loss at step 197: 0.0008861218811944127\n",
      "Loss at step 198: 0.0010189979802817106\n",
      "Loss at step 199: 0.0007868492393754423\n",
      "Loss at step 200: 0.0007817751611582935\n",
      "Loss at step 201: 0.0006469835643656552\n",
      "Loss at step 202: 0.0008201880846172571\n",
      "Loss at step 203: 0.0009732458274811506\n",
      "Loss at step 204: 0.0009402065770700574\n",
      "Loss at step 205: 0.0008971671340987086\n",
      "Loss at step 206: 0.0006802529678680003\n",
      "Loss at step 207: 0.0006573421414941549\n",
      "Loss at step 208: 0.0009846444008871913\n",
      "Loss at step 209: 0.0007750115473754704\n",
      "Loss at step 210: 0.001054234686307609\n",
      "Loss at step 211: 0.0008252947009168565\n",
      "Loss at step 212: 0.0007774807745590806\n",
      "Loss at step 213: 0.0008084718720056117\n",
      "Loss at step 214: 0.0007820735336281359\n",
      "Loss at step 215: 0.0006904334295541048\n",
      "Loss at step 216: 0.0008025685674510896\n",
      "Loss at step 217: 0.0010268865153193474\n",
      "Loss at step 218: 0.0009360149852000177\n",
      "Loss at step 219: 0.0008667698130011559\n",
      "Loss at step 220: 0.0010511289583519101\n",
      "Loss at step 221: 0.0008256176952272654\n",
      "Loss at step 222: 0.0006544404895976186\n",
      "Loss at step 223: 0.0009131149854511023\n",
      "Loss at step 224: 0.0008739217882975936\n",
      "Loss at step 225: 0.0008637781720608473\n",
      "Loss at step 226: 0.0007429672405123711\n",
      "Loss at step 227: 0.000899764709174633\n",
      "Loss at step 228: 0.0009165687370114028\n",
      "Loss at step 229: 0.0009390140185132623\n",
      "Loss at step 230: 0.0007494816672988236\n",
      "Loss at step 231: 0.000806097814347595\n",
      "Loss at step 232: 0.0009505021735094488\n",
      "Loss at step 233: 0.0009165406227111816\n",
      "Loss at step 234: 0.0007961772498674691\n",
      "Loss at step 235: 0.0007825795328244567\n",
      "Loss at step 236: 0.0009271501330658793\n",
      "Loss at step 237: 0.000808104348834604\n",
      "Loss at step 238: 0.0008332543075084686\n",
      "Loss at step 239: 0.000976470997557044\n",
      "Loss at step 240: 0.0008414107724092901\n",
      "Loss at step 241: 0.0008764632511883974\n",
      "Loss at step 242: 0.0007694975356571376\n",
      "Loss at step 243: 0.0008245313074439764\n",
      "Loss at step 244: 0.0007827527006156743\n",
      "Loss at step 245: 0.0008037984371185303\n",
      "Loss at step 246: 0.0008740153862163424\n",
      "Loss at step 247: 0.0006474448018707335\n",
      "Loss at step 248: 0.0009900436270982027\n",
      "Loss at step 249: 0.0009074175613932312\n",
      "Loss at step 250: 0.0008595434483140707\n",
      "Loss at step 251: 0.0009797383099794388\n",
      "Loss at step 252: 0.0008908850722946227\n",
      "Loss at step 253: 0.0008363066590391099\n",
      "Loss at step 254: 0.0008715479052625597\n",
      "Loss at step 255: 0.0009591589332558215\n",
      "Loss at step 256: 0.0008416756754741073\n",
      "Loss at step 257: 0.0007389822858385742\n",
      "Loss at step 258: 0.0008024730486795306\n",
      "Loss at step 259: 0.0010535941692069173\n",
      "Loss at step 260: 0.0008093532524071634\n",
      "Loss at step 261: 0.0009811482159420848\n",
      "Loss at step 262: 0.000875321973580867\n",
      "Loss at step 263: 0.0007871305570006371\n",
      "Loss at step 264: 0.0007881260244175792\n",
      "Loss at step 265: 0.0007929357816465199\n",
      "Loss at step 266: 0.0008394272299483418\n",
      "Loss at step 267: 0.0008719777106307447\n",
      "Loss at step 268: 0.0010664669098332524\n",
      "Loss at step 269: 0.0008957363315857947\n",
      "Loss at step 270: 0.0007893780712038279\n",
      "Loss at step 271: 0.0007611110340803862\n",
      "Loss at step 272: 0.0009519815794192255\n",
      "Loss at step 273: 0.0009346168371848762\n",
      "Loss at step 274: 0.000856271421071142\n",
      "Loss at step 275: 0.0007900691125541925\n",
      "Loss at step 276: 0.0008314895676448941\n",
      "Loss at step 277: 0.001038437825627625\n",
      "Loss at step 278: 0.0009777441155165434\n",
      "Loss at step 279: 0.0007875165902078152\n",
      "Loss at step 280: 0.0008501179399900138\n",
      "Loss at step 281: 0.0009162566857412457\n",
      "Loss at step 282: 0.000882717955391854\n",
      "Loss at step 283: 0.0007944807293824852\n",
      "Loss at step 284: 0.0007003669161349535\n",
      "Loss at step 285: 0.0007014962029643357\n",
      "Loss at step 286: 0.0007984602707438171\n",
      "Loss at step 287: 0.0007669628248549998\n",
      "Loss at step 288: 0.0008329369593411684\n",
      "Loss at step 289: 0.0006233089370653033\n",
      "Loss at step 290: 0.0008606872870586812\n",
      "Loss at step 291: 0.0008691615075804293\n",
      "Loss at step 292: 0.0009054340189322829\n",
      "Loss at step 293: 0.0006370085757225752\n",
      "Loss at step 294: 0.0009848866611719131\n",
      "Loss at step 295: 0.0007848043460398912\n",
      "Loss at step 296: 0.0008024618728086352\n",
      "Loss at step 297: 0.0009401183924637735\n",
      "Loss at step 298: 0.0009800049010664225\n",
      "Loss at step 299: 0.0007664937875233591\n",
      "Loss at step 300: 0.0009768994059413671\n",
      "Loss at step 301: 0.0006299075903370976\n",
      "Loss at step 302: 0.0010229251347482204\n",
      "Loss at step 303: 0.0007540890946984291\n",
      "Loss at step 304: 0.0009000740246847272\n",
      "Loss at step 305: 0.0007875634473748505\n",
      "Loss at step 306: 0.0007505960529670119\n",
      "Loss at step 307: 0.0007380444440059364\n",
      "Loss at step 308: 0.0009637195034883916\n",
      "Loss at step 309: 0.0009092016844078898\n",
      "Loss at step 310: 0.0007851439295336604\n",
      "Loss at step 311: 0.0008411887683905661\n",
      "Loss at step 312: 0.0006416956312023103\n",
      "Loss at step 313: 0.0009825576562434435\n",
      "Loss at step 314: 0.0008090967312455177\n",
      "Loss at step 315: 0.0008606174378655851\n",
      "Loss at step 316: 0.0008354946039617062\n",
      "Loss at step 317: 0.0011576809920370579\n",
      "Loss at step 318: 0.0007446830859407783\n",
      "Loss at step 319: 0.0011372981825843453\n",
      "Loss at step 320: 0.0009159542387351394\n",
      "Loss at step 321: 0.0008251720573753119\n",
      "Loss at step 322: 0.0007856455631554127\n",
      "Loss at step 323: 0.0007606571889482439\n",
      "Loss at step 324: 0.0008486874867230654\n",
      "Loss at step 325: 0.0008598066051490605\n",
      "Loss at step 326: 0.0009711660095490515\n",
      "Loss at step 327: 0.0009928152430802584\n",
      "Loss at step 328: 0.0008004490518942475\n",
      "Loss at step 329: 0.000922531820833683\n",
      "Loss at step 330: 0.0009069421794265509\n",
      "Loss at step 331: 0.0011658896692097187\n",
      "Loss at step 332: 0.0009657481568865478\n",
      "Loss at step 333: 0.0009733574697747827\n",
      "Loss at step 334: 0.000988928833976388\n",
      "Loss at step 335: 0.0009220094652846456\n",
      "Loss at step 336: 0.0009999785106629133\n",
      "Loss at step 337: 0.0009130077669396996\n",
      "Loss at step 338: 0.0007887750398367643\n",
      "Loss at step 339: 0.0008843268733471632\n",
      "Loss at step 340: 0.0009263147949241102\n",
      "Loss at step 341: 0.0007722949958406389\n",
      "Loss at step 342: 0.0008480990654788911\n",
      "Loss at step 343: 0.0005314279114827514\n",
      "Loss at step 344: 0.0008004326955415308\n",
      "Loss at step 345: 0.0008644078625366092\n",
      "Loss at step 346: 0.0005962435388937593\n",
      "Loss at step 347: 0.00100474723149091\n",
      "Loss at step 348: 0.0010373671539127827\n",
      "Loss at step 349: 0.0007586278370581567\n",
      "Loss at step 350: 0.0008333578007295728\n",
      "Loss at step 351: 0.000802675262093544\n",
      "Loss at step 352: 0.0008826124249026179\n",
      "Loss at step 353: 0.000768639671150595\n",
      "Loss at step 354: 0.0008809823193587363\n",
      "Loss at step 355: 0.0007885241066105664\n",
      "Loss at step 356: 0.0008426608401350677\n",
      "Loss at step 357: 0.0009282819228246808\n",
      "Loss at step 358: 0.001049300655722618\n",
      "Loss at step 359: 0.000863847613800317\n",
      "Loss at step 360: 0.0008363223751075566\n",
      "Loss at step 361: 0.0008922921842895448\n",
      "Loss at step 362: 0.0008915677317418158\n",
      "Loss at step 363: 0.0010333969257771969\n",
      "Loss at step 364: 0.0006402899161912501\n",
      "Loss at step 365: 0.0007581294048577547\n",
      "Loss at step 366: 0.0007032367866486311\n",
      "Loss at step 367: 0.0008459486998617649\n",
      "Loss at step 368: 0.0007290767389349639\n",
      "Loss at step 369: 0.0009542854968458414\n",
      "Loss at step 370: 0.0007590847671963274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 371: 0.0008367439149878919\n",
      "Loss at step 372: 0.00090679811546579\n",
      "Loss at step 373: 0.000586983107496053\n",
      "Loss at step 374: 0.0008081139530986547\n",
      "Loss at step 375: 0.000841677887365222\n",
      "Loss at step 376: 0.0010044912341982126\n",
      "Loss at step 377: 0.000863925670273602\n",
      "Loss at step 378: 0.0008634283440187573\n",
      "Loss at step 379: 0.0008498394745402038\n",
      "Loss at step 380: 0.0009354325593449175\n",
      "Loss at step 381: 0.0008318162872456014\n",
      "Loss at step 382: 0.0009187009418383241\n",
      "Loss at step 383: 0.0007121457019820809\n",
      "Loss at step 384: 0.000568506249692291\n",
      "Loss at step 385: 0.0007423026254400611\n",
      "Loss at step 386: 0.0009268195717595518\n",
      "Loss at step 387: 0.0007041957578621805\n",
      "Loss at step 388: 0.000938412849791348\n",
      "Loss at step 389: 0.000871470314450562\n",
      "Loss at step 390: 0.0007180137909017503\n",
      "Loss at step 391: 0.0010920428903773427\n",
      "Loss at step 392: 0.0007172386394813657\n",
      "Loss at step 393: 0.000837375526316464\n",
      "Loss at step 394: 0.0009245090768672526\n",
      "Loss at step 395: 0.0009316056384705007\n",
      "Loss at step 396: 0.0007379837916232646\n",
      "Loss at step 397: 0.0009593309368938208\n",
      "Loss at step 398: 0.0008063080604188144\n",
      "Loss at step 399: 0.0010501942597329617\n",
      "Loss at step 400: 0.0007834616117179394\n",
      "Loss at step 401: 0.0007896292372606695\n",
      "Loss at step 402: 0.0006282757967710495\n",
      "Loss at step 403: 0.0009247796842828393\n",
      "Loss at step 404: 0.0008440379751846194\n",
      "Loss at step 405: 0.0006312139448709786\n",
      "Loss at step 406: 0.0008591532241553068\n",
      "Loss at step 407: 0.0009591069538146257\n",
      "Loss at step 408: 0.0008801702642813325\n",
      "Loss at step 409: 0.000861865992192179\n",
      "Loss at step 410: 0.0011864954140037298\n",
      "Loss at step 411: 0.0008025337010622025\n",
      "Loss at step 412: 0.000647109467536211\n",
      "Loss at step 413: 0.001016913796775043\n",
      "Loss at step 414: 0.0008338132174685597\n",
      "Loss at step 415: 0.0007167588919401169\n",
      "Loss at step 416: 0.0009668393176980317\n",
      "Loss at step 417: 0.0008652909309603274\n",
      "Loss at step 418: 0.0007908231345936656\n",
      "Loss at step 419: 0.0008820734219625592\n",
      "Loss at step 420: 0.0008704413776285946\n",
      "Loss at step 421: 0.0008692273404449224\n",
      "Loss at step 422: 0.0008785752579569817\n",
      "Loss at step 423: 0.0008526269812136889\n",
      "Loss at step 424: 0.0007995438645593822\n",
      "Loss at step 425: 0.0009236757177859545\n",
      "Loss at step 426: 0.0008882175898179412\n",
      "Loss at step 427: 0.0008020131499506533\n",
      "Loss at step 428: 0.0006680276128463447\n",
      "Loss at step 429: 0.000682373414747417\n",
      "Loss at step 430: 0.0008820235962048173\n",
      "Loss at step 431: 0.0009046707418747246\n",
      "Loss at step 432: 0.0007971867453306913\n",
      "Loss at step 433: 0.0010562035022303462\n",
      "Loss at step 434: 0.0007949128630571067\n",
      "Loss at step 435: 0.0008855717023834586\n",
      "Loss at step 436: 0.0009561289916746318\n",
      "Loss at step 437: 0.000870981952175498\n",
      "Loss at step 438: 0.0005630672094412148\n",
      "Loss at step 439: 0.000761882052756846\n",
      "Loss at step 440: 0.0008862121612764895\n",
      "Loss at step 441: 0.0007981533999554813\n",
      "Loss at step 442: 0.0010156059870496392\n",
      "Loss at step 443: 0.0007901136996224523\n",
      "Loss at step 444: 0.0008784278761595488\n",
      "Loss at step 445: 0.000876885955221951\n",
      "Loss at step 446: 0.0009173689177259803\n",
      "Loss at step 447: 0.0008552831131964922\n",
      "Loss at step 448: 0.0008015071507543325\n",
      "Loss at step 449: 0.0009278515935875475\n",
      "Loss at step 450: 0.0008003003313206136\n",
      "Loss at step 451: 0.0008458252414129674\n",
      "Loss at step 452: 0.0008936363155953586\n",
      "Loss at step 453: 0.0006633069133386016\n",
      "Loss at step 454: 0.0007421706686727703\n",
      "Loss at step 455: 0.0006833100342191756\n",
      "Loss at step 456: 0.0006838871049694717\n",
      "Loss at step 457: 0.0008333250880241394\n",
      "Loss at step 458: 0.0008066982845775783\n",
      "Loss at step 459: 0.0007075353059917688\n",
      "Loss at step 460: 0.0008839776855893433\n",
      "Loss at step 461: 0.0009744829731062055\n",
      "Loss at step 462: 0.00086894107516855\n",
      "Loss at step 463: 0.0009163429494947195\n",
      "Loss at step 464: 0.0007106265984475613\n",
      "Loss at step 465: 0.00089078868040815\n",
      "Loss at step 466: 0.0007304620230570436\n",
      "Loss at step 467: 0.0012058475986123085\n",
      "Loss at step 468: 0.0009037508280016482\n",
      "Loss at step 469: 0.0006832758081145585\n",
      "Loss at step 470: 0.0006475405534729362\n",
      "Loss at step 471: 0.0008309149416163564\n",
      "Loss at step 472: 0.0007091917796060443\n",
      "Loss at step 473: 0.0008155428222380579\n",
      "Loss at step 474: 0.0008947319583967328\n",
      "Loss at step 475: 0.0007649516337551177\n",
      "Loss at step 476: 0.0009191680001094937\n",
      "Loss at step 477: 0.000813048507552594\n",
      "Loss at step 478: 0.0008439731318503618\n",
      "Loss at step 479: 0.000687736552208662\n",
      "Loss at step 480: 0.0007777444552630186\n",
      "Loss at step 481: 0.0009353997302241623\n",
      "Loss at step 482: 0.0008547545876353979\n",
      "Loss at step 483: 0.0007490253774449229\n",
      "Loss at step 484: 0.0008065458387136459\n",
      "Loss at step 485: 0.0010436956072226167\n",
      "Loss at step 486: 0.0009893729584291577\n",
      "Loss at step 487: 0.0009832601062953472\n",
      "Loss at step 488: 0.0009257529163733125\n",
      "Loss at step 489: 0.000845116563141346\n",
      "Loss at step 490: 0.000760229944717139\n",
      "Loss at step 491: 0.0006953190313652158\n",
      "Loss at step 492: 0.000833455182146281\n",
      "Loss at step 493: 0.0009247537236660719\n",
      "Loss at step 494: 0.0009779466781765223\n",
      "Loss at step 495: 0.0006886541959829628\n",
      "Loss at step 496: 0.0009173725266009569\n",
      "Loss at step 497: 0.0010035918094217777\n",
      "Loss at step 498: 0.0007232501520775259\n",
      "Loss at step 499: 0.0007716983091086149\n",
      "Loss at step 500: 0.0009274226031266153\n",
      "Loss at step 501: 0.0010285635944455862\n",
      "Loss at step 502: 0.0008788631530478597\n",
      "Loss at step 503: 0.0008404642576351762\n",
      "Loss at step 504: 0.0007507196860387921\n",
      "Loss at step 505: 0.0009264719556085765\n",
      "Loss at step 506: 0.0008538434631191194\n",
      "Loss at step 507: 0.0010027445387095213\n",
      "Loss at step 508: 0.0009516279678791761\n",
      "Loss at step 509: 0.0006344959256239235\n",
      "Loss at step 510: 0.0009447990451008081\n",
      "Loss at step 511: 0.0007772664539515972\n",
      "Loss at step 512: 0.0008652396500110626\n",
      "Loss at step 513: 0.0008541012648493052\n",
      "Loss at step 514: 0.0009164701914414763\n",
      "Loss at step 515: 0.0009953791741281748\n",
      "Loss at step 516: 0.0009072392131201923\n",
      "Loss at step 517: 0.0009741515968926251\n",
      "Loss at step 518: 0.0008121903520077467\n",
      "Loss at step 519: 0.0007995233172550797\n",
      "Loss at step 520: 0.0010226776357740164\n",
      "Loss at step 521: 0.0009324396378360689\n",
      "Loss at step 522: 0.0008340838248841465\n",
      "Loss at step 523: 0.0008289545075967908\n",
      "Loss at step 524: 0.0008771726279519498\n",
      "Loss at step 525: 0.0007692930521443486\n",
      "Loss at step 526: 0.0010315903928130865\n",
      "Loss at step 527: 0.0008180105942301452\n",
      "Loss at step 528: 0.0008658175356686115\n",
      "Loss at step 529: 0.0006524333730340004\n",
      "Loss at step 530: 0.0009427842451259494\n",
      "Loss at step 531: 0.000987698440439999\n",
      "Loss at step 532: 0.0009147466626018286\n",
      "Loss at step 533: 0.0006890846416354179\n",
      "Loss at step 534: 0.0008002221584320068\n",
      "Loss at step 535: 0.0007838402525521815\n",
      "Loss at step 536: 0.0008518783724866807\n",
      "Loss at step 537: 0.0008756445604376495\n",
      "Loss at step 538: 0.0009878634009510279\n",
      "Loss at step 539: 0.0009065823978744447\n",
      "Loss at step 540: 0.0006544556235894561\n",
      "Loss at step 541: 0.001022412907332182\n",
      "Loss at step 542: 0.0008685999782755971\n",
      "Loss at step 543: 0.0007526776171289384\n",
      "Loss at step 544: 0.0009564083884470165\n",
      "Loss at step 545: 0.0007386605138890445\n",
      "Loss at step 546: 0.0008975759265013039\n",
      "Loss at step 547: 0.0007850367692299187\n",
      "Loss at step 548: 0.001121251261793077\n",
      "Loss at step 549: 0.0008148155175149441\n",
      "Loss at step 550: 0.0010040285997092724\n",
      "Loss at step 551: 0.0010245704324916005\n",
      "Loss at step 552: 0.000766257056966424\n",
      "Loss at step 553: 0.0008266568765975535\n",
      "Loss at step 554: 0.0007140224915929139\n",
      "Loss at step 555: 0.0009947990765795112\n",
      "Loss at step 556: 0.0006435381365008652\n",
      "Loss at step 557: 0.0009025879553519189\n",
      "Loss at step 558: 0.000954804418142885\n",
      "Loss at step 559: 0.0006233542808331549\n",
      "Loss at step 560: 0.0009384279837831855\n",
      "Loss at step 561: 0.0008425883715972304\n",
      "Loss at step 562: 0.0008754263981245458\n",
      "Loss at step 563: 0.0009853994706645608\n",
      "Loss at step 564: 0.0008943401626311243\n",
      "Loss at step 565: 0.0010496167233213782\n",
      "Loss at step 566: 0.0008689613896422088\n",
      "Loss at step 567: 0.000847106333822012\n",
      "Loss at step 568: 0.0009074965491890907\n",
      "Loss at step 569: 0.0008584679453633726\n",
      "Loss at step 570: 0.0009155003353953362\n",
      "Loss at step 571: 0.0007048333063721657\n",
      "Loss at step 572: 0.0007406054064631462\n",
      "Loss at step 573: 0.0009076434071175754\n",
      "Loss at step 574: 0.0007535706972703338\n",
      "Loss at step 575: 0.0007987146964296699\n",
      "Loss at step 576: 0.0007989693549461663\n",
      "Loss at step 577: 0.000756696390453726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 578: 0.0008608102798461914\n",
      "Loss at step 579: 0.0009726190473884344\n",
      "Loss at step 580: 0.0008596273837611079\n",
      "Loss at step 581: 0.0006526983925141394\n",
      "Loss at step 582: 0.0009506053756922483\n",
      "Loss at step 583: 0.000999945099465549\n",
      "Loss at step 584: 0.0008339427295140922\n",
      "Loss at step 585: 0.0007706060423515737\n",
      "Loss at step 586: 0.0007387095829471946\n",
      "Loss at step 587: 0.0009163767681457102\n",
      "Loss at step 588: 0.0007916286122053862\n",
      "Loss at step 589: 0.0007468331605195999\n",
      "Loss at step 590: 0.0008667203946970403\n",
      "Loss at step 591: 0.0008013081969693303\n",
      "Loss at step 592: 0.0008015562198124826\n",
      "Loss at step 593: 0.0009102409239858389\n",
      "Loss at step 594: 0.0008620668086223304\n",
      "Loss at step 595: 0.0008988440386019647\n",
      "Loss at step 596: 0.0007707778131589293\n",
      "Loss at step 597: 0.0007991131860762835\n",
      "Loss at step 598: 0.0007478364859707654\n",
      "Loss at step 599: 0.0007946824189275503\n",
      "Loss at step 600: 0.0008039256790652871\n",
      "Loss at step 601: 0.0009227900882251561\n",
      "Loss at step 602: 0.0007874761940911412\n",
      "Loss at step 603: 0.0008074592333287001\n",
      "Loss at step 604: 0.000955867872107774\n",
      "Loss at step 605: 0.0008966932655312121\n",
      "Loss at step 606: 0.0009591442067176104\n",
      "Loss at step 607: 0.0007319847354665399\n",
      "Loss at step 608: 0.000971996400039643\n",
      "Loss at step 609: 0.0008545048767700791\n",
      "Loss at step 610: 0.0008017699001356959\n",
      "Loss at step 611: 0.0008493616478517652\n",
      "Loss at step 612: 0.0008234050474129617\n",
      "Loss at step 613: 0.0007745209150016308\n",
      "Loss at step 614: 0.000661166908685118\n",
      "Loss at step 615: 0.0007052265573292971\n",
      "Loss at step 616: 0.0007294239476323128\n",
      "Loss at step 617: 0.0008555451058782637\n",
      "Loss at step 618: 0.0008109987829811871\n",
      "Loss at step 619: 0.0006192115833982825\n",
      "Loss at step 620: 0.0008494280045852065\n",
      "Loss at step 621: 0.0011475580977275968\n",
      "Loss at step 622: 0.0009199572959914804\n",
      "Loss at step 623: 0.0007160985842347145\n",
      "Loss at step 624: 0.0007837582961656153\n",
      "Loss at step 625: 0.0009473113459534943\n",
      "Loss at step 626: 0.000764417985919863\n",
      "Loss at step 627: 0.000757983943913132\n",
      "Loss at step 628: 0.0008786373655311763\n",
      "Loss at step 629: 0.0008647288777865469\n",
      "Loss at step 630: 0.0008738138130865991\n",
      "Loss at step 631: 0.0007251991773955524\n",
      "Loss at step 632: 0.0008998272242024541\n",
      "Loss at step 633: 0.0007691837381571531\n",
      "Loss at step 634: 0.00093319162260741\n",
      "Loss at step 635: 0.001009354367852211\n",
      "Loss at step 636: 0.0008549988851882517\n",
      "Loss at step 637: 0.0008707464439794421\n",
      "Loss at step 638: 0.0009897660929709673\n",
      "Loss at step 639: 0.0008554138476029038\n",
      "Loss at step 640: 0.0007683189469389617\n",
      "Loss at step 641: 0.000756136083509773\n",
      "Loss at step 642: 0.0006937875878065825\n",
      "Loss at step 643: 0.001086824806407094\n",
      "Loss at step 644: 0.0009126748191192746\n",
      "Loss at step 645: 0.001014342182315886\n",
      "Loss at step 646: 0.0008464109851047397\n",
      "Loss at step 647: 0.0006998854223638773\n",
      "Loss at step 648: 0.0008468580199405551\n",
      "Loss at step 649: 0.0006673792377114296\n",
      "Loss at step 650: 0.0007449036347679794\n",
      "Loss at step 651: 0.0008359884959645569\n",
      "Loss at step 652: 0.0008025465649552643\n",
      "Loss at step 653: 0.0010201920522376895\n",
      "Loss at step 654: 0.0007888335385359824\n",
      "Loss at step 655: 0.0007309892680495977\n",
      "Loss at step 656: 0.0010009208926931024\n",
      "Loss at step 657: 0.0008318739710375667\n",
      "Loss at step 658: 0.000939244288019836\n",
      "Loss at step 659: 0.0010527969570830464\n",
      "Loss at step 660: 0.0009384917211718857\n",
      "Loss at step 661: 0.000746402598451823\n",
      "Loss at step 662: 0.0007342125754803419\n",
      "Loss at step 663: 0.0008913411875255406\n",
      "Loss at step 664: 0.0009878341807052493\n",
      "Loss at step 665: 0.0008659060113132\n",
      "Loss at step 666: 0.0007591787725687027\n",
      "Loss at step 667: 0.0008596229017712176\n",
      "Loss at step 668: 0.0007908471743576229\n",
      "Loss at step 669: 0.0007319020805880427\n",
      "Loss at step 670: 0.0009568615932948887\n",
      "Loss at step 671: 0.0007633784553036094\n",
      "Loss at step 672: 0.0009905571350827813\n",
      "Loss at step 673: 0.0007733036181889474\n",
      "Loss at step 674: 0.0006150109693408012\n",
      "Loss at step 675: 0.0008842625538818538\n",
      "Loss at step 676: 0.0008638145518489182\n",
      "Loss at step 677: 0.0009205808746628463\n",
      "Loss at step 678: 0.0009795927908271551\n",
      "Loss at step 679: 0.000939410412684083\n",
      "Loss at step 680: 0.000810804427601397\n",
      "Loss at step 681: 0.0009374700020998716\n",
      "Loss at step 682: 0.0008928938186727464\n",
      "Loss at step 683: 0.0008415183983743191\n",
      "Loss at step 684: 0.0007193143246695399\n",
      "Loss at step 685: 0.0008584429160691798\n",
      "Loss at step 686: 0.0008930892217904329\n",
      "Loss at step 687: 0.0008302179048769176\n",
      "Loss at step 688: 0.001053708023391664\n",
      "Loss at step 689: 0.000854790210723877\n",
      "Loss at step 690: 0.0008167106425389647\n",
      "Loss at step 691: 0.000754573498852551\n",
      "Loss at step 692: 0.0007658216054551303\n",
      "Loss at step 693: 0.0008824655087664723\n",
      "Loss at step 694: 0.00078506552381441\n",
      "Loss at step 695: 0.0009370315819978714\n",
      "Loss at step 696: 0.0008662060718052089\n",
      "Loss at step 697: 0.0007804609485901892\n",
      "Loss at step 698: 0.0008768495754338801\n",
      "Loss at step 699: 0.0010476324241608381\n",
      "Loss at step 700: 0.0009266780689358711\n",
      "Loss at step 701: 0.0008235613349825144\n",
      "Loss at step 702: 0.0008814616594463587\n",
      "Loss at step 703: 0.0007151452009566128\n",
      "Loss at step 704: 0.000700517906807363\n",
      "Loss at step 705: 0.0008386221015825868\n",
      "train Loss: 0.0009\n",
      "Loss at step 0: 0.0009001544094644487\n",
      "Loss at step 1: 0.000709114596247673\n",
      "Loss at step 2: 0.0010416381992399693\n",
      "Loss at step 3: 0.0006741605466231704\n",
      "Loss at step 4: 0.0008021316607482731\n",
      "Loss at step 5: 0.0006805615848861635\n",
      "Loss at step 6: 0.0008810686995275319\n",
      "Loss at step 7: 0.000976044568233192\n",
      "Loss at step 8: 0.0009305396815761924\n",
      "Loss at step 9: 0.0008463083067908883\n",
      "Loss at step 10: 0.0008834376349113882\n",
      "Loss at step 11: 0.0006070370436646044\n",
      "Loss at step 12: 0.0008374201715923846\n",
      "Loss at step 13: 0.0010214275680482388\n",
      "Loss at step 14: 0.0008624489419162273\n",
      "Loss at step 15: 0.0008188540232367814\n",
      "Loss at step 16: 0.0009476667619310319\n",
      "Loss at step 17: 0.0009541537729091942\n",
      "Loss at step 18: 0.0009139672038145363\n",
      "Loss at step 19: 0.0007782919565215707\n",
      "Loss at step 20: 0.0008635760168544948\n",
      "Loss at step 21: 0.0010152497561648488\n",
      "Loss at step 22: 0.00078627560287714\n",
      "Loss at step 23: 0.0007530142902396619\n",
      "Loss at step 24: 0.0008284447831101716\n",
      "Loss at step 25: 0.0009290697053074837\n",
      "Loss at step 26: 0.0007587674190290272\n",
      "Loss at step 27: 0.0008591233636252582\n",
      "Loss at step 28: 0.0007938690832816064\n",
      "Loss at step 29: 0.00112102588173002\n",
      "Loss at step 30: 0.0009117349982261658\n",
      "Loss at step 31: 0.0010578904766589403\n",
      "Loss at step 32: 0.0010131910676136613\n",
      "Loss at step 33: 0.0007498512859456241\n",
      "Loss at step 34: 0.0008818879723548889\n",
      "Loss at step 35: 0.0007726339972577989\n",
      "Loss at step 36: 0.000854976533446461\n",
      "Loss at step 37: 0.0009517429862171412\n",
      "Loss at step 38: 0.0006231417646631598\n",
      "Loss at step 39: 0.000681488832924515\n",
      "Loss at step 40: 0.0007437557214871049\n",
      "Loss at step 41: 0.0007378075970336795\n",
      "Loss at step 42: 0.0009016328258439898\n",
      "Loss at step 43: 0.0008775692549534142\n",
      "Loss at step 44: 0.0007591168396174908\n",
      "Loss at step 45: 0.0008419232908636332\n",
      "Loss at step 46: 0.0009043083991855383\n",
      "Loss at step 47: 0.0008921981207095087\n",
      "Loss at step 48: 0.0010289218043908477\n",
      "Loss at step 49: 0.0008597320993430912\n",
      "Loss at step 50: 0.0009214490419253707\n",
      "Loss at step 51: 0.000840712629724294\n",
      "Loss at step 52: 0.00092765421140939\n",
      "Loss at step 53: 0.0010285302996635437\n",
      "Loss at step 54: 0.0008400074439123273\n",
      "Loss at step 55: 0.0008062581764534116\n",
      "Loss at step 56: 0.0008964271401055157\n",
      "Loss at step 57: 0.0008837849600240588\n",
      "Loss at step 58: 0.0007546267006546259\n",
      "Loss at step 59: 0.0008391167502850294\n",
      "Loss at step 60: 0.0007406481308862567\n",
      "Loss at step 61: 0.0010369614465162158\n",
      "Loss at step 62: 0.0009579412871971726\n",
      "Loss at step 63: 0.0007573803886771202\n",
      "Loss at step 64: 0.0008276466396637261\n",
      "Loss at step 65: 0.0008005421259440482\n",
      "Loss at step 66: 0.0009252793388441205\n",
      "Loss at step 67: 0.0008059166721068323\n",
      "Loss at step 68: 0.0009721906390041113\n",
      "Loss at step 69: 0.0009896167321130633\n",
      "Loss at step 70: 0.0008316825842484832\n",
      "Loss at step 71: 0.0008623023168183863\n",
      "Loss at step 72: 0.0007971011800691485\n",
      "Loss at step 73: 0.0009521812316961586\n",
      "Loss at step 74: 0.000939037767238915\n",
      "Loss at step 75: 0.0007603667327202857\n",
      "Loss at step 76: 0.0008125777821987867\n",
      "Loss at step 77: 0.0008813384338282049\n",
      "Loss at step 78: 0.0008991201757453382\n",
      "Loss at step 79: 0.0006520145107060671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 80: 0.0007903002551756799\n",
      "Loss at step 81: 0.000819592853076756\n",
      "Loss at step 82: 0.000953933282289654\n",
      "Loss at step 83: 0.0008244321215897799\n",
      "Loss at step 84: 0.0008053929777815938\n",
      "Loss at step 85: 0.0005206860369071364\n",
      "Loss at step 86: 0.0009076662827283144\n",
      "Loss at step 87: 0.000995430862531066\n",
      "Loss at step 88: 0.0008275422733277082\n",
      "Loss at step 89: 0.000667685060761869\n",
      "Loss at step 90: 0.0008407052955590189\n",
      "Loss at step 91: 0.0009174335282295942\n",
      "Loss at step 92: 0.0008057273225858808\n",
      "Loss at step 93: 0.0007107248529791832\n",
      "Loss at step 94: 0.0007762368768453598\n",
      "Loss at step 95: 0.00092848896747455\n",
      "Loss at step 96: 0.0010830869432538748\n",
      "Loss at step 97: 0.0010416406439617276\n",
      "Loss at step 98: 0.0007146043353714049\n",
      "Loss at step 99: 0.0007547707064077258\n",
      "Loss at step 100: 0.0009974607964977622\n",
      "Loss at step 101: 0.0007207820890471339\n",
      "Loss at step 102: 0.0008458059164695442\n",
      "Loss at step 103: 0.0007906848913989961\n",
      "Loss at step 104: 0.0008010865421965718\n",
      "Loss at step 105: 0.0007224644650705159\n",
      "Loss at step 106: 0.0006921330350451171\n",
      "Loss at step 107: 0.0010582415852695704\n",
      "Loss at step 108: 0.0007363632321357727\n",
      "Loss at step 109: 0.0008372729062102735\n",
      "Loss at step 110: 0.001053215586580336\n",
      "Loss at step 111: 0.0010394807904958725\n",
      "Loss at step 112: 0.0008214000263251364\n",
      "Loss at step 113: 0.0009723040857352316\n",
      "Loss at step 114: 0.0008448271546512842\n",
      "Loss at step 115: 0.0007290294743143022\n",
      "Loss at step 116: 0.0007292559603229165\n",
      "Loss at step 117: 0.0009229732095263898\n",
      "Loss at step 118: 0.0007528694113716483\n",
      "Loss at step 119: 0.0009967227233573794\n",
      "Loss at step 120: 0.0009243442909792066\n",
      "Loss at step 121: 0.0008280278998427093\n",
      "Loss at step 122: 0.0008925888105295599\n",
      "Loss at step 123: 0.0008246467914432287\n",
      "Loss at step 124: 0.0008177165873348713\n",
      "Loss at step 125: 0.0007330304360948503\n",
      "Loss at step 126: 0.0008019778179004788\n",
      "Loss at step 127: 0.0009417220717296004\n",
      "Loss at step 128: 0.0008956692181527615\n",
      "Loss at step 129: 0.00107763207051903\n",
      "Loss at step 130: 0.0005494524957612157\n",
      "Loss at step 131: 0.0007589476299472153\n",
      "Loss at step 132: 0.0008926766458898783\n",
      "Loss at step 133: 0.0010143355466425419\n",
      "Loss at step 134: 0.0009337258525192738\n",
      "Loss at step 135: 0.0008445614948868752\n",
      "Loss at step 136: 0.0009406562894582748\n",
      "Loss at step 137: 0.000773414212744683\n",
      "Loss at step 138: 0.0006819454138167202\n",
      "Loss at step 139: 0.0007478053448721766\n",
      "Loss at step 140: 0.0007012650603428483\n",
      "Loss at step 141: 0.0008288073586300015\n",
      "Loss at step 142: 0.0009063934558071196\n",
      "Loss at step 143: 0.000854726240504533\n",
      "Loss at step 144: 0.0009130096877925098\n",
      "Loss at step 145: 0.0008280485635623336\n",
      "Loss at step 146: 0.0009717719512991607\n",
      "Loss at step 147: 0.0010503638768568635\n",
      "Loss at step 148: 0.0007566070999018848\n",
      "Loss at step 149: 0.0009487908100709319\n",
      "Loss at step 150: 0.0009850494097918272\n",
      "Loss at step 151: 0.0007933423039503396\n",
      "Loss at step 152: 0.0010115591576322913\n",
      "Loss at step 153: 0.0007113501778803766\n",
      "Loss at step 154: 0.0006965880747884512\n",
      "Loss at step 155: 0.001175683573819697\n",
      "Loss at step 156: 0.0008349807467311621\n",
      "Loss at step 157: 0.0008301780908368528\n",
      "Loss at step 158: 0.0010454761795699596\n",
      "Loss at step 159: 0.0008840414229780436\n",
      "Loss at step 160: 0.0009055235423147678\n",
      "Loss at step 161: 0.0008940456318669021\n",
      "Loss at step 162: 0.0009122557239606977\n",
      "Loss at step 163: 0.0007878168835304677\n",
      "Loss at step 164: 0.0009424258605577052\n",
      "Loss at step 165: 0.001003833138383925\n",
      "Loss at step 166: 0.0008860047673806548\n",
      "Loss at step 167: 0.0008661353494971991\n",
      "Loss at step 168: 0.0009126602672040462\n",
      "Loss at step 169: 0.0009068843792192638\n",
      "Loss at step 170: 0.0007379312301054597\n",
      "Loss at step 171: 0.0007600120734423399\n",
      "Loss at step 172: 0.0007601112010888755\n",
      "Loss at step 173: 0.0008388733840547502\n",
      "Loss at step 174: 0.0008544005686417222\n",
      "Loss at step 175: 0.0007901617209427059\n",
      "Loss at step 176: 0.0009409416816197336\n",
      "val Loss: 0.0009\n",
      "Epoch 2/4\n",
      "----------\n",
      "Loss at step 0: 0.0008192440727725625\n",
      "Loss at step 1: 0.0008814780740067363\n",
      "Loss at step 2: 0.0007356019341386855\n",
      "Loss at step 3: 0.0011282141786068678\n",
      "Loss at step 4: 0.000882082327734679\n",
      "Loss at step 5: 0.0007437987369485199\n",
      "Loss at step 6: 0.0008932993514463305\n",
      "Loss at step 7: 0.0009275206830352545\n",
      "Loss at step 8: 0.0009029492503032088\n",
      "Loss at step 9: 0.0007572041358798742\n",
      "Loss at step 10: 0.0009461977169848979\n",
      "Loss at step 11: 0.0008260413887910545\n",
      "Loss at step 12: 0.0008041779510676861\n",
      "Loss at step 13: 0.0008092029020190239\n",
      "Loss at step 14: 0.0008961515268310905\n",
      "Loss at step 15: 0.0008656725403852761\n",
      "Loss at step 16: 0.0008597664418630302\n",
      "Loss at step 17: 0.0008580604917369783\n",
      "Loss at step 18: 0.0008073934004642069\n",
      "Loss at step 19: 0.0007750768563710153\n",
      "Loss at step 20: 0.0007765627815388143\n",
      "Loss at step 21: 0.0006731734611093998\n",
      "Loss at step 22: 0.000817831780295819\n",
      "Loss at step 23: 0.0008764484082348645\n",
      "Loss at step 24: 0.000812859449069947\n",
      "Loss at step 25: 0.0007765826885588467\n",
      "Loss at step 26: 0.0007709685596637428\n",
      "Loss at step 27: 0.0007595719071105123\n",
      "Loss at step 28: 0.0007838763995096087\n",
      "Loss at step 29: 0.000735327135771513\n",
      "Loss at step 30: 0.0007400978356599808\n",
      "Loss at step 31: 0.000894523982424289\n",
      "Loss at step 32: 0.0007703171577304602\n",
      "Loss at step 33: 0.0008834016625769436\n",
      "Loss at step 34: 0.000832190562505275\n",
      "Loss at step 35: 0.0007472841534763575\n",
      "Loss at step 36: 0.0007746791816316545\n",
      "Loss at step 37: 0.0009751941543072462\n",
      "Loss at step 38: 0.0006956164143048227\n",
      "Loss at step 39: 0.0007954962202347815\n",
      "Loss at step 40: 0.0007510537980124354\n",
      "Loss at step 41: 0.0009410592028871179\n",
      "Loss at step 42: 0.0008622159366495907\n",
      "Loss at step 43: 0.000878285092767328\n",
      "Loss at step 44: 0.0008542508585378528\n",
      "Loss at step 45: 0.0010032851714640856\n",
      "Loss at step 46: 0.0006594585720449686\n",
      "Loss at step 47: 0.0010711707873269916\n",
      "Loss at step 48: 0.0009198556654155254\n",
      "Loss at step 49: 0.0008567674667574465\n",
      "Loss at step 50: 0.0009171477286145091\n",
      "Loss at step 51: 0.0008573809172958136\n",
      "Loss at step 52: 0.0009098289301618934\n",
      "Loss at step 53: 0.0008485224680043757\n",
      "Loss at step 54: 0.0008802989614196122\n",
      "Loss at step 55: 0.0009213594603352249\n",
      "Loss at step 56: 0.000942898856010288\n",
      "Loss at step 57: 0.0008287026430480182\n",
      "Loss at step 58: 0.0008399873622693121\n",
      "Loss at step 59: 0.0009800492553040385\n",
      "Loss at step 60: 0.000743938609957695\n",
      "Loss at step 61: 0.0007401492912322283\n",
      "Loss at step 62: 0.0009283161489292979\n",
      "Loss at step 63: 0.0008142568403854966\n",
      "Loss at step 64: 0.0006425165920518339\n",
      "Loss at step 65: 0.0008351883734576404\n",
      "Loss at step 66: 0.0009811738273128867\n",
      "Loss at step 67: 0.0010109065333381295\n",
      "Loss at step 68: 0.0009016743279062212\n",
      "Loss at step 69: 0.0009434226667508483\n",
      "Loss at step 70: 0.0007803111802786589\n",
      "Loss at step 71: 0.0008870944730006158\n",
      "Loss at step 72: 0.0009549623355269432\n",
      "Loss at step 73: 0.0008421952370554209\n",
      "Loss at step 74: 0.0009249798604287207\n",
      "Loss at step 75: 0.000621277024038136\n",
      "Loss at step 76: 0.0010047734249383211\n",
      "Loss at step 77: 0.0010829165112227201\n",
      "Loss at step 78: 0.000846424198243767\n",
      "Loss at step 79: 0.0008947700262069702\n",
      "Loss at step 80: 0.0008380577783100307\n",
      "Loss at step 81: 0.0008855769410729408\n",
      "Loss at step 82: 0.0009507128270342946\n",
      "Loss at step 83: 0.0009533280390314758\n",
      "Loss at step 84: 0.0008491143817082047\n",
      "Loss at step 85: 0.0007810263196006417\n",
      "Loss at step 86: 0.0006810084450989962\n",
      "Loss at step 87: 0.0008844071417115629\n",
      "Loss at step 88: 0.0009327062289230525\n",
      "Loss at step 89: 0.0006762436241842806\n",
      "Loss at step 90: 0.0007873313152231276\n",
      "Loss at step 91: 0.0010797117138281465\n",
      "Loss at step 92: 0.0007779138395562768\n",
      "Loss at step 93: 0.0009226030670106411\n",
      "Loss at step 94: 0.0007526128320023417\n",
      "Loss at step 95: 0.0008788618724793196\n",
      "Loss at step 96: 0.0008127231267280877\n",
      "Loss at step 97: 0.00092303566634655\n",
      "Loss at step 98: 0.0008978163241408765\n",
      "Loss at step 99: 0.0008364064851775765\n",
      "Loss at step 100: 0.0009544396307319403\n",
      "Loss at step 101: 0.0008066018926911056\n",
      "Loss at step 102: 0.0006947251386009157\n",
      "Loss at step 103: 0.000798253167886287\n",
      "Loss at step 104: 0.0007651980267837644\n",
      "Loss at step 105: 0.0007324159960262477\n",
      "Loss at step 106: 0.0009678076021373272\n",
      "Loss at step 107: 0.0008126309257932007\n",
      "Loss at step 108: 0.0007389583624899387\n",
      "Loss at step 109: 0.0009421558352187276\n",
      "Loss at step 110: 0.0008343184599652886\n",
      "Loss at step 111: 0.000871826836373657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 112: 0.0007784891058690846\n",
      "Loss at step 113: 0.0007451179553754628\n",
      "Loss at step 114: 0.0008341221255250275\n",
      "Loss at step 115: 0.000876121106557548\n",
      "Loss at step 116: 0.0009622726356610656\n",
      "Loss at step 117: 0.0008010760648176074\n",
      "Loss at step 118: 0.000918865785934031\n",
      "Loss at step 119: 0.0009087554062716663\n",
      "Loss at step 120: 0.0010127153946086764\n",
      "Loss at step 121: 0.000743903627153486\n",
      "Loss at step 122: 0.0008692185510881245\n",
      "Loss at step 123: 0.0008115152595564723\n",
      "Loss at step 124: 0.0008967758039943874\n",
      "Loss at step 125: 0.0006875795661471784\n",
      "Loss at step 126: 0.0009464324684813619\n",
      "Loss at step 127: 0.0008967758622020483\n",
      "Loss at step 128: 0.0009031047811731696\n",
      "Loss at step 129: 0.000894243479706347\n",
      "Loss at step 130: 0.0008734632865525782\n",
      "Loss at step 131: 0.0008390814764425159\n",
      "Loss at step 132: 0.0007585639832541347\n",
      "Loss at step 133: 0.0009553508134558797\n",
      "Loss at step 134: 0.0007288375054486096\n",
      "Loss at step 135: 0.0005928176105953753\n",
      "Loss at step 136: 0.0009605111554265022\n",
      "Loss at step 137: 0.0007097505149431527\n",
      "Loss at step 138: 0.0009441663278266788\n",
      "Loss at step 139: 0.0008869972662068903\n",
      "Loss at step 140: 0.0008359963539987803\n",
      "Loss at step 141: 0.0008352429140359163\n",
      "Loss at step 142: 0.0006148203392513096\n",
      "Loss at step 143: 0.0007988424622453749\n",
      "Loss at step 144: 0.0009809279581531882\n",
      "Loss at step 145: 0.0007908697007223964\n",
      "Loss at step 146: 0.0008690268732607365\n",
      "Loss at step 147: 0.0008012512698769569\n",
      "Loss at step 148: 0.0009026438347063959\n",
      "Loss at step 149: 0.0011179650900885463\n",
      "Loss at step 150: 0.0009573051356710494\n",
      "Loss at step 151: 0.000798424647655338\n",
      "Loss at step 152: 0.0007755251135677099\n",
      "Loss at step 153: 0.0007486326503567398\n",
      "Loss at step 154: 0.0007912804721854627\n",
      "Loss at step 155: 0.0008331275312229991\n",
      "Loss at step 156: 0.000821310852188617\n",
      "Loss at step 157: 0.0009377199457958341\n",
      "Loss at step 158: 0.0007124043768271804\n",
      "Loss at step 159: 0.0007397690205834806\n",
      "Loss at step 160: 0.000708054518327117\n",
      "Loss at step 161: 0.0008688780362717807\n",
      "Loss at step 162: 0.0008543523726984859\n",
      "Loss at step 163: 0.0008779017953202128\n",
      "Loss at step 164: 0.0008690985850989819\n",
      "Loss at step 165: 0.0007251746137626469\n",
      "Loss at step 166: 0.0006901160231791437\n",
      "Loss at step 167: 0.0007862545317038894\n",
      "Loss at step 168: 0.0009307882864959538\n",
      "Loss at step 169: 0.0008716945303604007\n",
      "Loss at step 170: 0.0010026184609159827\n",
      "Loss at step 171: 0.000963604892604053\n",
      "Loss at step 172: 0.0009328486630693078\n",
      "Loss at step 173: 0.001043140422552824\n",
      "Loss at step 174: 0.0008149923523887992\n",
      "Loss at step 175: 0.0008731925627216697\n",
      "Loss at step 176: 0.0008463250123895705\n",
      "Loss at step 177: 0.0010984411928802729\n",
      "Loss at step 178: 0.0008592751109972596\n",
      "Loss at step 179: 0.0006823164294473827\n",
      "Loss at step 180: 0.0009861140279099345\n",
      "Loss at step 181: 0.0005046201986260712\n",
      "Loss at step 182: 0.0008646747446618974\n",
      "Loss at step 183: 0.000912014686036855\n",
      "Loss at step 184: 0.0009800790576264262\n",
      "Loss at step 185: 0.0006427562329918146\n",
      "Loss at step 186: 0.000940072990488261\n",
      "Loss at step 187: 0.000840254477225244\n",
      "Loss at step 188: 0.0009452099329791963\n",
      "Loss at step 189: 0.0008035769569687545\n",
      "Loss at step 190: 0.0009089832892641425\n",
      "Loss at step 191: 0.0009445474133826792\n",
      "Loss at step 192: 0.0008549485355615616\n",
      "Loss at step 193: 0.0010096612386405468\n",
      "Loss at step 194: 0.0009413021616637707\n",
      "Loss at step 195: 0.0009922727476805449\n",
      "Loss at step 196: 0.0008504370343871415\n",
      "Loss at step 197: 0.0007333437097258866\n",
      "Loss at step 198: 0.0007363139884546399\n",
      "Loss at step 199: 0.0010852369014173746\n",
      "Loss at step 200: 0.0006755770300514996\n",
      "Loss at step 201: 0.0009159559849649668\n",
      "Loss at step 202: 0.000781216484028846\n",
      "Loss at step 203: 0.0007931301952339709\n",
      "Loss at step 204: 0.0010133296018466353\n",
      "Loss at step 205: 0.0008779383497312665\n",
      "Loss at step 206: 0.0009118189918808639\n",
      "Loss at step 207: 0.000744986638892442\n",
      "Loss at step 208: 0.0008828091667965055\n",
      "Loss at step 209: 0.0008512940839864314\n",
      "Loss at step 210: 0.0008601396693848073\n",
      "Loss at step 211: 0.0008618523133918643\n",
      "Loss at step 212: 0.0009698776411823928\n",
      "Loss at step 213: 0.0008303141221404076\n",
      "Loss at step 214: 0.000832987716421485\n",
      "Loss at step 215: 0.0008694669813849032\n",
      "Loss at step 216: 0.0008118523983284831\n",
      "Loss at step 217: 0.0007563852122984827\n",
      "Loss at step 218: 0.000806338619440794\n",
      "Loss at step 219: 0.000891994044650346\n",
      "Loss at step 220: 0.000737820693757385\n",
      "Loss at step 221: 0.0008474448695778847\n",
      "Loss at step 222: 0.0006480938172899187\n",
      "Loss at step 223: 0.000919362879358232\n",
      "Loss at step 224: 0.0010912457946687937\n",
      "Loss at step 225: 0.0008662777254357934\n",
      "Loss at step 226: 0.0007768342038616538\n",
      "Loss at step 227: 0.0008563996525481343\n",
      "Loss at step 228: 0.0008489109459333122\n",
      "Loss at step 229: 0.0008787050028331578\n",
      "Loss at step 230: 0.0007669805781915784\n",
      "Loss at step 231: 0.0008233889238908887\n",
      "Loss at step 232: 0.0006454108515754342\n",
      "Loss at step 233: 0.0008426642743870616\n",
      "Loss at step 234: 0.0009361242991872132\n",
      "Loss at step 235: 0.0008474813657812774\n",
      "Loss at step 236: 0.0009649500716477633\n",
      "Loss at step 237: 0.0008301031775772572\n",
      "Loss at step 238: 0.0008892395417205989\n",
      "Loss at step 239: 0.0008014403283596039\n",
      "Loss at step 240: 0.0008225044584833086\n",
      "Loss at step 241: 0.0009377538808621466\n",
      "Loss at step 242: 0.0007491617579944432\n",
      "Loss at step 243: 0.0010934753809124231\n",
      "Loss at step 244: 0.0009083522018045187\n",
      "Loss at step 245: 0.0008895940845832229\n",
      "Loss at step 246: 0.0007640874246135354\n",
      "Loss at step 247: 0.0009702337556518614\n",
      "Loss at step 248: 0.0007807808578945696\n",
      "Loss at step 249: 0.0006985703948885202\n",
      "Loss at step 250: 0.0009379851981066167\n",
      "Loss at step 251: 0.0006913460674695671\n",
      "Loss at step 252: 0.000876608130056411\n",
      "Loss at step 253: 0.000891624775249511\n",
      "Loss at step 254: 0.0007611791370436549\n",
      "Loss at step 255: 0.0008110270136967301\n",
      "Loss at step 256: 0.0007321076700463891\n",
      "Loss at step 257: 0.0007321993471123278\n",
      "Loss at step 258: 0.0009069297229871154\n",
      "Loss at step 259: 0.0009089967934414744\n",
      "Loss at step 260: 0.0009460813598707318\n",
      "Loss at step 261: 0.0007045554812066257\n",
      "Loss at step 262: 0.0008470332249999046\n",
      "Loss at step 263: 0.0007528038695454597\n",
      "Loss at step 264: 0.0009908621432259679\n",
      "Loss at step 265: 0.0007988628349266946\n",
      "Loss at step 266: 0.0008119238191284239\n",
      "Loss at step 267: 0.0009747215081006289\n",
      "Loss at step 268: 0.0007965443073771894\n",
      "Loss at step 269: 0.0008841771050356328\n",
      "Loss at step 270: 0.0008771392167545855\n",
      "Loss at step 271: 0.0007171542965807021\n",
      "Loss at step 272: 0.0007692994549870491\n",
      "Loss at step 273: 0.0007727999472990632\n",
      "Loss at step 274: 0.0007543240790255368\n",
      "Loss at step 275: 0.0008867877768352628\n",
      "Loss at step 276: 0.0008718250319361687\n",
      "Loss at step 277: 0.0008167343912646174\n",
      "Loss at step 278: 0.001002797158434987\n",
      "Loss at step 279: 0.0008815900655463338\n",
      "Loss at step 280: 0.0007409811951220036\n",
      "Loss at step 281: 0.0007426650845445693\n",
      "Loss at step 282: 0.0009752975893206894\n",
      "Loss at step 283: 0.0009792346972972155\n",
      "Loss at step 284: 0.0008690532413311303\n",
      "Loss at step 285: 0.0009782027918845415\n",
      "Loss at step 286: 0.0008401473751291633\n",
      "Loss at step 287: 0.0007698048721067607\n",
      "Loss at step 288: 0.0009214768069796264\n",
      "Loss at step 289: 0.0008975399541668594\n",
      "Loss at step 290: 0.0006407926557585597\n",
      "Loss at step 291: 0.0009477655403316021\n",
      "Loss at step 292: 0.0008216386777348816\n",
      "Loss at step 293: 0.000856085738632828\n",
      "Loss at step 294: 0.0007427429663948715\n",
      "Loss at step 295: 0.0008563360897824168\n",
      "Loss at step 296: 0.0008107190951704979\n",
      "Loss at step 297: 0.0007658553076907992\n",
      "Loss at step 298: 0.0008596152765676379\n",
      "Loss at step 299: 0.0008643186884000897\n",
      "Loss at step 300: 0.0007529837894253433\n",
      "Loss at step 301: 0.0007020618068054318\n",
      "Loss at step 302: 0.0008946949383243918\n",
      "Loss at step 303: 0.0008609612705186009\n",
      "Loss at step 304: 0.0007728089694865048\n",
      "Loss at step 305: 0.0007573881885036826\n",
      "Loss at step 306: 0.0009032628731802106\n",
      "Loss at step 307: 0.0007693342631682754\n",
      "Loss at step 308: 0.0007381613249890506\n",
      "Loss at step 309: 0.0009305186686106026\n",
      "Loss at step 310: 0.0008605130133219063\n",
      "Loss at step 311: 0.0008055121288634837\n",
      "Loss at step 312: 0.000783955620136112\n",
      "Loss at step 313: 0.0006309488089755177\n",
      "Loss at step 314: 0.0008772218716330826\n",
      "Loss at step 315: 0.0009031346999108791\n",
      "Loss at step 316: 0.0009656683541834354\n",
      "Loss at step 317: 0.0009529272792860866\n",
      "Loss at step 318: 0.0008293358841910958\n",
      "Loss at step 319: 0.000804441049695015\n",
      "Loss at step 320: 0.0008111544302664697\n",
      "Loss at step 321: 0.0008700927719473839\n",
      "Loss at step 322: 0.0006313578342087567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 323: 0.0007296367548406124\n",
      "Loss at step 324: 0.0009394505177624524\n",
      "Loss at step 325: 0.000712161127012223\n",
      "Loss at step 326: 0.0009774597128853202\n",
      "Loss at step 327: 0.0009183228248730302\n",
      "Loss at step 328: 0.0009425943717360497\n",
      "Loss at step 329: 0.0009166388772428036\n",
      "Loss at step 330: 0.0007484492380172014\n",
      "Loss at step 331: 0.0007789077935740352\n",
      "Loss at step 332: 0.0007446143426932395\n",
      "Loss at step 333: 0.0006860236171633005\n",
      "Loss at step 334: 0.0008534908411093056\n",
      "Loss at step 335: 0.0007879300392232835\n",
      "Loss at step 336: 0.0008627979550510645\n",
      "Loss at step 337: 0.0008260956965386868\n",
      "Loss at step 338: 0.0010169903980568051\n",
      "Loss at step 339: 0.0007474370650015771\n",
      "Loss at step 340: 0.0009494153200648725\n",
      "Loss at step 341: 0.0008037443039938807\n",
      "Loss at step 342: 0.0007683467702008784\n",
      "Loss at step 343: 0.0006623812369070947\n",
      "Loss at step 344: 0.0008260252652689815\n",
      "Loss at step 345: 0.000973190413787961\n",
      "Loss at step 346: 0.0006939820596016943\n",
      "Loss at step 347: 0.0008612664532847703\n",
      "Loss at step 348: 0.000818476895801723\n",
      "Loss at step 349: 0.0007734354585409164\n",
      "Loss at step 350: 0.0009150750702247024\n",
      "Loss at step 351: 0.0007151585887186229\n",
      "Loss at step 352: 0.0009562873747199774\n",
      "Loss at step 353: 0.0007586833671666682\n",
      "Loss at step 354: 0.0008432380273006856\n",
      "Loss at step 355: 0.0007967709680087864\n",
      "Loss at step 356: 0.0008057832601480186\n",
      "Loss at step 357: 0.0009962357580661774\n",
      "Loss at step 358: 0.0006264526746235788\n",
      "Loss at step 359: 0.0009657642804086208\n",
      "Loss at step 360: 0.0007106001139618456\n",
      "Loss at step 361: 0.000719336501788348\n",
      "Loss at step 362: 0.0009560710750520229\n",
      "Loss at step 363: 0.0007833187701180577\n",
      "Loss at step 364: 0.0008838902576826513\n",
      "Loss at step 365: 0.0006464310572482646\n",
      "Loss at step 366: 0.000940650119446218\n",
      "Loss at step 367: 0.0008299903711304069\n",
      "Loss at step 368: 0.0008713979041203856\n",
      "Loss at step 369: 0.0008743703365325928\n",
      "Loss at step 370: 0.0008466774597764015\n",
      "Loss at step 371: 0.0008162507438100874\n",
      "Loss at step 372: 0.0007831717957742512\n",
      "Loss at step 373: 0.0006636352627538145\n",
      "Loss at step 374: 0.0008426090353168547\n",
      "Loss at step 375: 0.0009097628644667566\n",
      "Loss at step 376: 0.0009438301785849035\n",
      "Loss at step 377: 0.0008617326966486871\n",
      "Loss at step 378: 0.0009146067313849926\n",
      "Loss at step 379: 0.0007454250589944422\n",
      "Loss at step 380: 0.0007718281704001129\n",
      "Loss at step 381: 0.0006809976766817272\n",
      "Loss at step 382: 0.0010568116558715701\n",
      "Loss at step 383: 0.0008374142344109714\n",
      "Loss at step 384: 0.000861325825098902\n",
      "Loss at step 385: 0.0008266394725069404\n",
      "Loss at step 386: 0.0007588192820549011\n",
      "Loss at step 387: 0.000831497076433152\n",
      "Loss at step 388: 0.0007417172309942544\n",
      "Loss at step 389: 0.0008462354890070856\n",
      "Loss at step 390: 0.0008012352045625448\n",
      "Loss at step 391: 0.0008095924276858568\n",
      "Loss at step 392: 0.0009006339823827147\n",
      "Loss at step 393: 0.0007342593744397163\n",
      "Loss at step 394: 0.0006144738872535527\n",
      "Loss at step 395: 0.0008410590817220509\n",
      "Loss at step 396: 0.0010898374021053314\n",
      "Loss at step 397: 0.0007698729750700295\n",
      "Loss at step 398: 0.0008795288158580661\n",
      "Loss at step 399: 0.0008193390094675124\n",
      "Loss at step 400: 0.001114891842007637\n",
      "Loss at step 401: 0.0009146108641289175\n",
      "Loss at step 402: 0.0008862618124112487\n",
      "Loss at step 403: 0.0009998040040954947\n",
      "Loss at step 404: 0.0007226526504382491\n",
      "Loss at step 405: 0.0008348206174559891\n",
      "Loss at step 406: 0.0007513812161050737\n",
      "Loss at step 407: 0.000815340259578079\n",
      "Loss at step 408: 0.0009482098976150155\n",
      "Loss at step 409: 0.0006454080576077104\n",
      "Loss at step 410: 0.000936834723688662\n",
      "Loss at step 411: 0.0008840073132887483\n",
      "Loss at step 412: 0.000691284891217947\n",
      "Loss at step 413: 0.0008604647591710091\n",
      "Loss at step 414: 0.0008412624592892826\n",
      "Loss at step 415: 0.0007313136011362076\n",
      "Loss at step 416: 0.0009030409273691475\n",
      "Loss at step 417: 0.0008854091283865273\n",
      "Loss at step 418: 0.0008693932904861867\n",
      "Loss at step 419: 0.0008867523283697665\n",
      "Loss at step 420: 0.0009896911215037107\n",
      "Loss at step 421: 0.0010917402105405927\n",
      "Loss at step 422: 0.0007877136813476682\n",
      "Loss at step 423: 0.0007834208663553\n",
      "Loss at step 424: 0.0008518542745150626\n",
      "Loss at step 425: 0.0007309666834771633\n",
      "Loss at step 426: 0.0008687431109137833\n",
      "Loss at step 427: 0.0008234679116867483\n",
      "Loss at step 428: 0.0008811327861621976\n",
      "Loss at step 429: 0.0008328825933858752\n",
      "Loss at step 430: 0.0008738545584492385\n",
      "Loss at step 431: 0.000825944181997329\n",
      "Loss at step 432: 0.0009374856017529964\n",
      "Loss at step 433: 0.0010263345902785659\n",
      "Loss at step 434: 0.0009833000367507339\n",
      "Loss at step 435: 0.0009784797439351678\n",
      "Loss at step 436: 0.0009214231977239251\n",
      "Loss at step 437: 0.0009468349744565785\n",
      "Loss at step 438: 0.0008377807680517435\n",
      "Loss at step 439: 0.000853606965392828\n",
      "Loss at step 440: 0.000888134993147105\n",
      "Loss at step 441: 0.0009616350289434195\n",
      "Loss at step 442: 0.0009775736834853888\n",
      "Loss at step 443: 0.0009019174613058567\n",
      "Loss at step 444: 0.0008845229749567807\n",
      "Loss at step 445: 0.0008826358825899661\n",
      "Loss at step 446: 0.0006510548992082477\n",
      "Loss at step 447: 0.0009046846535056829\n",
      "Loss at step 448: 0.0007428504759445786\n",
      "Loss at step 449: 0.0008997489931061864\n",
      "Loss at step 450: 0.000839252898003906\n",
      "Loss at step 451: 0.0009221333311870694\n",
      "Loss at step 452: 0.0008999309502542019\n",
      "Loss at step 453: 0.0008807015256024897\n",
      "Loss at step 454: 0.0008491641492582858\n",
      "Loss at step 455: 0.0007582688704133034\n",
      "Loss at step 456: 0.0007496607722714543\n",
      "Loss at step 457: 0.0008430867455899715\n",
      "Loss at step 458: 0.0009718449437059462\n",
      "Loss at step 459: 0.0009716935455799103\n",
      "Loss at step 460: 0.0007893276633694768\n",
      "Loss at step 461: 0.0008665267378091812\n",
      "Loss at step 462: 0.0007990738959051669\n",
      "Loss at step 463: 0.000712248613126576\n",
      "Loss at step 464: 0.000933747855015099\n",
      "Loss at step 465: 0.0008723057107999921\n",
      "Loss at step 466: 0.000944121740758419\n",
      "Loss at step 467: 0.0008006482967175543\n",
      "Loss at step 468: 0.0006646977853961289\n",
      "Loss at step 469: 0.000991271692328155\n",
      "Loss at step 470: 0.0008902373956516385\n",
      "Loss at step 471: 0.0008375756442546844\n",
      "Loss at step 472: 0.0008293665596283972\n",
      "Loss at step 473: 0.0010771520901471376\n",
      "Loss at step 474: 0.0008706501103006303\n",
      "Loss at step 475: 0.0008136737742461264\n",
      "Loss at step 476: 0.0008542710565961897\n",
      "Loss at step 477: 0.0008732735877856612\n",
      "Loss at step 478: 0.0006951625109650195\n",
      "Loss at step 479: 0.0007255361997522414\n",
      "Loss at step 480: 0.0009239079663529992\n",
      "Loss at step 481: 0.0009464535978622735\n",
      "Loss at step 482: 0.000956457166466862\n",
      "Loss at step 483: 0.0009359901887364686\n",
      "Loss at step 484: 0.0008236429421231151\n",
      "Loss at step 485: 0.0008448745356872678\n",
      "Loss at step 486: 0.0009102746844291687\n",
      "Loss at step 487: 0.0010072569129988551\n",
      "Loss at step 488: 0.0009842956205829978\n",
      "Loss at step 489: 0.000994729227386415\n",
      "Loss at step 490: 0.00096107367426157\n",
      "Loss at step 491: 0.0008508418686687946\n",
      "Loss at step 492: 0.000806293508503586\n",
      "Loss at step 493: 0.0006213018205016851\n",
      "Loss at step 494: 0.0008324185037054121\n",
      "Loss at step 495: 0.0009142213966697454\n",
      "Loss at step 496: 0.0007390399696305394\n",
      "Loss at step 497: 0.0006885887123644352\n",
      "Loss at step 498: 0.00081699836300686\n",
      "Loss at step 499: 0.0008104123407974839\n",
      "Loss at step 500: 0.0007792018004693091\n",
      "Loss at step 501: 0.00072185491444543\n",
      "Loss at step 502: 0.0008921772823669016\n",
      "Loss at step 503: 0.0007011256529949605\n",
      "Loss at step 504: 0.0009024175233207643\n",
      "Loss at step 505: 0.0006450340733863413\n",
      "Loss at step 506: 0.0007483536610379815\n",
      "Loss at step 507: 0.000745622324757278\n",
      "Loss at step 508: 0.0009354637004435062\n",
      "Loss at step 509: 0.00071483023930341\n",
      "Loss at step 510: 0.0008049740572459996\n",
      "Loss at step 511: 0.000936927564907819\n",
      "Loss at step 512: 0.0007645896985195577\n",
      "Loss at step 513: 0.000949716370087117\n",
      "Loss at step 514: 0.0008996087708510458\n",
      "Loss at step 515: 0.0009024026221595705\n",
      "Loss at step 516: 0.0007271055364981294\n",
      "Loss at step 517: 0.0009902110323309898\n",
      "Loss at step 518: 0.0008528092876076698\n",
      "Loss at step 519: 0.0007948458078317344\n",
      "Loss at step 520: 0.0009704655385576189\n",
      "Loss at step 521: 0.0008696580189280212\n",
      "Loss at step 522: 0.0008654256234876812\n",
      "Loss at step 523: 0.0008373218006454408\n",
      "Loss at step 524: 0.0008708189125172794\n",
      "Loss at step 525: 0.0007387732621282339\n",
      "Loss at step 526: 0.0009204439702443779\n",
      "Loss at step 527: 0.0008372701122425497\n",
      "Loss at step 528: 0.0010332922684028745\n",
      "Loss at step 529: 0.0007817397126927972\n",
      "Loss at step 530: 0.00099236483220011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 531: 0.0006791270570829511\n",
      "Loss at step 532: 0.0008491929620504379\n",
      "Loss at step 533: 0.000773266947362572\n",
      "Loss at step 534: 0.0006361405248753726\n",
      "Loss at step 535: 0.0009168645483441651\n",
      "Loss at step 536: 0.0008339365595020354\n",
      "Loss at step 537: 0.0010270191123709083\n",
      "Loss at step 538: 0.0008613025420345366\n",
      "Loss at step 539: 0.0007926629041321576\n",
      "Loss at step 540: 0.0006961552426218987\n",
      "Loss at step 541: 0.0007346697966568172\n",
      "Loss at step 542: 0.0008641522144898772\n",
      "Loss at step 543: 0.0010974780889227986\n",
      "Loss at step 544: 0.000935673073399812\n",
      "Loss at step 545: 0.0008118986152112484\n",
      "Loss at step 546: 0.0008197108400054276\n",
      "Loss at step 547: 0.0009392172796651721\n",
      "Loss at step 548: 0.0008752167923375964\n",
      "Loss at step 549: 0.000702112854924053\n",
      "Loss at step 550: 0.0008733777212910354\n",
      "Loss at step 551: 0.0008971350616775453\n",
      "Loss at step 552: 0.0009162574424408376\n",
      "Loss at step 553: 0.0008356485050171614\n",
      "Loss at step 554: 0.0009464501054026186\n",
      "Loss at step 555: 0.0008533084765076637\n",
      "Loss at step 556: 0.0009020925499498844\n",
      "Loss at step 557: 0.0008207514183595777\n",
      "Loss at step 558: 0.0008859134977683425\n",
      "Loss at step 559: 0.0007196705555543303\n",
      "Loss at step 560: 0.0008781104115769267\n",
      "Loss at step 561: 0.0007898076437413692\n",
      "Loss at step 562: 0.0008924520225264132\n",
      "Loss at step 563: 0.001011029933579266\n",
      "Loss at step 564: 0.000966529012657702\n",
      "Loss at step 565: 0.0008458081865683198\n",
      "Loss at step 566: 0.0007719830609858036\n",
      "Loss at step 567: 0.0008492927881889045\n",
      "Loss at step 568: 0.000995952752418816\n",
      "Loss at step 569: 0.0008011078462004662\n",
      "Loss at step 570: 0.000804734940174967\n",
      "Loss at step 571: 0.000711412460077554\n",
      "Loss at step 572: 0.000790727382991463\n",
      "Loss at step 573: 0.0009555707219988108\n",
      "Loss at step 574: 0.0007597614894621074\n",
      "Loss at step 575: 0.0007762054447084665\n",
      "Loss at step 576: 0.0010136577766388655\n",
      "Loss at step 577: 0.0006351475021801889\n",
      "Loss at step 578: 0.0008361563668586314\n",
      "Loss at step 579: 0.0008071939810179174\n",
      "Loss at step 580: 0.0008696898003108799\n",
      "Loss at step 581: 0.0006819782429374754\n",
      "Loss at step 582: 0.0009417171240784228\n",
      "Loss at step 583: 0.0008135285461321473\n",
      "Loss at step 584: 0.0008085437584668398\n",
      "Loss at step 585: 0.0008335796883329749\n",
      "Loss at step 586: 0.0008801229414530098\n",
      "Loss at step 587: 0.0009302854305133224\n",
      "Loss at step 588: 0.0009384185541421175\n",
      "Loss at step 589: 0.0006402613362297416\n",
      "Loss at step 590: 0.0008355799946002662\n",
      "Loss at step 591: 0.0009045775514096022\n",
      "Loss at step 592: 0.0008227606303989887\n",
      "Loss at step 593: 0.00060913065681234\n",
      "Loss at step 594: 0.0010191133478656411\n",
      "Loss at step 595: 0.0007849287358112633\n",
      "Loss at step 596: 0.000749724917113781\n",
      "Loss at step 597: 0.0008069475879892707\n",
      "Loss at step 598: 0.0007852011476643384\n",
      "Loss at step 599: 0.0009463196038268507\n",
      "Loss at step 600: 0.0009124214411713183\n",
      "Loss at step 601: 0.0009680194198153913\n",
      "Loss at step 602: 0.000835524289868772\n",
      "Loss at step 603: 0.0009693176252767444\n",
      "Loss at step 604: 0.0008133078808896244\n",
      "Loss at step 605: 0.0009012715891003609\n",
      "Loss at step 606: 0.0007269657216966152\n",
      "Loss at step 607: 0.0007576754433102906\n",
      "Loss at step 608: 0.0007614351343363523\n",
      "Loss at step 609: 0.0010295838583260775\n",
      "Loss at step 610: 0.0007773627294227481\n",
      "Loss at step 611: 0.0009246592526324093\n",
      "Loss at step 612: 0.000691538501996547\n",
      "Loss at step 613: 0.0009548091911710799\n",
      "Loss at step 614: 0.0008348420378752053\n",
      "Loss at step 615: 0.0009286488639190793\n",
      "Loss at step 616: 0.000707656960003078\n",
      "Loss at step 617: 0.0006786930025555193\n",
      "Loss at step 618: 0.0010375239653512836\n",
      "Loss at step 619: 0.0007545764092355967\n",
      "Loss at step 620: 0.0010556677589192986\n",
      "Loss at step 621: 0.0009920417796820402\n",
      "Loss at step 622: 0.0008845247211866081\n",
      "Loss at step 623: 0.000964227830991149\n",
      "Loss at step 624: 0.0009278676589019597\n",
      "Loss at step 625: 0.0008188482606783509\n",
      "Loss at step 626: 0.0007702370639890432\n",
      "Loss at step 627: 0.0008476665243506432\n",
      "Loss at step 628: 0.000854003126733005\n",
      "Loss at step 629: 0.0007675878587178886\n",
      "Loss at step 630: 0.000724138633813709\n",
      "Loss at step 631: 0.0008505372097715735\n",
      "Loss at step 632: 0.0008932024938985705\n",
      "Loss at step 633: 0.0007173271151259542\n",
      "Loss at step 634: 0.0008416603086516261\n",
      "Loss at step 635: 0.000977701973170042\n",
      "Loss at step 636: 0.0006394737283699214\n",
      "Loss at step 637: 0.0008042994304560125\n",
      "Loss at step 638: 0.0009450266370549798\n",
      "Loss at step 639: 0.0009230338619090617\n",
      "Loss at step 640: 0.0010033991420641541\n",
      "Loss at step 641: 0.0008078937535174191\n",
      "Loss at step 642: 0.0007790336385369301\n",
      "Loss at step 643: 0.0009647479164414108\n",
      "Loss at step 644: 0.0010065505048260093\n",
      "Loss at step 645: 0.0007619987009093165\n",
      "Loss at step 646: 0.0007580572855658829\n",
      "Loss at step 647: 0.0009190053096972406\n",
      "Loss at step 648: 0.0008957179961726069\n",
      "Loss at step 649: 0.0008128837798722088\n",
      "Loss at step 650: 0.0007229605689644814\n",
      "Loss at step 651: 0.0009342101984657347\n",
      "Loss at step 652: 0.0006831096252426505\n",
      "Loss at step 653: 0.0009291622554883361\n",
      "Loss at step 654: 0.00097656185971573\n",
      "Loss at step 655: 0.0009380250121466815\n",
      "Loss at step 656: 0.0007532125455327332\n",
      "Loss at step 657: 0.0009693583124317229\n",
      "Loss at step 658: 0.0008772904402576387\n",
      "Loss at step 659: 0.0009471451630815864\n",
      "Loss at step 660: 0.0008816891931928694\n",
      "Loss at step 661: 0.0008378952625207603\n",
      "Loss at step 662: 0.000805126444902271\n",
      "Loss at step 663: 0.0009714532061479986\n",
      "Loss at step 664: 0.0009218508494086564\n",
      "Loss at step 665: 0.0008973157382570207\n",
      "Loss at step 666: 0.0009537438745610416\n",
      "Loss at step 667: 0.0009954130509868264\n",
      "Loss at step 668: 0.0008927644812501967\n",
      "Loss at step 669: 0.0009509416413493454\n",
      "Loss at step 670: 0.0009520124294795096\n",
      "Loss at step 671: 0.0008925825823098421\n",
      "Loss at step 672: 0.0007185071590356529\n",
      "Loss at step 673: 0.0008249538950622082\n",
      "Loss at step 674: 0.0007809212547726929\n",
      "Loss at step 675: 0.000783521041739732\n",
      "Loss at step 676: 0.0008337412727996707\n",
      "Loss at step 677: 0.000723105447832495\n",
      "Loss at step 678: 0.0008325416129082441\n",
      "Loss at step 679: 0.000660001183860004\n",
      "Loss at step 680: 0.0009953866247087717\n",
      "Loss at step 681: 0.0008411912713199854\n",
      "Loss at step 682: 0.0009798378450796008\n",
      "Loss at step 683: 0.0006854361854493618\n",
      "Loss at step 684: 0.0007279261481016874\n",
      "Loss at step 685: 0.0009964838391169906\n",
      "Loss at step 686: 0.000893459131475538\n",
      "Loss at step 687: 0.000861362845171243\n",
      "Loss at step 688: 0.0008303001523017883\n",
      "Loss at step 689: 0.0007913336157798767\n",
      "Loss at step 690: 0.0006738363299518824\n",
      "Loss at step 691: 0.0007357480353675783\n",
      "Loss at step 692: 0.0006160466000437737\n",
      "Loss at step 693: 0.0009458882850594819\n",
      "Loss at step 694: 0.0008942264248616993\n",
      "Loss at step 695: 0.0008196388371288776\n",
      "Loss at step 696: 0.0009263513493351638\n",
      "Loss at step 697: 0.0009417720139026642\n",
      "Loss at step 698: 0.0007754930993542075\n",
      "Loss at step 699: 0.0009302222169935703\n",
      "Loss at step 700: 0.0007977703935466707\n",
      "Loss at step 701: 0.0007979698129929602\n",
      "Loss at step 702: 0.0009058773284777999\n",
      "Loss at step 703: 0.0007668287144042552\n",
      "Loss at step 704: 0.000856981088872999\n",
      "Loss at step 705: 0.0007076178444549441\n",
      "train Loss: 0.0008\n",
      "Loss at step 0: 0.0007669014157727361\n",
      "Loss at step 1: 0.001025667181238532\n",
      "Loss at step 2: 0.0007935013272799551\n",
      "Loss at step 3: 0.0009177363244816661\n",
      "Loss at step 4: 0.0006586791714653373\n",
      "Loss at step 5: 0.0007923362427391112\n",
      "Loss at step 6: 0.0007874561124481261\n",
      "Loss at step 7: 0.0007718723500147462\n",
      "Loss at step 8: 0.0008631329401396215\n",
      "Loss at step 9: 0.0009271324961446226\n",
      "Loss at step 10: 0.0008516205125488341\n",
      "Loss at step 11: 0.000736116839107126\n",
      "Loss at step 12: 0.0007448258111253381\n",
      "Loss at step 13: 0.0008770332206040621\n",
      "Loss at step 14: 0.0009683229145593941\n",
      "Loss at step 15: 0.0007943370146676898\n",
      "Loss at step 16: 0.0006936146528460085\n",
      "Loss at step 17: 0.0010781947057694197\n",
      "Loss at step 18: 0.0008317554020322859\n",
      "Loss at step 19: 0.0010366732021793723\n",
      "Loss at step 20: 0.0008838679641485214\n",
      "Loss at step 21: 0.0009023456950671971\n",
      "Loss at step 22: 0.0009895807597786188\n",
      "Loss at step 23: 0.0009437738917768002\n",
      "Loss at step 24: 0.0009095583809539676\n",
      "Loss at step 25: 0.0008070828043855727\n",
      "Loss at step 26: 0.0009681959636509418\n",
      "Loss at step 27: 0.0010024791117757559\n",
      "Loss at step 28: 0.0008536330424249172\n",
      "Loss at step 29: 0.0008653458789922297\n",
      "Loss at step 30: 0.0007047021645121276\n",
      "Loss at step 31: 0.0008005531271919608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 32: 0.000721318123396486\n",
      "Loss at step 33: 0.000785490614362061\n",
      "Loss at step 34: 0.0006873172824271023\n",
      "Loss at step 35: 0.0008322990615852177\n",
      "Loss at step 36: 0.00083768623881042\n",
      "Loss at step 37: 0.0008883286500349641\n",
      "Loss at step 38: 0.0008620223961770535\n",
      "Loss at step 39: 0.0008390821749344468\n",
      "Loss at step 40: 0.0009475383558310568\n",
      "Loss at step 41: 0.0009678035276010633\n",
      "Loss at step 42: 0.0007620595279149711\n",
      "Loss at step 43: 0.0009433617815375328\n",
      "Loss at step 44: 0.0011339191114529967\n",
      "Loss at step 45: 0.0010020529152825475\n",
      "Loss at step 46: 0.0007835107971914113\n",
      "Loss at step 47: 0.0007410140242427588\n",
      "Loss at step 48: 0.0008532210486009717\n",
      "Loss at step 49: 0.0007325121550820768\n",
      "Loss at step 50: 0.0008480326505377889\n",
      "Loss at step 51: 0.0009711337625049055\n",
      "Loss at step 52: 0.0008769596461206675\n",
      "Loss at step 53: 0.0009576239972375333\n",
      "Loss at step 54: 0.0008285758667625487\n",
      "Loss at step 55: 0.0007704526651650667\n",
      "Loss at step 56: 0.001019914634525776\n",
      "Loss at step 57: 0.0008286181255243719\n",
      "Loss at step 58: 0.0008481813711114228\n",
      "Loss at step 59: 0.0008055458893068135\n",
      "Loss at step 60: 0.0008065983420237899\n",
      "Loss at step 61: 0.000892027688678354\n",
      "Loss at step 62: 0.0009215481695719063\n",
      "Loss at step 63: 0.0008923047571443021\n",
      "Loss at step 64: 0.0009472204837948084\n",
      "Loss at step 65: 0.0007271486683748662\n",
      "Loss at step 66: 0.0009303835104219615\n",
      "Loss at step 67: 0.0008644681656733155\n",
      "Loss at step 68: 0.0008983988082036376\n",
      "Loss at step 69: 0.0010914331069216132\n",
      "Loss at step 70: 0.0007935390458442271\n",
      "Loss at step 71: 0.0008836660417728126\n",
      "Loss at step 72: 0.0008809658465906978\n",
      "Loss at step 73: 0.0009486371418461204\n",
      "Loss at step 74: 0.0007178592495620251\n",
      "Loss at step 75: 0.0008075059740804136\n",
      "Loss at step 76: 0.0008214929257519543\n",
      "Loss at step 77: 0.0007296708645299077\n",
      "Loss at step 78: 0.0008045322028920054\n",
      "Loss at step 79: 0.0008816261542961001\n",
      "Loss at step 80: 0.0010747633641585708\n",
      "Loss at step 81: 0.0008244228083640337\n",
      "Loss at step 82: 0.0006593303987756371\n",
      "Loss at step 83: 0.001008158316835761\n",
      "Loss at step 84: 0.0010331382509320974\n",
      "Loss at step 85: 0.0009410154307261109\n",
      "Loss at step 86: 0.000864675035700202\n",
      "Loss at step 87: 0.00088491290807724\n",
      "Loss at step 88: 0.00077273283386603\n",
      "Loss at step 89: 0.0007360453600995243\n",
      "Loss at step 90: 0.0009697682689875364\n",
      "Loss at step 91: 0.0008848650031723082\n",
      "Loss at step 92: 0.0009312095935456455\n",
      "Loss at step 93: 0.0007353613036684692\n",
      "Loss at step 94: 0.0007069104467518628\n",
      "Loss at step 95: 0.0009225626708939672\n",
      "Loss at step 96: 0.0009825793094933033\n",
      "Loss at step 97: 0.0007543317624367774\n",
      "Loss at step 98: 0.0009418112458661199\n",
      "Loss at step 99: 0.0007890340057201684\n",
      "Loss at step 100: 0.0006914199329912663\n",
      "Loss at step 101: 0.0008598574204370379\n",
      "Loss at step 102: 0.0008405995904468\n",
      "Loss at step 103: 0.0009887022897601128\n",
      "Loss at step 104: 0.0008786980179138482\n",
      "Loss at step 105: 0.0007938468479551375\n",
      "Loss at step 106: 0.0010922071523964405\n",
      "Loss at step 107: 0.0010569283040240407\n",
      "Loss at step 108: 0.0010748677887022495\n",
      "Loss at step 109: 0.0008501953561790287\n",
      "Loss at step 110: 0.0005936605739407241\n",
      "Loss at step 111: 0.0008304014918394387\n",
      "Loss at step 112: 0.0007559680379927158\n",
      "Loss at step 113: 0.000987077015452087\n",
      "Loss at step 114: 0.0007743617752566934\n",
      "Loss at step 115: 0.000706634484231472\n",
      "Loss at step 116: 0.0009743318660184741\n",
      "Loss at step 117: 0.0008596991538070142\n",
      "Loss at step 118: 0.0008653804543428123\n",
      "Loss at step 119: 0.000874488556291908\n",
      "Loss at step 120: 0.0009517123107798398\n",
      "Loss at step 121: 0.000837170984596014\n",
      "Loss at step 122: 0.0005892687477171421\n",
      "Loss at step 123: 0.000751060142647475\n",
      "Loss at step 124: 0.0008540734997950494\n",
      "Loss at step 125: 0.0008759308839216828\n",
      "Loss at step 126: 0.0007877377793192863\n",
      "Loss at step 127: 0.0006465118494816124\n",
      "Loss at step 128: 0.0007931159343570471\n",
      "Loss at step 129: 0.000726809143088758\n",
      "Loss at step 130: 0.0009406342287547886\n",
      "Loss at step 131: 0.000981649151071906\n",
      "Loss at step 132: 0.0010370815871283412\n",
      "Loss at step 133: 0.0007894299924373627\n",
      "Loss at step 134: 0.0010153210023418069\n",
      "Loss at step 135: 0.0010228074388578534\n",
      "Loss at step 136: 0.0007334076217375696\n",
      "Loss at step 137: 0.0009141007903963327\n",
      "Loss at step 138: 0.000805998919531703\n",
      "Loss at step 139: 0.0008741224883124232\n",
      "Loss at step 140: 0.0008636242127977312\n",
      "Loss at step 141: 0.0007301599835045636\n",
      "Loss at step 142: 0.0008203734178096056\n",
      "Loss at step 143: 0.000912013987544924\n",
      "Loss at step 144: 0.0009502460598014295\n",
      "Loss at step 145: 0.0010131171438843012\n",
      "Loss at step 146: 0.0009663501987233758\n",
      "Loss at step 147: 0.0009954744018614292\n",
      "Loss at step 148: 0.0008549322956241667\n",
      "Loss at step 149: 0.0008301099296659231\n",
      "Loss at step 150: 0.0006741397664882243\n",
      "Loss at step 151: 0.0006618914194405079\n",
      "Loss at step 152: 0.0008402974926866591\n",
      "Loss at step 153: 0.0009541151230223477\n",
      "Loss at step 154: 0.0010081313084810972\n",
      "Loss at step 155: 0.0009571260889060795\n",
      "Loss at step 156: 0.0009086549398489296\n",
      "Loss at step 157: 0.0009016917319968343\n",
      "Loss at step 158: 0.00089889025548473\n",
      "Loss at step 159: 0.0009481154847890139\n",
      "Loss at step 160: 0.0010487744584679604\n",
      "Loss at step 161: 0.0010426051449030638\n",
      "Loss at step 162: 0.0009536224533803761\n",
      "Loss at step 163: 0.0008524198201484978\n",
      "Loss at step 164: 0.0009078310686163604\n",
      "Loss at step 165: 0.0006950206006877124\n",
      "Loss at step 166: 0.0009039704455062747\n",
      "Loss at step 167: 0.000875733676366508\n",
      "Loss at step 168: 0.0007501164800487459\n",
      "Loss at step 169: 0.0010600778041407466\n",
      "Loss at step 170: 0.0008359054918400943\n",
      "Loss at step 171: 0.0010035164887085557\n",
      "Loss at step 172: 0.0009988285601139069\n",
      "Loss at step 173: 0.0005931583582423627\n",
      "Loss at step 174: 0.001161527936346829\n",
      "Loss at step 175: 0.000838170584756881\n",
      "Loss at step 176: 0.0005346362595446408\n",
      "val Loss: 0.0009\n",
      "Epoch 3/4\n",
      "----------\n",
      "Loss at step 0: 0.0006869501667097211\n",
      "Loss at step 1: 0.0008708310197107494\n",
      "Loss at step 2: 0.000893258024007082\n",
      "Loss at step 3: 0.0007722848677076399\n",
      "Loss at step 4: 0.000807256146799773\n",
      "Loss at step 5: 0.0006176196620799601\n",
      "Loss at step 6: 0.0008871629252098501\n",
      "Loss at step 7: 0.0006458664429374039\n",
      "Loss at step 8: 0.0008679063175804913\n",
      "Loss at step 9: 0.0007750455406494439\n",
      "Loss at step 10: 0.0009627312538214028\n",
      "Loss at step 11: 0.0008201610762625933\n",
      "Loss at step 12: 0.0009405285818502307\n",
      "Loss at step 13: 0.0008811019361019135\n",
      "Loss at step 14: 0.0009121873299591243\n",
      "Loss at step 15: 0.0008543136646039784\n",
      "Loss at step 16: 0.0008569442434236407\n",
      "Loss at step 17: 0.0009346152073703706\n",
      "Loss at step 18: 0.0007382541662082076\n",
      "Loss at step 19: 0.0009958070004358888\n",
      "Loss at step 20: 0.0007629967294633389\n",
      "Loss at step 21: 0.0008374859462492168\n",
      "Loss at step 22: 0.0007370764506049454\n",
      "Loss at step 23: 0.0007552635506726801\n",
      "Loss at step 24: 0.0007808135123923421\n",
      "Loss at step 25: 0.0009085738565772772\n",
      "Loss at step 26: 0.0008450715686194599\n",
      "Loss at step 27: 0.0008194564725272357\n",
      "Loss at step 28: 0.00089914386626333\n",
      "Loss at step 29: 0.0009516172576695681\n",
      "Loss at step 30: 0.0009515422862023115\n",
      "Loss at step 31: 0.0009110886603593826\n",
      "Loss at step 32: 0.0008478268864564598\n",
      "Loss at step 33: 0.0008693606359884143\n",
      "Loss at step 34: 0.0007924532983452082\n",
      "Loss at step 35: 0.0008298074244521558\n",
      "Loss at step 36: 0.0009738754597492516\n",
      "Loss at step 37: 0.0008540241979062557\n",
      "Loss at step 38: 0.0006936948047950864\n",
      "Loss at step 39: 0.0007801841129548848\n",
      "Loss at step 40: 0.0006183600053191185\n",
      "Loss at step 41: 0.0009285499691031873\n",
      "Loss at step 42: 0.0007967805140651762\n",
      "Loss at step 43: 0.0007578764343634248\n",
      "Loss at step 44: 0.000887370144482702\n",
      "Loss at step 45: 0.0006613557925447822\n",
      "Loss at step 46: 0.0008376504993066192\n",
      "Loss at step 47: 0.0008358994382433593\n",
      "Loss at step 48: 0.000813871796708554\n",
      "Loss at step 49: 0.000891182862687856\n",
      "Loss at step 50: 0.0007760156877338886\n",
      "Loss at step 51: 0.0009806259768083692\n",
      "Loss at step 52: 0.0008946560556069016\n",
      "Loss at step 53: 0.0007337082060985267\n",
      "Loss at step 54: 0.0008822102099657059\n",
      "Loss at step 55: 0.0007630728068761528\n",
      "Loss at step 56: 0.0008258207817561924\n",
      "Loss at step 57: 0.0010133272735401988\n",
      "Loss at step 58: 0.000797296583186835\n",
      "Loss at step 59: 0.0009071460808627307\n",
      "Loss at step 60: 0.0008891412289813161\n",
      "Loss at step 61: 0.0008813505992293358\n",
      "Loss at step 62: 0.001012965221889317\n",
      "Loss at step 63: 0.0008984822197817266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 64: 0.0009270372102037072\n",
      "Loss at step 65: 0.0007456312887370586\n",
      "Loss at step 66: 0.0010333162499591708\n",
      "Loss at step 67: 0.0007476034807041287\n",
      "Loss at step 68: 0.0008932428900152445\n",
      "Loss at step 69: 0.0010526468977332115\n",
      "Loss at step 70: 0.0009087151847779751\n",
      "Loss at step 71: 0.0007457461906597018\n",
      "Loss at step 72: 0.0008372807060368359\n",
      "Loss at step 73: 0.0006896571139805019\n",
      "Loss at step 74: 0.0008841475355438888\n",
      "Loss at step 75: 0.0008681709296070039\n",
      "Loss at step 76: 0.0008254475542344153\n",
      "Loss at step 77: 0.0007083142991177738\n",
      "Loss at step 78: 0.0006643834640271962\n",
      "Loss at step 79: 0.0009105905774049461\n",
      "Loss at step 80: 0.0008799103670753539\n",
      "Loss at step 81: 0.000752379884943366\n",
      "Loss at step 82: 0.0007633512723259628\n",
      "Loss at step 83: 0.0009815680095925927\n",
      "Loss at step 84: 0.001053655636496842\n",
      "Loss at step 85: 0.000758779642637819\n",
      "Loss at step 86: 0.0008792316075414419\n",
      "Loss at step 87: 0.0008963500731624663\n",
      "Loss at step 88: 0.0007984463009051979\n",
      "Loss at step 89: 0.0008286268566735089\n",
      "Loss at step 90: 0.0006250980077311397\n",
      "Loss at step 91: 0.0007891364512033761\n",
      "Loss at step 92: 0.0009587212698534131\n",
      "Loss at step 93: 0.0010904446244239807\n",
      "Loss at step 94: 0.0007991226157173514\n",
      "Loss at step 95: 0.0007510643335990608\n",
      "Loss at step 96: 0.000731799635104835\n",
      "Loss at step 97: 0.0008256749715656042\n",
      "Loss at step 98: 0.0007108314894139767\n",
      "Loss at step 99: 0.0008463779813610017\n",
      "Loss at step 100: 0.0008347175316885114\n",
      "Loss at step 101: 0.0009395346278324723\n",
      "Loss at step 102: 0.0007916493341326714\n",
      "Loss at step 103: 0.0008299176697619259\n",
      "Loss at step 104: 0.000846153125166893\n",
      "Loss at step 105: 0.0009450206416659057\n",
      "Loss at step 106: 0.0007672552019357681\n",
      "Loss at step 107: 0.0007595109054818749\n",
      "Loss at step 108: 0.0008369708084501326\n",
      "Loss at step 109: 0.000838175299577415\n",
      "Loss at step 110: 0.0008477225201204419\n",
      "Loss at step 111: 0.0007397669833153486\n",
      "Loss at step 112: 0.0006947986548766494\n",
      "Loss at step 113: 0.0008535624365322292\n",
      "Loss at step 114: 0.0007386885699816048\n",
      "Loss at step 115: 0.0008480274118483067\n",
      "Loss at step 116: 0.0009494394180364907\n",
      "Loss at step 117: 0.0008793175220489502\n",
      "Loss at step 118: 0.0009223262895829976\n",
      "Loss at step 119: 0.0009637228213250637\n",
      "Loss at step 120: 0.0008809542050585151\n",
      "Loss at step 121: 0.0008935685036703944\n",
      "Loss at step 122: 0.000704717356711626\n",
      "Loss at step 123: 0.0009347893064841628\n",
      "Loss at step 124: 0.0008425025152973831\n",
      "Loss at step 125: 0.0007912426954135299\n",
      "Loss at step 126: 0.0008561094873584807\n",
      "Loss at step 127: 0.0008699122699908912\n",
      "Loss at step 128: 0.0008929941686801612\n",
      "Loss at step 129: 0.0008507607853971422\n",
      "Loss at step 130: 0.0006360416300594807\n",
      "Loss at step 131: 0.0008825357654131949\n",
      "Loss at step 132: 0.001009924104437232\n",
      "Loss at step 133: 0.0008067925809882581\n",
      "Loss at step 134: 0.0010530579602345824\n",
      "Loss at step 135: 0.0008080393308773637\n",
      "Loss at step 136: 0.0006969538517296314\n",
      "Loss at step 137: 0.0007148499717004597\n",
      "Loss at step 138: 0.000664172344841063\n",
      "Loss at step 139: 0.0008188266074284911\n",
      "Loss at step 140: 0.0009011432994157076\n",
      "Loss at step 141: 0.0007524038664996624\n",
      "Loss at step 142: 0.0008135440293699503\n",
      "Loss at step 143: 0.0009714164189063013\n",
      "Loss at step 144: 0.0007231533527374268\n",
      "Loss at step 145: 0.0007211929769255221\n",
      "Loss at step 146: 0.0008818925707601011\n",
      "Loss at step 147: 0.0008008694276213646\n",
      "Loss at step 148: 0.0009192036814056337\n",
      "Loss at step 149: 0.000810290570370853\n",
      "Loss at step 150: 0.0009967300575226545\n",
      "Loss at step 151: 0.0007412106497213244\n",
      "Loss at step 152: 0.0010794091504067183\n",
      "Loss at step 153: 0.0008482362027280033\n",
      "Loss at step 154: 0.0007374156266450882\n",
      "Loss at step 155: 0.0008511068881489336\n",
      "Loss at step 156: 0.000899975304491818\n",
      "Loss at step 157: 0.0007717699045315385\n",
      "Loss at step 158: 0.0007703265291638672\n",
      "Loss at step 159: 0.0007221380947157741\n",
      "Loss at step 160: 0.0007967128767631948\n",
      "Loss at step 161: 0.0009610602864995599\n",
      "Loss at step 162: 0.000870796968229115\n",
      "Loss at step 163: 0.000801335962023586\n",
      "Loss at step 164: 0.0006528104422613978\n",
      "Loss at step 165: 0.0008019742090255022\n",
      "Loss at step 166: 0.0010041560744866729\n",
      "Loss at step 167: 0.0009466020273976028\n",
      "Loss at step 168: 0.0009589413530193269\n",
      "Loss at step 169: 0.0008640103042125702\n",
      "Loss at step 170: 0.0009866011096164584\n",
      "Loss at step 171: 0.0008710409165360034\n",
      "Loss at step 172: 0.00086606340482831\n",
      "Loss at step 173: 0.0009296027710661292\n",
      "Loss at step 174: 0.00074164685793221\n",
      "Loss at step 175: 0.0007641881820745766\n",
      "Loss at step 176: 0.0007701013819314539\n",
      "Loss at step 177: 0.0008793382439762354\n",
      "Loss at step 178: 0.0009805351728573442\n",
      "Loss at step 179: 0.0008810194558463991\n",
      "Loss at step 180: 0.000990719418041408\n",
      "Loss at step 181: 0.0009643951198086143\n",
      "Loss at step 182: 0.0009180725319311023\n",
      "Loss at step 183: 0.0006558562163263559\n",
      "Loss at step 184: 0.0008147695916704834\n",
      "Loss at step 185: 0.0007786022033542395\n",
      "Loss at step 186: 0.0008771088323555887\n",
      "Loss at step 187: 0.0009562724735587835\n",
      "Loss at step 188: 0.0009268083958886564\n",
      "Loss at step 189: 0.0011537950485944748\n",
      "Loss at step 190: 0.0009448330383747816\n",
      "Loss at step 191: 0.0007252001669257879\n",
      "Loss at step 192: 0.0009387919562868774\n",
      "Loss at step 193: 0.000988330808468163\n",
      "Loss at step 194: 0.0009624636732041836\n",
      "Loss at step 195: 0.0008800095529295504\n",
      "Loss at step 196: 0.0008934608194977045\n",
      "Loss at step 197: 0.0007006732048466802\n",
      "Loss at step 198: 0.0007003835635259748\n",
      "Loss at step 199: 0.0007635272922925651\n",
      "Loss at step 200: 0.0007523902459070086\n",
      "Loss at step 201: 0.0006839236593805254\n",
      "Loss at step 202: 0.0008660929161123931\n",
      "Loss at step 203: 0.0008642180473543704\n",
      "Loss at step 204: 0.0008985197637230158\n",
      "Loss at step 205: 0.0008681979961693287\n",
      "Loss at step 206: 0.0007213839562609792\n",
      "Loss at step 207: 0.0009283796534873545\n",
      "Loss at step 208: 0.0009292110335081816\n",
      "Loss at step 209: 0.0007387165096588433\n",
      "Loss at step 210: 0.001019833143800497\n",
      "Loss at step 211: 0.0010206479346379638\n",
      "Loss at step 212: 0.0008942774729803205\n",
      "Loss at step 213: 0.0009051424567587674\n",
      "Loss at step 214: 0.0007191022741608322\n",
      "Loss at step 215: 0.0007634502835571766\n",
      "Loss at step 216: 0.0009168676915578544\n",
      "Loss at step 217: 0.0008880855166353285\n",
      "Loss at step 218: 0.0006469896761700511\n",
      "Loss at step 219: 0.0008244748460128903\n",
      "Loss at step 220: 0.0007958321366459131\n",
      "Loss at step 221: 0.0009720949456095695\n",
      "Loss at step 222: 0.0009375016088597476\n",
      "Loss at step 223: 0.000681207689922303\n",
      "Loss at step 224: 0.0009473150712437928\n",
      "Loss at step 225: 0.0008468750165775418\n",
      "Loss at step 226: 0.0008696274016983807\n",
      "Loss at step 227: 0.001014966401271522\n",
      "Loss at step 228: 0.0006126491352915764\n",
      "Loss at step 229: 0.0007639043615199625\n",
      "Loss at step 230: 0.0007704193703830242\n",
      "Loss at step 231: 0.0006032088422216475\n",
      "Loss at step 232: 0.0008173754904419184\n",
      "Loss at step 233: 0.0008658783626742661\n",
      "Loss at step 234: 0.0007312275702133775\n",
      "Loss at step 235: 0.0009209830895997584\n",
      "Loss at step 236: 0.0007866952801123261\n",
      "Loss at step 237: 0.0008105644956231117\n",
      "Loss at step 238: 0.0009527297224849463\n",
      "Loss at step 239: 0.0008446190040558577\n",
      "Loss at step 240: 0.0007308474741876125\n",
      "Loss at step 241: 0.000984033104032278\n",
      "Loss at step 242: 0.0007685721502639353\n",
      "Loss at step 243: 0.0009443673770874739\n",
      "Loss at step 244: 0.0006542806513607502\n",
      "Loss at step 245: 0.0007687468314543366\n",
      "Loss at step 246: 0.0008409436559304595\n",
      "Loss at step 247: 0.0008760254131630063\n",
      "Loss at step 248: 0.0007954783504828811\n",
      "Loss at step 249: 0.0008993917144834995\n",
      "Loss at step 250: 0.0008614889811724424\n",
      "Loss at step 251: 0.0010572696337476373\n",
      "Loss at step 252: 0.0006950108800083399\n",
      "Loss at step 253: 0.0007889986736699939\n",
      "Loss at step 254: 0.0007090972503647208\n",
      "Loss at step 255: 0.0007789877126924694\n",
      "Loss at step 256: 0.0007504733512178063\n",
      "Loss at step 257: 0.0007818724843673408\n",
      "Loss at step 258: 0.0009441887377761304\n",
      "Loss at step 259: 0.0009257383644580841\n",
      "Loss at step 260: 0.0008293947321362793\n",
      "Loss at step 261: 0.0006309269228950143\n",
      "Loss at step 262: 0.000880603794939816\n",
      "Loss at step 263: 0.0007901103235781193\n",
      "Loss at step 264: 0.0007998206419870257\n",
      "Loss at step 265: 0.0009444205788895488\n",
      "Loss at step 266: 0.0009386324672959745\n",
      "Loss at step 267: 0.0008749898406676948\n",
      "Loss at step 268: 0.000782246992457658\n",
      "Loss at step 269: 0.000938187527935952\n",
      "Loss at step 270: 0.0009343057754449546\n",
      "Loss at step 271: 0.0009193317964673042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 272: 0.0008659547893330455\n",
      "Loss at step 273: 0.0008411562885157764\n",
      "Loss at step 274: 0.0009849019115790725\n",
      "Loss at step 275: 0.0008245801436714828\n",
      "Loss at step 276: 0.0006139407050795853\n",
      "Loss at step 277: 0.0007935593603178859\n",
      "Loss at step 278: 0.0008665737695991993\n",
      "Loss at step 279: 0.0009206270333379507\n",
      "Loss at step 280: 0.0007131770253181458\n",
      "Loss at step 281: 0.000782126619014889\n",
      "Loss at step 282: 0.0008941031410358846\n",
      "Loss at step 283: 0.0009227083064615726\n",
      "Loss at step 284: 0.0010319616412743926\n",
      "Loss at step 285: 0.0008097503450699151\n",
      "Loss at step 286: 0.0008998129051178694\n",
      "Loss at step 287: 0.0009018452255986631\n",
      "Loss at step 288: 0.0010040545603260398\n",
      "Loss at step 289: 0.000762114068493247\n",
      "Loss at step 290: 0.0008280788897536695\n",
      "Loss at step 291: 0.0008050010656006634\n",
      "Loss at step 292: 0.0009316036012023687\n",
      "Loss at step 293: 0.0008117937832139432\n",
      "Loss at step 294: 0.0008853658800944686\n",
      "Loss at step 295: 0.0009795778896659613\n",
      "Loss at step 296: 0.000890935945790261\n",
      "Loss at step 297: 0.000782958697527647\n",
      "Loss at step 298: 0.0010041543282568455\n",
      "Loss at step 299: 0.0007584761478938162\n",
      "Loss at step 300: 0.0006625138339586556\n",
      "Loss at step 301: 0.000640664657112211\n",
      "Loss at step 302: 0.0007196034421212971\n",
      "Loss at step 303: 0.0009522219770587981\n",
      "Loss at step 304: 0.0007261590217240155\n",
      "Loss at step 305: 0.0009584217332303524\n",
      "Loss at step 306: 0.0009081235621124506\n",
      "Loss at step 307: 0.0007997385109774768\n",
      "Loss at step 308: 0.0007538591744378209\n",
      "Loss at step 309: 0.0008879355737008154\n",
      "Loss at step 310: 0.0008038828382268548\n",
      "Loss at step 311: 0.0009231935255229473\n",
      "Loss at step 312: 0.0008423522231169045\n",
      "Loss at step 313: 0.0008517897804267704\n",
      "Loss at step 314: 0.0008458723896183074\n",
      "Loss at step 315: 0.0006784999859519303\n",
      "Loss at step 316: 0.0007831426337361336\n",
      "Loss at step 317: 0.0008159718126989901\n",
      "Loss at step 318: 0.0007626452716067433\n",
      "Loss at step 319: 0.0009968626545742154\n",
      "Loss at step 320: 0.0008315795566886663\n",
      "Loss at step 321: 0.0007358958246186376\n",
      "Loss at step 322: 0.0008725449442863464\n",
      "Loss at step 323: 0.0006893042591400445\n",
      "Loss at step 324: 0.0007752254605293274\n",
      "Loss at step 325: 0.0007175713544711471\n",
      "Loss at step 326: 0.000798192631918937\n",
      "Loss at step 327: 0.0010137843200936913\n",
      "Loss at step 328: 0.0008515890222042799\n",
      "Loss at step 329: 0.0007615014328621328\n",
      "Loss at step 330: 0.000807633507065475\n",
      "Loss at step 331: 0.001011866144835949\n",
      "Loss at step 332: 0.0010023307986557484\n",
      "Loss at step 333: 0.0008267753291875124\n",
      "Loss at step 334: 0.0008048768504522741\n",
      "Loss at step 335: 0.0009395646629855037\n",
      "Loss at step 336: 0.0008081524283625185\n",
      "Loss at step 337: 0.0009563624626025558\n",
      "Loss at step 338: 0.0009123829076997936\n",
      "Loss at step 339: 0.0008309216354973614\n",
      "Loss at step 340: 0.0009963359916582704\n",
      "Loss at step 341: 0.0007219388498924673\n",
      "Loss at step 342: 0.0008721489575691521\n",
      "Loss at step 343: 0.0006831874488852918\n",
      "Loss at step 344: 0.0008545800228603184\n",
      "Loss at step 345: 0.0006291614263318479\n",
      "Loss at step 346: 0.0006804289878346026\n",
      "Loss at step 347: 0.0008026580908335745\n",
      "Loss at step 348: 0.000967072497587651\n",
      "Loss at step 349: 0.0007501548388972878\n",
      "Loss at step 350: 0.000900755578186363\n",
      "Loss at step 351: 0.0008820561924949288\n",
      "Loss at step 352: 0.0006210491410456598\n",
      "Loss at step 353: 0.0008644805056974292\n",
      "Loss at step 354: 0.0008743808139115572\n",
      "Loss at step 355: 0.000871421245392412\n",
      "Loss at step 356: 0.0008639786392450333\n",
      "Loss at step 357: 0.000834814680274576\n",
      "Loss at step 358: 0.0008391014416702092\n",
      "Loss at step 359: 0.001031485735438764\n",
      "Loss at step 360: 0.000942217477131635\n",
      "Loss at step 361: 0.0009555298020131886\n",
      "Loss at step 362: 0.0007198870880529284\n",
      "Loss at step 363: 0.0008577930275350809\n",
      "Loss at step 364: 0.0008013395126909018\n",
      "Loss at step 365: 0.0006679844227619469\n",
      "Loss at step 366: 0.0008133119554258883\n",
      "Loss at step 367: 0.000857537379488349\n",
      "Loss at step 368: 0.0008604620234109461\n",
      "Loss at step 369: 0.0009752613259479403\n",
      "Loss at step 370: 0.0008066654554568231\n",
      "Loss at step 371: 0.0009144149371422827\n",
      "Loss at step 372: 0.0009188766125589609\n",
      "Loss at step 373: 0.0007239262340590358\n",
      "Loss at step 374: 0.0007918913033790886\n",
      "Loss at step 375: 0.0009612187859602273\n",
      "Loss at step 376: 0.0008344976813532412\n",
      "Loss at step 377: 0.0009528300724923611\n",
      "Loss at step 378: 0.0007738569984212518\n",
      "Loss at step 379: 0.0008018570370040834\n",
      "Loss at step 380: 0.0008284296491183341\n",
      "Loss at step 381: 0.0007604107959195971\n",
      "Loss at step 382: 0.0007316155242733657\n",
      "Loss at step 383: 0.000626536610070616\n",
      "Loss at step 384: 0.0006859007989987731\n",
      "Loss at step 385: 0.0008706257794983685\n",
      "Loss at step 386: 0.0007819741149432957\n",
      "Loss at step 387: 0.0009444263996556401\n",
      "Loss at step 388: 0.0009608349646441638\n",
      "Loss at step 389: 0.0009237314225174487\n",
      "Loss at step 390: 0.0008376352488994598\n",
      "Loss at step 391: 0.0007116156630218029\n",
      "Loss at step 392: 0.0008043400011956692\n",
      "Loss at step 393: 0.0007668024045415223\n",
      "Loss at step 394: 0.0007988839060999453\n",
      "Loss at step 395: 0.0009250000584870577\n",
      "Loss at step 396: 0.0009039043798111379\n",
      "Loss at step 397: 0.0010438408935442567\n",
      "Loss at step 398: 0.0008932604105211794\n",
      "Loss at step 399: 0.00069078104570508\n",
      "Loss at step 400: 0.000724686193279922\n",
      "Loss at step 401: 0.0007849588873796165\n",
      "Loss at step 402: 0.0008834312320686877\n",
      "Loss at step 403: 0.0006580316694453359\n",
      "Loss at step 404: 0.0007197950035333633\n",
      "Loss at step 405: 0.0009293394978158176\n",
      "Loss at step 406: 0.0007373164407908916\n",
      "Loss at step 407: 0.0007766575436107814\n",
      "Loss at step 408: 0.0008845058619044721\n",
      "Loss at step 409: 0.0008514183573424816\n",
      "Loss at step 410: 0.000985616003163159\n",
      "Loss at step 411: 0.0009335638605989516\n",
      "Loss at step 412: 0.0008281063055619597\n",
      "Loss at step 413: 0.000968994339928031\n",
      "Loss at step 414: 0.0006909907679073513\n",
      "Loss at step 415: 0.0007114658365026116\n",
      "Loss at step 416: 0.0008013738552108407\n",
      "Loss at step 417: 0.0008059722604230046\n",
      "Loss at step 418: 0.0008160690777003765\n",
      "Loss at step 419: 0.0007721412112005055\n",
      "Loss at step 420: 0.0008521624840795994\n",
      "Loss at step 421: 0.0008237036527134478\n",
      "Loss at step 422: 0.0008381109801121056\n",
      "Loss at step 423: 0.0008114150841720402\n",
      "Loss at step 424: 0.0009522684849798679\n",
      "Loss at step 425: 0.0009543192572891712\n",
      "Loss at step 426: 0.0009059406584128737\n",
      "Loss at step 427: 0.0007456663297489285\n",
      "Loss at step 428: 0.0006607768591493368\n",
      "Loss at step 429: 0.0009538427693769336\n",
      "Loss at step 430: 0.0009707740391604602\n",
      "Loss at step 431: 0.0007984753465279937\n",
      "Loss at step 432: 0.0008656363934278488\n",
      "Loss at step 433: 0.0008244141936302185\n",
      "Loss at step 434: 0.00085296860197559\n",
      "Loss at step 435: 0.001052871928550303\n",
      "Loss at step 436: 0.0007601168472319841\n",
      "Loss at step 437: 0.0008499807445332408\n",
      "Loss at step 438: 0.0009723221883177757\n",
      "Loss at step 439: 0.00078678346471861\n",
      "Loss at step 440: 0.0006417877157218754\n",
      "Loss at step 441: 0.0008488630410283804\n",
      "Loss at step 442: 0.0009267933783121407\n",
      "Loss at step 443: 0.0007629347965121269\n",
      "Loss at step 444: 0.0006712350295856595\n",
      "Loss at step 445: 0.0006862666341476142\n",
      "Loss at step 446: 0.0007709768833592534\n",
      "Loss at step 447: 0.0007088952115736902\n",
      "Loss at step 448: 0.0008573547238484025\n",
      "Loss at step 449: 0.0007160526583902538\n",
      "Loss at step 450: 0.000840159656945616\n",
      "Loss at step 451: 0.0010582082904875278\n",
      "Loss at step 452: 0.0009365606820210814\n",
      "Loss at step 453: 0.0007923340890556574\n",
      "Loss at step 454: 0.000808407086879015\n",
      "Loss at step 455: 0.0008263283525593579\n",
      "Loss at step 456: 0.0009462075540795922\n",
      "Loss at step 457: 0.0008250374812632799\n",
      "Loss at step 458: 0.0007993373437784612\n",
      "Loss at step 459: 0.0009517997386865318\n",
      "Loss at step 460: 0.0009363109711557627\n",
      "Loss at step 461: 0.0007117515197023749\n",
      "Loss at step 462: 0.000831114943139255\n",
      "Loss at step 463: 0.0008428362780250609\n",
      "Loss at step 464: 0.0009893226670101285\n",
      "Loss at step 465: 0.0008615799597464502\n",
      "Loss at step 466: 0.0008829566068015993\n",
      "Loss at step 467: 0.0006338600069284439\n",
      "Loss at step 468: 0.0010549286380410194\n",
      "Loss at step 469: 0.0007457196479663253\n",
      "Loss at step 470: 0.0009581460617482662\n",
      "Loss at step 471: 0.0007378755253739655\n",
      "Loss at step 472: 0.000780995876993984\n",
      "Loss at step 473: 0.0009657144546508789\n",
      "Loss at step 474: 0.0007517417543567717\n",
      "Loss at step 475: 0.0009326431318186224\n",
      "Loss at step 476: 0.0009255394688807428\n",
      "Loss at step 477: 0.0008437762735411525\n",
      "Loss at step 478: 0.000804908515419811\n",
      "Loss at step 479: 0.0008664357010275126\n",
      "Loss at step 480: 0.0007897026371210814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 481: 0.0010508785489946604\n",
      "Loss at step 482: 0.0008929637842811644\n",
      "Loss at step 483: 0.0008434965857304633\n",
      "Loss at step 484: 0.0007749113137833774\n",
      "Loss at step 485: 0.0007929836283437908\n",
      "Loss at step 486: 0.0008287795935757458\n",
      "Loss at step 487: 0.0009774790378287435\n",
      "Loss at step 488: 0.0007695452077314258\n",
      "Loss at step 489: 0.0008792083244770765\n",
      "Loss at step 490: 0.0009711579768918455\n",
      "Loss at step 491: 0.0007638080860488117\n",
      "Loss at step 492: 0.0008672691183164716\n",
      "Loss at step 493: 0.0007186569855548441\n",
      "Loss at step 494: 0.0008722144993953407\n",
      "Loss at step 495: 0.0006497744470834732\n",
      "Loss at step 496: 0.0007109895232133567\n",
      "Loss at step 497: 0.0009609452681615949\n",
      "Loss at step 498: 0.0008752535213716328\n",
      "Loss at step 499: 0.00106519996188581\n",
      "Loss at step 500: 0.0007038844050839543\n",
      "Loss at step 501: 0.0008975357632152736\n",
      "Loss at step 502: 0.0009088703664019704\n",
      "Loss at step 503: 0.0010512202279642224\n",
      "Loss at step 504: 0.0009960569441318512\n",
      "Loss at step 505: 0.0009228193084709346\n",
      "Loss at step 506: 0.0008575876709073782\n",
      "Loss at step 507: 0.0010251732310280204\n",
      "Loss at step 508: 0.0007424284121952951\n",
      "Loss at step 509: 0.0007766340277157724\n",
      "Loss at step 510: 0.0007123198010958731\n",
      "Loss at step 511: 0.0009297107462771237\n",
      "Loss at step 512: 0.0007881646743044257\n",
      "Loss at step 513: 0.0009343104902654886\n",
      "Loss at step 514: 0.0007312078378163278\n",
      "Loss at step 515: 0.0008105324232019484\n",
      "Loss at step 516: 0.0010327287018299103\n",
      "Loss at step 517: 0.0008500237017869949\n",
      "Loss at step 518: 0.0007135422201827168\n",
      "Loss at step 519: 0.0007397662848234177\n",
      "Loss at step 520: 0.000694560119882226\n",
      "Loss at step 521: 0.0009937114082276821\n",
      "Loss at step 522: 0.0007659774855710566\n",
      "Loss at step 523: 0.0006889242213219404\n",
      "Loss at step 524: 0.000704255304299295\n",
      "Loss at step 525: 0.0008674837299622595\n",
      "Loss at step 526: 0.0009620721102692187\n",
      "Loss at step 527: 0.0009146087104454637\n",
      "Loss at step 528: 0.0009266370325349271\n",
      "Loss at step 529: 0.0010441243648529053\n",
      "Loss at step 530: 0.00082359928637743\n",
      "Loss at step 531: 0.0008580419817008078\n",
      "Loss at step 532: 0.0009206102113239467\n",
      "Loss at step 533: 0.0008919600513763726\n",
      "Loss at step 534: 0.000901141669601202\n",
      "Loss at step 535: 0.0008413284667767584\n",
      "Loss at step 536: 0.0009335618233308196\n",
      "Loss at step 537: 0.0008756696479395032\n",
      "Loss at step 538: 0.0011091271881014109\n",
      "Loss at step 539: 0.0008136419346556067\n",
      "Loss at step 540: 0.0008943977300077677\n",
      "Loss at step 541: 0.0008191469823941588\n",
      "Loss at step 542: 0.0010161767713725567\n",
      "Loss at step 543: 0.0006369546172209084\n",
      "Loss at step 544: 0.0007883890648372471\n",
      "Loss at step 545: 0.0008645142079330981\n",
      "Loss at step 546: 0.0008422880782745779\n",
      "Loss at step 547: 0.0010518255876377225\n",
      "Loss at step 548: 0.0009113273117691278\n",
      "Loss at step 549: 0.0007549236761406064\n",
      "Loss at step 550: 0.0006881004082970321\n",
      "Loss at step 551: 0.0007791334646753967\n",
      "Loss at step 552: 0.0009357389062643051\n",
      "Loss at step 553: 0.0007380597526207566\n",
      "Loss at step 554: 0.0006614039884880185\n",
      "Loss at step 555: 0.0008927236776798964\n",
      "Loss at step 556: 0.0008817539201118052\n",
      "Loss at step 557: 0.000888054259121418\n",
      "Loss at step 558: 0.0008180108270607889\n",
      "Loss at step 559: 0.0007681333227083087\n",
      "Loss at step 560: 0.0006190870190039277\n",
      "Loss at step 561: 0.0007904567173682153\n",
      "Loss at step 562: 0.0009009322384372354\n",
      "Loss at step 563: 0.000782824179623276\n",
      "Loss at step 564: 0.0009120715549215674\n",
      "Loss at step 565: 0.0007753802929073572\n",
      "Loss at step 566: 0.0009853556985035539\n",
      "Loss at step 567: 0.0008488570456393063\n",
      "Loss at step 568: 0.0009081693715415895\n",
      "Loss at step 569: 0.0006960986647754908\n",
      "Loss at step 570: 0.0009710454032756388\n",
      "Loss at step 571: 0.0007803490152582526\n",
      "Loss at step 572: 0.0008356042089872062\n",
      "Loss at step 573: 0.0008376767509616911\n",
      "Loss at step 574: 0.0009949406376108527\n",
      "Loss at step 575: 0.0009360183612443507\n",
      "Loss at step 576: 0.0007335451664403081\n",
      "Loss at step 577: 0.000965386105235666\n",
      "Loss at step 578: 0.0008174043032340705\n",
      "Loss at step 579: 0.0008322198991663754\n",
      "Loss at step 580: 0.0006775285000912845\n",
      "Loss at step 581: 0.0007945799152366817\n",
      "Loss at step 582: 0.0009345270227640867\n",
      "Loss at step 583: 0.0007515536854043603\n",
      "Loss at step 584: 0.0009872019290924072\n",
      "Loss at step 585: 0.0009500196320004761\n",
      "Loss at step 586: 0.0009061017772182822\n",
      "Loss at step 587: 0.0010535063920542598\n",
      "Loss at step 588: 0.0009152466082014143\n",
      "Loss at step 589: 0.0008371085277758539\n",
      "Loss at step 590: 0.0007012829883024096\n",
      "Loss at step 591: 0.0007392353727482259\n",
      "Loss at step 592: 0.0007996155181899667\n",
      "Loss at step 593: 0.0009300707024522126\n",
      "Loss at step 594: 0.0007648649043403566\n",
      "Loss at step 595: 0.0008369004353880882\n",
      "Loss at step 596: 0.000840738823171705\n",
      "Loss at step 597: 0.0007489016279578209\n",
      "Loss at step 598: 0.0009097314323298633\n",
      "Loss at step 599: 0.0007272317889146507\n",
      "Loss at step 600: 0.000876741309184581\n",
      "Loss at step 601: 0.0007837635930627584\n",
      "Loss at step 602: 0.000852964527439326\n",
      "Loss at step 603: 0.000900937826372683\n",
      "Loss at step 604: 0.0006930864765308797\n",
      "Loss at step 605: 0.0008155858959071338\n",
      "Loss at step 606: 0.0007940435316413641\n",
      "Loss at step 607: 0.0007854479481466115\n",
      "Loss at step 608: 0.0009931561071425676\n",
      "Loss at step 609: 0.0006478333380073309\n",
      "Loss at step 610: 0.000893167220056057\n",
      "Loss at step 611: 0.0007765732007101178\n",
      "Loss at step 612: 0.0008208999643102288\n",
      "Loss at step 613: 0.0008932321215979755\n",
      "Loss at step 614: 0.0007544648833572865\n",
      "Loss at step 615: 0.0008405756088905036\n",
      "Loss at step 616: 0.0009009403875097632\n",
      "Loss at step 617: 0.0009031443623825908\n",
      "Loss at step 618: 0.0006900568259879947\n",
      "Loss at step 619: 0.0007047744584269822\n",
      "Loss at step 620: 0.0006149251712486148\n",
      "Loss at step 621: 0.0010417313314974308\n",
      "Loss at step 622: 0.0007207386661320925\n",
      "Loss at step 623: 0.0008792901644483209\n",
      "Loss at step 624: 0.0007400575559586287\n",
      "Loss at step 625: 0.0009237808990292251\n",
      "Loss at step 626: 0.0008494672365486622\n",
      "Loss at step 627: 0.0007481312495656312\n",
      "Loss at step 628: 0.0007750525837764144\n",
      "Loss at step 629: 0.0008041913388296962\n",
      "Loss at step 630: 0.0009493380784988403\n",
      "Loss at step 631: 0.0008085652953013778\n",
      "Loss at step 632: 0.0009678764618001878\n",
      "Loss at step 633: 0.0006922539323568344\n",
      "Loss at step 634: 0.0008856065687723458\n",
      "Loss at step 635: 0.0009568576933816075\n",
      "Loss at step 636: 0.0007894193404354155\n",
      "Loss at step 637: 0.0008457489893771708\n",
      "Loss at step 638: 0.0010090022115036845\n",
      "Loss at step 639: 0.0007752176024951041\n",
      "Loss at step 640: 0.000814520928543061\n",
      "Loss at step 641: 0.0008535240776836872\n",
      "Loss at step 642: 0.0006370910559780896\n",
      "Loss at step 643: 0.0009688787977211177\n",
      "Loss at step 644: 0.0008393102907575667\n",
      "Loss at step 645: 0.0010916156461462379\n",
      "Loss at step 646: 0.0009518871083855629\n",
      "Loss at step 647: 0.0006363384309224784\n",
      "Loss at step 648: 0.0007284182938747108\n",
      "Loss at step 649: 0.0008411110029555857\n",
      "Loss at step 650: 0.0008466533035971224\n",
      "Loss at step 651: 0.0005741036729887128\n",
      "Loss at step 652: 0.0007260245620273054\n",
      "Loss at step 653: 0.0008725515217520297\n",
      "Loss at step 654: 0.0009157282183878124\n",
      "Loss at step 655: 0.0009235464385710657\n",
      "Loss at step 656: 0.0008083992870524526\n",
      "Loss at step 657: 0.0009167915559373796\n",
      "Loss at step 658: 0.0008316574385389686\n",
      "Loss at step 659: 0.0008502971031703055\n",
      "Loss at step 660: 0.0008998935809358954\n",
      "Loss at step 661: 0.0009189324919134378\n",
      "Loss at step 662: 0.0008755421731621027\n",
      "Loss at step 663: 0.0011013587936758995\n",
      "Loss at step 664: 0.0009845959721133113\n",
      "Loss at step 665: 0.000931893999222666\n",
      "Loss at step 666: 0.0008131549111567438\n",
      "Loss at step 667: 0.0009174387669190764\n",
      "Loss at step 668: 0.0008907632436603308\n",
      "Loss at step 669: 0.0009127467055805027\n",
      "Loss at step 670: 0.0009013995877467096\n",
      "Loss at step 671: 0.0008248264784924686\n",
      "Loss at step 672: 0.000969864777289331\n",
      "Loss at step 673: 0.0008930579060688615\n",
      "Loss at step 674: 0.0006483204779215157\n",
      "Loss at step 675: 0.0009648979757912457\n",
      "Loss at step 676: 0.0008602371672168374\n",
      "Loss at step 677: 0.0007966147386468947\n",
      "Loss at step 678: 0.0006261300295591354\n",
      "Loss at step 679: 0.0011351181892678142\n",
      "Loss at step 680: 0.0007081229123286903\n",
      "Loss at step 681: 0.0010328321950510144\n",
      "Loss at step 682: 0.0005695602158084512\n",
      "Loss at step 683: 0.0009104147320613265\n",
      "Loss at step 684: 0.0005726218223571777\n",
      "Loss at step 685: 0.0009523971821181476\n",
      "Loss at step 686: 0.0008310697739943862\n",
      "Loss at step 687: 0.0010590199381113052\n",
      "Loss at step 688: 0.0006922567263245583\n",
      "Loss at step 689: 0.0007486182148568332\n",
      "Loss at step 690: 0.0008416444179601967\n",
      "Loss at step 691: 0.0008135379757732153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 692: 0.0009638287592679262\n",
      "Loss at step 693: 0.0009419296402484179\n",
      "Loss at step 694: 0.0006890085060149431\n",
      "Loss at step 695: 0.0010374026605859399\n",
      "Loss at step 696: 0.0006946788053028286\n",
      "Loss at step 697: 0.000900440791156143\n",
      "Loss at step 698: 0.0007307425839826465\n",
      "Loss at step 699: 0.0008690905524417758\n",
      "Loss at step 700: 0.0008220492745749652\n",
      "Loss at step 701: 0.0008725498919375241\n",
      "Loss at step 702: 0.0008304599905386567\n",
      "Loss at step 703: 0.000994484988041222\n",
      "Loss at step 704: 0.0008102089632302523\n",
      "Loss at step 705: 0.0006811025086790323\n",
      "train Loss: 0.0008\n",
      "Loss at step 0: 0.0007045461679808795\n",
      "Loss at step 1: 0.0008897963562048972\n",
      "Loss at step 2: 0.0008929851464927197\n",
      "Loss at step 3: 0.0009637395269237459\n",
      "Loss at step 4: 0.0009554153657518327\n",
      "Loss at step 5: 0.0009389833430759609\n",
      "Loss at step 6: 0.0009045333135873079\n",
      "Loss at step 7: 0.0008274244610220194\n",
      "Loss at step 8: 0.0009585098596289754\n",
      "Loss at step 9: 0.0010022555943578482\n",
      "Loss at step 10: 0.0007327984203584492\n",
      "Loss at step 11: 0.0008795177564024925\n",
      "Loss at step 12: 0.0007730360957793891\n",
      "Loss at step 13: 0.000859128194861114\n",
      "Loss at step 14: 0.0007613689522258937\n",
      "Loss at step 15: 0.0009373519569635391\n",
      "Loss at step 16: 0.0008084939327090979\n",
      "Loss at step 17: 0.0008612059173174202\n",
      "Loss at step 18: 0.0010038239415735006\n",
      "Loss at step 19: 0.0008144730818457901\n",
      "Loss at step 20: 0.0007840093458071351\n",
      "Loss at step 21: 0.0009050336666405201\n",
      "Loss at step 22: 0.0008917636587284505\n",
      "Loss at step 23: 0.0008341330103576183\n",
      "Loss at step 24: 0.0007882876670919359\n",
      "Loss at step 25: 0.000747094745747745\n",
      "Loss at step 26: 0.0008271153783425689\n",
      "Loss at step 27: 0.0008694486459717155\n",
      "Loss at step 28: 0.0008618860156275332\n",
      "Loss at step 29: 0.0008080759434960783\n",
      "Loss at step 30: 0.0008234065608121455\n",
      "Loss at step 31: 0.0009588840184733272\n",
      "Loss at step 32: 0.0009297174983657897\n",
      "Loss at step 33: 0.0009583551436662674\n",
      "Loss at step 34: 0.0008539694244973361\n",
      "Loss at step 35: 0.000974969647359103\n",
      "Loss at step 36: 0.0008520696428604424\n",
      "Loss at step 37: 0.0009218825143761933\n",
      "Loss at step 38: 0.0008091967320069671\n",
      "Loss at step 39: 0.000735742156393826\n",
      "Loss at step 40: 0.0007007387466728687\n",
      "Loss at step 41: 0.0009669506689533591\n",
      "Loss at step 42: 0.0008877214859239757\n",
      "Loss at step 43: 0.0005702010821551085\n",
      "Loss at step 44: 0.0007506822585128248\n",
      "Loss at step 45: 0.0010698767146095634\n",
      "Loss at step 46: 0.0008903048583306372\n",
      "Loss at step 47: 0.0008670943207107484\n",
      "Loss at step 48: 0.0010769182117655873\n",
      "Loss at step 49: 0.0008188124629668891\n",
      "Loss at step 50: 0.0008421822567470372\n",
      "Loss at step 51: 0.0009791089687496424\n",
      "Loss at step 52: 0.0009859713027253747\n",
      "Loss at step 53: 0.0009758276864886284\n",
      "Loss at step 54: 0.0009969177190214396\n",
      "Loss at step 55: 0.0009297275682911277\n",
      "Loss at step 56: 0.0008431996102444828\n",
      "Loss at step 57: 0.0009636246250011027\n",
      "Loss at step 58: 0.0010666921734809875\n",
      "Loss at step 59: 0.000687314837705344\n",
      "Loss at step 60: 0.0007951149600557983\n",
      "Loss at step 61: 0.0006442426238209009\n",
      "Loss at step 62: 0.0007719634450040758\n",
      "Loss at step 63: 0.0009510513627901673\n",
      "Loss at step 64: 0.0008745951927267015\n",
      "Loss at step 65: 0.0009981670882552862\n",
      "Loss at step 66: 0.0007715956307947636\n",
      "Loss at step 67: 0.0007905939128249884\n",
      "Loss at step 68: 0.0008894344209693372\n",
      "Loss at step 69: 0.0006908320356160402\n",
      "Loss at step 70: 0.0007395072025246918\n",
      "Loss at step 71: 0.00099098717328161\n",
      "Loss at step 72: 0.0008211085805669427\n",
      "Loss at step 73: 0.0007013580179773271\n",
      "Loss at step 74: 0.0009224521345458925\n",
      "Loss at step 75: 0.0009917154675349593\n",
      "Loss at step 76: 0.0007320704753510654\n",
      "Loss at step 77: 0.0008068261086009443\n",
      "Loss at step 78: 0.000933223171159625\n",
      "Loss at step 79: 0.000947602791711688\n",
      "Loss at step 80: 0.000781672541052103\n",
      "Loss at step 81: 0.0008865563431754708\n",
      "Loss at step 82: 0.0010019444162026048\n",
      "Loss at step 83: 0.0008268368546850979\n",
      "Loss at step 84: 0.0006476707058027387\n",
      "Loss at step 85: 0.0007753422833047807\n",
      "Loss at step 86: 0.0009287063730880618\n",
      "Loss at step 87: 0.0009403423755429685\n",
      "Loss at step 88: 0.0008283419301733375\n",
      "Loss at step 89: 0.0009292809409089386\n",
      "Loss at step 90: 0.0008450006134808064\n",
      "Loss at step 91: 0.0008652051328681409\n",
      "Loss at step 92: 0.0008181615266948938\n",
      "Loss at step 93: 0.00097904063295573\n",
      "Loss at step 94: 0.0008131996146403253\n",
      "Loss at step 95: 0.0010173554765060544\n",
      "Loss at step 96: 0.0009139145840890706\n",
      "Loss at step 97: 0.0009249953436665237\n",
      "Loss at step 98: 0.0008913498022593558\n",
      "Loss at step 99: 0.0009877129923552275\n",
      "Loss at step 100: 0.000941579753998667\n",
      "Loss at step 101: 0.0008659781888127327\n",
      "Loss at step 102: 0.0008586527546867728\n",
      "Loss at step 103: 0.0007181641412898898\n",
      "Loss at step 104: 0.000767426798120141\n",
      "Loss at step 105: 0.0010141357779502869\n",
      "Loss at step 106: 0.0008550383499823511\n",
      "Loss at step 107: 0.0007575523923151195\n",
      "Loss at step 108: 0.0008941827691160142\n",
      "Loss at step 109: 0.0008727256790734828\n",
      "Loss at step 110: 0.0009400966810062528\n",
      "Loss at step 111: 0.0006748359301127493\n",
      "Loss at step 112: 0.0008526498568244278\n",
      "Loss at step 113: 0.0011393799213692546\n",
      "Loss at step 114: 0.0008114753291010857\n",
      "Loss at step 115: 0.0008617278072051704\n",
      "Loss at step 116: 0.0009649814455769956\n",
      "Loss at step 117: 0.0007904917583800852\n",
      "Loss at step 118: 0.0007037085015326738\n",
      "Loss at step 119: 0.0008620255975984037\n",
      "Loss at step 120: 0.0008322103531099856\n",
      "Loss at step 121: 0.0007756389095447958\n",
      "Loss at step 122: 0.0008006348507478833\n",
      "Loss at step 123: 0.0008743545622564852\n",
      "Loss at step 124: 0.0009203991503454745\n",
      "Loss at step 125: 0.0008637034916318953\n",
      "Loss at step 126: 0.000920904683880508\n",
      "Loss at step 127: 0.000642493658233434\n",
      "Loss at step 128: 0.000903078995179385\n",
      "Loss at step 129: 0.0010200823890045285\n",
      "Loss at step 130: 0.0008002459653653204\n",
      "Loss at step 131: 0.0007999333902262151\n",
      "Loss at step 132: 0.0007509658462367952\n",
      "Loss at step 133: 0.0010087453993037343\n",
      "Loss at step 134: 0.0010020924964919686\n",
      "Loss at step 135: 0.0009887394262477756\n",
      "Loss at step 136: 0.0007970429142005742\n",
      "Loss at step 137: 0.0009311835747212172\n",
      "Loss at step 138: 0.0008778251358307898\n",
      "Loss at step 139: 0.0009531119139865041\n",
      "Loss at step 140: 0.001078220084309578\n",
      "Loss at step 141: 0.0008820550865493715\n",
      "Loss at step 142: 0.0010040688794106245\n",
      "Loss at step 143: 0.0008673781412653625\n",
      "Loss at step 144: 0.0006575190927833319\n",
      "Loss at step 145: 0.0008918484672904015\n",
      "Loss at step 146: 0.0008928896277211607\n",
      "Loss at step 147: 0.0010206660954281688\n",
      "Loss at step 148: 0.0006780383992008865\n",
      "Loss at step 149: 0.0008612059173174202\n",
      "Loss at step 150: 0.0007601645775139332\n",
      "Loss at step 151: 0.0008813251042738557\n",
      "Loss at step 152: 0.0010109655559062958\n",
      "Loss at step 153: 0.0009650636347942054\n",
      "Loss at step 154: 0.0007878097239881754\n",
      "Loss at step 155: 0.000836480176076293\n",
      "Loss at step 156: 0.0009160940535366535\n",
      "Loss at step 157: 0.0007854403811506927\n",
      "Loss at step 158: 0.0007576436619274318\n",
      "Loss at step 159: 0.0007359192823059857\n",
      "Loss at step 160: 0.0009741347166709602\n",
      "Loss at step 161: 0.0009120212635025382\n",
      "Loss at step 162: 0.0007375932764261961\n",
      "Loss at step 163: 0.0006996183656156063\n",
      "Loss at step 164: 0.0007527499692514539\n",
      "Loss at step 165: 0.0009555196738801897\n",
      "Loss at step 166: 0.0008556514512747526\n",
      "Loss at step 167: 0.0008652221877127886\n",
      "Loss at step 168: 0.0009553121635690331\n",
      "Loss at step 169: 0.0006797913229092956\n",
      "Loss at step 170: 0.0007271564099937677\n",
      "Loss at step 171: 0.0008090318297035992\n",
      "Loss at step 172: 0.0008860686793923378\n",
      "Loss at step 173: 0.0009184628142975271\n",
      "Loss at step 174: 0.0007277667173184454\n",
      "Loss at step 175: 0.0009148860699497163\n",
      "Loss at step 176: 0.0005720608751289546\n",
      "val Loss: 0.0009\n",
      "Epoch 4/4\n",
      "----------\n",
      "Loss at step 0: 0.0007998464861884713\n",
      "Loss at step 1: 0.0008247564546763897\n",
      "Loss at step 2: 0.0006909528747200966\n",
      "Loss at step 3: 0.0008926065638661385\n",
      "Loss at step 4: 0.0010339157888665795\n",
      "Loss at step 5: 0.0008158569107763469\n",
      "Loss at step 6: 0.0008336324826814234\n",
      "Loss at step 7: 0.0008719300967641175\n",
      "Loss at step 8: 0.0008945294539444149\n",
      "Loss at step 9: 0.0008411031449213624\n",
      "Loss at step 10: 0.0007995451451279223\n",
      "Loss at step 11: 0.0008316775783896446\n",
      "Loss at step 12: 0.0008594632381573319\n",
      "Loss at step 13: 0.0008849246078170836\n",
      "Loss at step 14: 0.0008074490469880402\n",
      "Loss at step 15: 0.0009714481420814991\n",
      "Loss at step 16: 0.0007931186119094491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 17: 0.0008085930603556335\n",
      "Loss at step 18: 0.0010451297275722027\n",
      "Loss at step 19: 0.0008708557579666376\n",
      "Loss at step 20: 0.0008767418912611902\n",
      "Loss at step 21: 0.001030615996569395\n",
      "Loss at step 22: 0.0007678338442929089\n",
      "Loss at step 23: 0.0007189470925368369\n",
      "Loss at step 24: 0.0007432409911416471\n",
      "Loss at step 25: 0.0006979033933021128\n",
      "Loss at step 26: 0.0009974983986467123\n",
      "Loss at step 27: 0.0008808584534563124\n",
      "Loss at step 28: 0.0008950447663664818\n",
      "Loss at step 29: 0.0007783350301906466\n",
      "Loss at step 30: 0.0008162316516973078\n",
      "Loss at step 31: 0.0008674880373291671\n",
      "Loss at step 32: 0.0007569965091533959\n",
      "Loss at step 33: 0.0011290009133517742\n",
      "Loss at step 34: 0.0006671232404187322\n",
      "Loss at step 35: 0.000774689600802958\n",
      "Loss at step 36: 0.0008127739420160651\n",
      "Loss at step 37: 0.0007938535418361425\n",
      "Loss at step 38: 0.000955748837441206\n",
      "Loss at step 39: 0.001036731293424964\n",
      "Loss at step 40: 0.0007990528829395771\n",
      "Loss at step 41: 0.0008540741982869804\n",
      "Loss at step 42: 0.0008767389808781445\n",
      "Loss at step 43: 0.0008555116364732385\n",
      "Loss at step 44: 0.0008894575876183808\n",
      "Loss at step 45: 0.0008982580038718879\n",
      "Loss at step 46: 0.0008960459963418543\n",
      "Loss at step 47: 0.0006423291633836925\n",
      "Loss at step 48: 0.0007093718159012496\n",
      "Loss at step 49: 0.001137221115641296\n",
      "Loss at step 50: 0.0008936887606978416\n",
      "Loss at step 51: 0.0009597708121873438\n",
      "Loss at step 52: 0.0007695658132433891\n",
      "Loss at step 53: 0.0009021476143971086\n",
      "Loss at step 54: 0.0007908171392045915\n",
      "Loss at step 55: 0.0008550994098186493\n",
      "Loss at step 56: 0.0006733321351930499\n",
      "Loss at step 57: 0.0010224083671346307\n",
      "Loss at step 58: 0.0008177891140803695\n",
      "Loss at step 59: 0.0007448861724697053\n",
      "Loss at step 60: 0.0010388504015281796\n",
      "Loss at step 61: 0.0008402409730479121\n",
      "Loss at step 62: 0.0006314306519925594\n",
      "Loss at step 63: 0.0008501709089614451\n",
      "Loss at step 64: 0.0007429739343933761\n",
      "Loss at step 65: 0.000868510571308434\n",
      "Loss at step 66: 0.0008333393489010632\n",
      "Loss at step 67: 0.0009207521216012537\n",
      "Loss at step 68: 0.0009089124505408108\n",
      "Loss at step 69: 0.0006230479921214283\n",
      "Loss at step 70: 0.0010830031242221594\n",
      "Loss at step 71: 0.0008302896749228239\n",
      "Loss at step 72: 0.0007554647163487971\n",
      "Loss at step 73: 0.0007668544421903789\n",
      "Loss at step 74: 0.0008326059905812144\n",
      "Loss at step 75: 0.0010153776966035366\n",
      "Loss at step 76: 0.0006416673422791064\n",
      "Loss at step 77: 0.0007179703679867089\n",
      "Loss at step 78: 0.0008573158411309123\n",
      "Loss at step 79: 0.0007784051122143865\n",
      "Loss at step 80: 0.000887831614818424\n",
      "Loss at step 81: 0.0007070404826663435\n",
      "Loss at step 82: 0.0010061317589133978\n",
      "Loss at step 83: 0.0008451545145362616\n",
      "Loss at step 84: 0.0008906027651391923\n",
      "Loss at step 85: 0.0007608024752698839\n",
      "Loss at step 86: 0.0008303049253299832\n",
      "Loss at step 87: 0.0009146376978605986\n",
      "Loss at step 88: 0.0008007250726222992\n",
      "Loss at step 89: 0.0007058143382892013\n",
      "Loss at step 90: 0.0009632747969590127\n",
      "Loss at step 91: 0.0008098999969661236\n",
      "Loss at step 92: 0.0008934628567658365\n",
      "Loss at step 93: 0.0008179081487469375\n",
      "Loss at step 94: 0.0008982600411400199\n",
      "Loss at step 95: 0.0008934274083003402\n",
      "Loss at step 96: 0.0008368245325982571\n",
      "Loss at step 97: 0.0008515482186339796\n",
      "Loss at step 98: 0.000888753856997937\n",
      "Loss at step 99: 0.0009327900479547679\n",
      "Loss at step 100: 0.0008634802652522922\n",
      "Loss at step 101: 0.0008570424979552627\n",
      "Loss at step 102: 0.0007414252613671124\n",
      "Loss at step 103: 0.0008554595406167209\n",
      "Loss at step 104: 0.0008355439640581608\n",
      "Loss at step 105: 0.0008740996709093451\n",
      "Loss at step 106: 0.0009244955726899207\n",
      "Loss at step 107: 0.0007966110133565962\n",
      "Loss at step 108: 0.0007895449525676668\n",
      "Loss at step 109: 0.0007180187967605889\n",
      "Loss at step 110: 0.0007869941764511168\n",
      "Loss at step 111: 0.0009859212441369891\n",
      "Loss at step 112: 0.0007181582623161376\n",
      "Loss at step 113: 0.0008491110056638718\n",
      "Loss at step 114: 0.0010348823852837086\n",
      "Loss at step 115: 0.0007592900656163692\n",
      "Loss at step 116: 0.0009373040520586073\n",
      "Loss at step 117: 0.000960100325755775\n",
      "Loss at step 118: 0.0007609297172166407\n",
      "Loss at step 119: 0.00063785829115659\n",
      "Loss at step 120: 0.0007215315708890557\n",
      "Loss at step 121: 0.0009341015247628093\n",
      "Loss at step 122: 0.0008945182198658586\n",
      "Loss at step 123: 0.0008829306461848319\n",
      "Loss at step 124: 0.0008258734596893191\n",
      "Loss at step 125: 0.0008383072563447058\n",
      "Loss at step 126: 0.0007369706872850657\n",
      "Loss at step 127: 0.0005935693043284118\n",
      "Loss at step 128: 0.000872560718562454\n",
      "Loss at step 129: 0.0008437152719125152\n",
      "Loss at step 130: 0.0008974155061878264\n",
      "Loss at step 131: 0.0006663796375505626\n",
      "Loss at step 132: 0.0008681131293997169\n",
      "Loss at step 133: 0.000994834234006703\n",
      "Loss at step 134: 0.0009251329465769231\n",
      "Loss at step 135: 0.0008805767865851521\n",
      "Loss at step 136: 0.0007709116325713694\n",
      "Loss at step 137: 0.0008325944072566926\n",
      "Loss at step 138: 0.0007140406523831189\n",
      "Loss at step 139: 0.0008557498222216964\n",
      "Loss at step 140: 0.0008112089126370847\n",
      "Loss at step 141: 0.0008958650287240744\n",
      "Loss at step 142: 0.0008995421812869608\n",
      "Loss at step 143: 0.0010220683179795742\n",
      "Loss at step 144: 0.0008647127542644739\n",
      "Loss at step 145: 0.0009589947876520455\n",
      "Loss at step 146: 0.0009366061422042549\n",
      "Loss at step 147: 0.0009694723994471133\n",
      "Loss at step 148: 0.0007778125000186265\n",
      "Loss at step 149: 0.0009702554671093822\n",
      "Loss at step 150: 0.0008292156271636486\n",
      "Loss at step 151: 0.0009366729063913226\n",
      "Loss at step 152: 0.0009576269658282399\n",
      "Loss at step 153: 0.0008393742609769106\n",
      "Loss at step 154: 0.0008040163666009903\n",
      "Loss at step 155: 0.0008040446555241942\n",
      "Loss at step 156: 0.0008806563564576209\n",
      "Loss at step 157: 0.0009271822054870427\n",
      "Loss at step 158: 0.0009390250779688358\n",
      "Loss at step 159: 0.0008310925331898034\n",
      "Loss at step 160: 0.001000418676994741\n",
      "Loss at step 161: 0.0008533064974471927\n",
      "Loss at step 162: 0.0008618903812021017\n",
      "Loss at step 163: 0.000963182479608804\n",
      "Loss at step 164: 0.000946194224525243\n",
      "Loss at step 165: 0.0008553728694096208\n",
      "Loss at step 166: 0.0009736113133840263\n",
      "Loss at step 167: 0.0007801323663443327\n",
      "Loss at step 168: 0.0008235413115471601\n",
      "Loss at step 169: 0.0008105565211735666\n",
      "Loss at step 170: 0.0006470706430263817\n",
      "Loss at step 171: 0.0009644689271226525\n",
      "Loss at step 172: 0.0008972625946626067\n",
      "Loss at step 173: 0.00093730358639732\n",
      "Loss at step 174: 0.0007410908583551645\n",
      "Loss at step 175: 0.000776145257987082\n",
      "Loss at step 176: 0.000778425601311028\n",
      "Loss at step 177: 0.0007787992944940925\n",
      "Loss at step 178: 0.0007130294106900692\n",
      "Loss at step 179: 0.0008652613032609224\n",
      "Loss at step 180: 0.0007760186563245952\n",
      "Loss at step 181: 0.0008575786487199366\n",
      "Loss at step 182: 0.0009205217938870192\n",
      "Loss at step 183: 0.000940212223213166\n",
      "Loss at step 184: 0.0007686205208301544\n",
      "Loss at step 185: 0.0007970621809363365\n",
      "Loss at step 186: 0.0008893391932360828\n",
      "Loss at step 187: 0.0007892991998232901\n",
      "Loss at step 188: 0.0009324421989731491\n",
      "Loss at step 189: 0.0006733930786140263\n",
      "Loss at step 190: 0.0009721527458168566\n",
      "Loss at step 191: 0.0007211491465568542\n",
      "Loss at step 192: 0.0008349609561264515\n",
      "Loss at step 193: 0.0008135116077028215\n",
      "Loss at step 194: 0.0007254088413901627\n",
      "Loss at step 195: 0.0007365829078480601\n",
      "Loss at step 196: 0.0009386884630657732\n",
      "Loss at step 197: 0.000716022215783596\n",
      "Loss at step 198: 0.0008498666575178504\n",
      "Loss at step 199: 0.0008257771260105073\n",
      "Loss at step 200: 0.000712814275175333\n",
      "Loss at step 201: 0.0007270052446983755\n",
      "Loss at step 202: 0.0007939565111882985\n",
      "Loss at step 203: 0.0007283823797479272\n",
      "Loss at step 204: 0.0009272865718230605\n",
      "Loss at step 205: 0.0008507700404152274\n",
      "Loss at step 206: 0.0007752020610496402\n",
      "Loss at step 207: 0.0008079264662228525\n",
      "Loss at step 208: 0.0006938626756891608\n",
      "Loss at step 209: 0.0008565795724280179\n",
      "Loss at step 210: 0.0009260234073735774\n",
      "Loss at step 211: 0.000963573984336108\n",
      "Loss at step 212: 0.0008510707993991673\n",
      "Loss at step 213: 0.000916787947062403\n",
      "Loss at step 214: 0.0005958722904324532\n",
      "Loss at step 215: 0.0008415430784225464\n",
      "Loss at step 216: 0.0007777803111821413\n",
      "Loss at step 217: 0.0009474543039686978\n",
      "Loss at step 218: 0.0008862257818691432\n",
      "Loss at step 219: 0.0007191550685092807\n",
      "Loss at step 220: 0.0009080584277398884\n",
      "Loss at step 221: 0.0008999427082017064\n",
      "Loss at step 222: 0.0009205079986713827\n",
      "Loss at step 223: 0.0007237818790599704\n",
      "Loss at step 224: 0.000720774638466537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 225: 0.0007559619261883199\n",
      "Loss at step 226: 0.00087808130774647\n",
      "Loss at step 227: 0.0007125984993763268\n",
      "Loss at step 228: 0.0007763624889776111\n",
      "Loss at step 229: 0.0007778374128974974\n",
      "Loss at step 230: 0.0009038211428560317\n",
      "Loss at step 231: 0.0008663420449011028\n",
      "Loss at step 232: 0.0008484857971780002\n",
      "Loss at step 233: 0.0009828782640397549\n",
      "Loss at step 234: 0.0009684569085948169\n",
      "Loss at step 235: 0.0009125355863943696\n",
      "Loss at step 236: 0.0008499044342897832\n",
      "Loss at step 237: 0.0008264556527137756\n",
      "Loss at step 238: 0.0006410669884644449\n",
      "Loss at step 239: 0.000967289786785841\n",
      "Loss at step 240: 0.0008103570435196161\n",
      "Loss at step 241: 0.0007527060806751251\n",
      "Loss at step 242: 0.0007149520679377019\n",
      "Loss at step 243: 0.0009818270336836576\n",
      "Loss at step 244: 0.000884432636667043\n",
      "Loss at step 245: 0.000662980426568538\n",
      "Loss at step 246: 0.0010307440534234047\n",
      "Loss at step 247: 0.000808798591606319\n",
      "Loss at step 248: 0.0008162417216226459\n",
      "Loss at step 249: 0.001019678427837789\n",
      "Loss at step 250: 0.000958934600930661\n",
      "Loss at step 251: 0.0008596212137490511\n",
      "Loss at step 252: 0.0007957048946991563\n",
      "Loss at step 253: 0.0008791229338385165\n",
      "Loss at step 254: 0.001082693925127387\n",
      "Loss at step 255: 0.0009038513526320457\n",
      "Loss at step 256: 0.0009424882009625435\n",
      "Loss at step 257: 0.0009440145804546773\n",
      "Loss at step 258: 0.0009103059419430792\n",
      "Loss at step 259: 0.0008496427908539772\n",
      "Loss at step 260: 0.001005477039143443\n",
      "Loss at step 261: 0.0007426931406371295\n",
      "Loss at step 262: 0.0007093758904375136\n",
      "Loss at step 263: 0.0006882985471747816\n",
      "Loss at step 264: 0.0009319717646576464\n",
      "Loss at step 265: 0.0006448898348025978\n",
      "Loss at step 266: 0.0008054504287429154\n",
      "Loss at step 267: 0.0007033036090433598\n",
      "Loss at step 268: 0.000829752127174288\n",
      "Loss at step 269: 0.0007072575972415507\n",
      "Loss at step 270: 0.000821923662442714\n",
      "Loss at step 271: 0.0006871128571219742\n",
      "Loss at step 272: 0.0007468003313988447\n",
      "Loss at step 273: 0.0007561743259429932\n",
      "Loss at step 274: 0.000902443309314549\n",
      "Loss at step 275: 0.0009427472250536084\n",
      "Loss at step 276: 0.0007448704564012587\n",
      "Loss at step 277: 0.0007634687353856862\n",
      "Loss at step 278: 0.0007993029430508614\n",
      "Loss at step 279: 0.0007899184129200876\n",
      "Loss at step 280: 0.0009314582566730678\n",
      "Loss at step 281: 0.0010177063522860408\n",
      "Loss at step 282: 0.0008250258397310972\n",
      "Loss at step 283: 0.0008871876634657383\n",
      "Loss at step 284: 0.0009272275492548943\n",
      "Loss at step 285: 0.0007799648446962237\n",
      "Loss at step 286: 0.0009296725038439035\n",
      "Loss at step 287: 0.0009148741373792291\n",
      "Loss at step 288: 0.0007713842205703259\n",
      "Loss at step 289: 0.0008395799086429179\n",
      "Loss at step 290: 0.0007713788654655218\n",
      "Loss at step 291: 0.0008584093302488327\n",
      "Loss at step 292: 0.0007360301096923649\n",
      "Loss at step 293: 0.0006384369917213917\n",
      "Loss at step 294: 0.00089036556892097\n",
      "Loss at step 295: 0.0008158865384757519\n",
      "Loss at step 296: 0.0006623708759434521\n",
      "Loss at step 297: 0.0008990865899249911\n",
      "Loss at step 298: 0.0009101686882786453\n",
      "Loss at step 299: 0.0008735397714190185\n",
      "Loss at step 300: 0.0007505284156650305\n",
      "Loss at step 301: 0.0007832541596144438\n",
      "Loss at step 302: 0.000690546294208616\n",
      "Loss at step 303: 0.0008500259136781096\n",
      "Loss at step 304: 0.0010601349640637636\n",
      "Loss at step 305: 0.0010253926739096642\n",
      "Loss at step 306: 0.0010907826945185661\n",
      "Loss at step 307: 0.0008160310680978\n",
      "Loss at step 308: 0.0007006843807175756\n",
      "Loss at step 309: 0.000847004703246057\n",
      "Loss at step 310: 0.0007491590804420412\n",
      "Loss at step 311: 0.0009207887924276292\n",
      "Loss at step 312: 0.0007687287288717926\n",
      "Loss at step 313: 0.0009161469643004239\n",
      "Loss at step 314: 0.0007836894947104156\n",
      "Loss at step 315: 0.0008772619185037911\n",
      "Loss at step 316: 0.0007684844895265996\n",
      "Loss at step 317: 0.0006747810984961689\n",
      "Loss at step 318: 0.0007801263709552586\n",
      "Loss at step 319: 0.0008361524087376893\n",
      "Loss at step 320: 0.0008096256642602384\n",
      "Loss at step 321: 0.000811191217508167\n",
      "Loss at step 322: 0.0008607638301327825\n",
      "Loss at step 323: 0.0008259561727754772\n",
      "Loss at step 324: 0.0006859811837784946\n",
      "Loss at step 325: 0.0009350287145934999\n",
      "Loss at step 326: 0.0008028929005376995\n",
      "Loss at step 327: 0.0007698394474573433\n",
      "Loss at step 328: 0.00092120940098539\n",
      "Loss at step 329: 0.0006367526366375387\n",
      "Loss at step 330: 0.0008004456176422536\n",
      "Loss at step 331: 0.0007734839455224574\n",
      "Loss at step 332: 0.0008647294016554952\n",
      "Loss at step 333: 0.0008592702797614038\n",
      "Loss at step 334: 0.0005832068854942918\n",
      "Loss at step 335: 0.0007469027186743915\n",
      "Loss at step 336: 0.0008630265365354717\n",
      "Loss at step 337: 0.0010497835464775562\n",
      "Loss at step 338: 0.0008669826784171164\n",
      "Loss at step 339: 0.0007718502311035991\n",
      "Loss at step 340: 0.0007723437738604844\n",
      "Loss at step 341: 0.0009126437362283468\n",
      "Loss at step 342: 0.0009431032813154161\n",
      "Loss at step 343: 0.0006326473085209727\n",
      "Loss at step 344: 0.0009278238285332918\n",
      "Loss at step 345: 0.0009079933515749872\n",
      "Loss at step 346: 0.0008659522864036262\n",
      "Loss at step 347: 0.0007899312186054885\n",
      "Loss at step 348: 0.0006868682103231549\n",
      "Loss at step 349: 0.0009385075536556542\n",
      "Loss at step 350: 0.0008591911173425615\n",
      "Loss at step 351: 0.0006629842100664973\n",
      "Loss at step 352: 0.0006567159434780478\n",
      "Loss at step 353: 0.0009438476990908384\n",
      "Loss at step 354: 0.0008811829029582441\n",
      "Loss at step 355: 0.0007535287877544761\n",
      "Loss at step 356: 0.0009791729971766472\n",
      "Loss at step 357: 0.0008065004949457943\n",
      "Loss at step 358: 0.0008001519599929452\n",
      "Loss at step 359: 0.0008292213315144181\n",
      "Loss at step 360: 0.0007986902492120862\n",
      "Loss at step 361: 0.0006665650871582329\n",
      "Loss at step 362: 0.0008247077348642051\n",
      "Loss at step 363: 0.0009225211688317358\n",
      "Loss at step 364: 0.000729095540009439\n",
      "Loss at step 365: 0.0007414922001771629\n",
      "Loss at step 366: 0.0008031707257032394\n",
      "Loss at step 367: 0.0008786738617345691\n",
      "Loss at step 368: 0.0009602783829905093\n",
      "Loss at step 369: 0.0008313853177241981\n",
      "Loss at step 370: 0.0009682817617431283\n",
      "Loss at step 371: 0.0008525784942321479\n",
      "Loss at step 372: 0.0007830914109945297\n",
      "Loss at step 373: 0.0006933282711543143\n",
      "Loss at step 374: 0.0009797468082979321\n",
      "Loss at step 375: 0.0006927776848897338\n",
      "Loss at step 376: 0.0008236204739660025\n",
      "Loss at step 377: 0.0006963470950722694\n",
      "Loss at step 378: 0.0007067727856338024\n",
      "Loss at step 379: 0.0008616006816737354\n",
      "Loss at step 380: 0.0008831648156046867\n",
      "Loss at step 381: 0.0008838091744109988\n",
      "Loss at step 382: 0.000877779966685921\n",
      "Loss at step 383: 0.0006869097705930471\n",
      "Loss at step 384: 0.0008584513561800122\n",
      "Loss at step 385: 0.0007764692418277264\n",
      "Loss at step 386: 0.0008472887566313148\n",
      "Loss at step 387: 0.0008798736380413175\n",
      "Loss at step 388: 0.0007425130461342633\n",
      "Loss at step 389: 0.0008052108460105956\n",
      "Loss at step 390: 0.0007633045897819102\n",
      "Loss at step 391: 0.000844446592964232\n",
      "Loss at step 392: 0.0006357960519380867\n",
      "Loss at step 393: 0.0008258040179498494\n",
      "Loss at step 394: 0.0008659603190608323\n",
      "Loss at step 395: 0.0009750149329192936\n",
      "Loss at step 396: 0.0007769615040160716\n",
      "Loss at step 397: 0.0009086732752621174\n",
      "Loss at step 398: 0.0008289128891192377\n",
      "Loss at step 399: 0.0007001507910899818\n",
      "Loss at step 400: 0.0009233112214133143\n",
      "Loss at step 401: 0.0008921431726776063\n",
      "Loss at step 402: 0.0007859889883548021\n",
      "Loss at step 403: 0.0007691278588026762\n",
      "Loss at step 404: 0.0008753077709116042\n",
      "Loss at step 405: 0.0007297220290638506\n",
      "Loss at step 406: 0.0009220386273227632\n",
      "Loss at step 407: 0.0009566116495989263\n",
      "Loss at step 408: 0.0010010453406721354\n",
      "Loss at step 409: 0.00075242092134431\n",
      "Loss at step 410: 0.0007317840936593711\n",
      "Loss at step 411: 0.0008686312939971685\n",
      "Loss at step 412: 0.0007699634879827499\n",
      "Loss at step 413: 0.0008488742168992758\n",
      "Loss at step 414: 0.00102424796205014\n",
      "Loss at step 415: 0.0008131336653605103\n",
      "Loss at step 416: 0.0006409419002011418\n",
      "Loss at step 417: 0.0008198384894058108\n",
      "Loss at step 418: 0.0007961688097566366\n",
      "Loss at step 419: 0.0006075647543184459\n",
      "Loss at step 420: 0.0006908517680130899\n",
      "Loss at step 421: 0.0009702006354928017\n",
      "Loss at step 422: 0.0008782248478382826\n",
      "Loss at step 423: 0.0008950725896283984\n",
      "Loss at step 424: 0.0007204473949968815\n",
      "Loss at step 425: 0.0006834412924945354\n",
      "Loss at step 426: 0.0007976799970492721\n",
      "Loss at step 427: 0.0008612340316176414\n",
      "Loss at step 428: 0.000862844055518508\n",
      "Loss at step 429: 0.0008641031454317272\n",
      "Loss at step 430: 0.0008668077643960714\n",
      "Loss at step 431: 0.001018128707073629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 432: 0.0007109616999514401\n",
      "Loss at step 433: 0.0006268032011575997\n",
      "Loss at step 434: 0.0009301560930907726\n",
      "Loss at step 435: 0.0008668942609801888\n",
      "Loss at step 436: 0.0009850884089246392\n",
      "Loss at step 437: 0.0006963921478018165\n",
      "Loss at step 438: 0.0009024817263707519\n",
      "Loss at step 439: 0.000817348132841289\n",
      "Loss at step 440: 0.0008271168917417526\n",
      "Loss at step 441: 0.0009429787751287222\n",
      "Loss at step 442: 0.0008226028876379132\n",
      "Loss at step 443: 0.0008936596568673849\n",
      "Loss at step 444: 0.0008934721699915826\n",
      "Loss at step 445: 0.0009751236066222191\n",
      "Loss at step 446: 0.0008710070978850126\n",
      "Loss at step 447: 0.0007520917570218444\n",
      "Loss at step 448: 0.0008390046423301101\n",
      "Loss at step 449: 0.0009344402351416647\n",
      "Loss at step 450: 0.0007324186735786498\n",
      "Loss at step 451: 0.000946224492508918\n",
      "Loss at step 452: 0.0009323434787802398\n",
      "Loss at step 453: 0.0005153972888365388\n",
      "Loss at step 454: 0.0006963409250602126\n",
      "Loss at step 455: 0.0008516728994436562\n",
      "Loss at step 456: 0.0008437384385615587\n",
      "Loss at step 457: 0.0009106575162149966\n",
      "Loss at step 458: 0.000760435767006129\n",
      "Loss at step 459: 0.0009763446287252009\n",
      "Loss at step 460: 0.0009889907669276\n",
      "Loss at step 461: 0.0009605818777345121\n",
      "Loss at step 462: 0.0009681940427981317\n",
      "Loss at step 463: 0.0008381993975490332\n",
      "Loss at step 464: 0.0009152075508609414\n",
      "Loss at step 465: 0.0008983316947706044\n",
      "Loss at step 466: 0.0007482575019821525\n",
      "Loss at step 467: 0.0009285742416977882\n",
      "Loss at step 468: 0.0007512808660976589\n",
      "Loss at step 469: 0.0009184462251141667\n",
      "Loss at step 470: 0.0009414421510882676\n",
      "Loss at step 471: 0.0008069701725617051\n",
      "Loss at step 472: 0.000894062512088567\n",
      "Loss at step 473: 0.0008423758554272354\n",
      "Loss at step 474: 0.0007139826193451881\n",
      "Loss at step 475: 0.000698936521075666\n",
      "Loss at step 476: 0.0006880320142954588\n",
      "Loss at step 477: 0.0008718176395632327\n",
      "Loss at step 478: 0.0008323680958710611\n",
      "Loss at step 479: 0.0006356420344673097\n",
      "Loss at step 480: 0.000866273941937834\n",
      "Loss at step 481: 0.0008023159462027252\n",
      "Loss at step 482: 0.0008659691084176302\n",
      "Loss at step 483: 0.0008229081868194044\n",
      "Loss at step 484: 0.0008620385779067874\n",
      "Loss at step 485: 0.0007004979997873306\n",
      "Loss at step 486: 0.0010416371515020728\n",
      "Loss at step 487: 0.0009589721448719501\n",
      "Loss at step 488: 0.0008510635234415531\n",
      "Loss at step 489: 0.0008346381364390254\n",
      "Loss at step 490: 0.0009347270824946463\n",
      "Loss at step 491: 0.0007768718060106039\n",
      "Loss at step 492: 0.000895213452167809\n",
      "Loss at step 493: 0.0008319783955812454\n",
      "Loss at step 494: 0.0008916564984247088\n",
      "Loss at step 495: 0.0008689656388014555\n",
      "Loss at step 496: 0.000872586970217526\n",
      "Loss at step 497: 0.0008005344425328076\n",
      "Loss at step 498: 0.0008142393198795617\n",
      "Loss at step 499: 0.000877222279086709\n",
      "Loss at step 500: 0.0007000789046287537\n",
      "Loss at step 501: 0.0009182043722830713\n",
      "Loss at step 502: 0.0007782959146425128\n",
      "Loss at step 503: 0.0008903962443582714\n",
      "Loss at step 504: 0.0006449510692618787\n",
      "Loss at step 505: 0.0008669522940181196\n",
      "Loss at step 506: 0.0008584633469581604\n",
      "Loss at step 507: 0.001045872108079493\n",
      "Loss at step 508: 0.0007804418564774096\n",
      "Loss at step 509: 0.0007768382201902568\n",
      "Loss at step 510: 0.0007321097073145211\n",
      "Loss at step 511: 0.0009060841402970254\n",
      "Loss at step 512: 0.0007961699739098549\n",
      "Loss at step 513: 0.001026473823003471\n",
      "Loss at step 514: 0.0008883783011697233\n",
      "Loss at step 515: 0.0009975925786420703\n",
      "Loss at step 516: 0.0008062879787757993\n",
      "Loss at step 517: 0.0007332226959988475\n",
      "Loss at step 518: 0.0009311839821748435\n",
      "Loss at step 519: 0.000747355748899281\n",
      "Loss at step 520: 0.0007932430016808212\n",
      "Loss at step 521: 0.0009702337556518614\n",
      "Loss at step 522: 0.0008277834276668727\n",
      "Loss at step 523: 0.0008047859300859272\n",
      "Loss at step 524: 0.0009372087079100311\n",
      "Loss at step 525: 0.0006713325856253505\n",
      "Loss at step 526: 0.0007210444891825318\n",
      "Loss at step 527: 0.0008735255687497556\n",
      "Loss at step 528: 0.0008618063875474036\n",
      "Loss at step 529: 0.0008766100509092212\n",
      "Loss at step 530: 0.0006856110412627459\n",
      "Loss at step 531: 0.0007701976574026048\n",
      "Loss at step 532: 0.0007768354844301939\n",
      "Loss at step 533: 0.0008873173501342535\n",
      "Loss at step 534: 0.000853916397318244\n",
      "Loss at step 535: 0.0007948601269163191\n",
      "Loss at step 536: 0.0008540504495613277\n",
      "Loss at step 537: 0.0008300712797790766\n",
      "Loss at step 538: 0.0009358044480904937\n",
      "Loss at step 539: 0.0008230789098888636\n",
      "Loss at step 540: 0.0007928445702418685\n",
      "Loss at step 541: 0.0007306938641704619\n",
      "Loss at step 542: 0.0008084754808805883\n",
      "Loss at step 543: 0.0007842743070796132\n",
      "Loss at step 544: 0.0007365630008280277\n",
      "Loss at step 545: 0.0008022646652534604\n",
      "Loss at step 546: 0.0009080747840926051\n",
      "Loss at step 547: 0.0007530488655902445\n",
      "Loss at step 548: 0.0006720953388139606\n",
      "Loss at step 549: 0.0008101562270894647\n",
      "Loss at step 550: 0.0008972082869149745\n",
      "Loss at step 551: 0.0008472033077850938\n",
      "Loss at step 552: 0.0008005440467968583\n",
      "Loss at step 553: 0.000791282975114882\n",
      "Loss at step 554: 0.0009047314524650574\n",
      "Loss at step 555: 0.0008652677061036229\n",
      "Loss at step 556: 0.0006506625795736909\n",
      "Loss at step 557: 0.0009820545092225075\n",
      "Loss at step 558: 0.0008929342729970813\n",
      "Loss at step 559: 0.000850379467010498\n",
      "Loss at step 560: 0.0007764996262267232\n",
      "Loss at step 561: 0.0007328072097152472\n",
      "Loss at step 562: 0.000811433361377567\n",
      "Loss at step 563: 0.001079423469491303\n",
      "Loss at step 564: 0.0008293899009004235\n",
      "Loss at step 565: 0.0008170041837729514\n",
      "Loss at step 566: 0.0009142726194113493\n",
      "Loss at step 567: 0.0009790855692699552\n",
      "Loss at step 568: 0.0006261072121560574\n",
      "Loss at step 569: 0.0008336427272297442\n",
      "Loss at step 570: 0.000718695402611047\n",
      "Loss at step 571: 0.0009207305265590549\n",
      "Loss at step 572: 0.0007973252795636654\n",
      "Loss at step 573: 0.0007656977977603674\n",
      "Loss at step 574: 0.0008878632797859609\n",
      "Loss at step 575: 0.0007565543055534363\n",
      "Loss at step 576: 0.0008503699791617692\n",
      "Loss at step 577: 0.0007823210908100009\n",
      "Loss at step 578: 0.0008207482751458883\n",
      "Loss at step 579: 0.000899151957128197\n",
      "Loss at step 580: 0.0008370265131816268\n",
      "Loss at step 581: 0.0009408341720700264\n",
      "Loss at step 582: 0.0009594438597559929\n",
      "Loss at step 583: 0.0008092227508313954\n",
      "Loss at step 584: 0.0008335381862707436\n",
      "Loss at step 585: 0.0008239029557444155\n",
      "Loss at step 586: 0.0010134453186765313\n",
      "Loss at step 587: 0.0009097701986320317\n",
      "Loss at step 588: 0.0006299278466030955\n",
      "Loss at step 589: 0.000805832736659795\n",
      "Loss at step 590: 0.0005786990514025092\n",
      "Loss at step 591: 0.0007465329836122692\n",
      "Loss at step 592: 0.0010069427080452442\n",
      "Loss at step 593: 0.0006540983449667692\n",
      "Loss at step 594: 0.0007724540191702545\n",
      "Loss at step 595: 0.0008001158712431788\n",
      "Loss at step 596: 0.0007632176275365055\n",
      "Loss at step 597: 0.0008494950598105788\n",
      "Loss at step 598: 0.0008761014323681593\n",
      "Loss at step 599: 0.0008758108597248793\n",
      "Loss at step 600: 0.0008266642689704895\n",
      "Loss at step 601: 0.0008705821819603443\n",
      "Loss at step 602: 0.0008141511352732778\n",
      "Loss at step 603: 0.0010602654656395316\n",
      "Loss at step 604: 0.000808412441983819\n",
      "Loss at step 605: 0.0009243079111911356\n",
      "Loss at step 606: 0.0008675122517161071\n",
      "Loss at step 607: 0.0008242963231168687\n",
      "Loss at step 608: 0.0008639080333523452\n",
      "Loss at step 609: 0.0009259498328901827\n",
      "Loss at step 610: 0.0008208296494558454\n",
      "Loss at step 611: 0.0010042680660262704\n",
      "Loss at step 612: 0.0006644986569881439\n",
      "Loss at step 613: 0.0008802969823591411\n",
      "Loss at step 614: 0.0008729808614589274\n",
      "Loss at step 615: 0.0008430881425738335\n",
      "Loss at step 616: 0.0006898742285557091\n",
      "Loss at step 617: 0.0008050322066992521\n",
      "Loss at step 618: 0.0009012972586788237\n",
      "Loss at step 619: 0.001193442614749074\n",
      "Loss at step 620: 0.0008903028792701662\n",
      "Loss at step 621: 0.0008991325157694519\n",
      "Loss at step 622: 0.0010154364863410592\n",
      "Loss at step 623: 0.0006766261649318039\n",
      "Loss at step 624: 0.0007800888270139694\n",
      "Loss at step 625: 0.0008512957720085979\n",
      "Loss at step 626: 0.0006802347488701344\n",
      "Loss at step 627: 0.0009835527744144201\n",
      "Loss at step 628: 0.0009516786667518318\n",
      "Loss at step 629: 0.0008631281671114266\n",
      "Loss at step 630: 0.0009264341206289828\n",
      "Loss at step 631: 0.001012312830425799\n",
      "Loss at step 632: 0.0008516039815731347\n",
      "Loss at step 633: 0.0005952317733317614\n",
      "Loss at step 634: 0.0008726966334506869\n",
      "Loss at step 635: 0.0009316568612121046\n",
      "Loss at step 636: 0.0008239659364335239\n",
      "Loss at step 637: 0.0007152198813855648\n",
      "Loss at step 638: 0.0009443996823392808\n",
      "Loss at step 639: 0.0008694770513102412\n",
      "Loss at step 640: 0.0007281745201908052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 641: 0.0009848763002082705\n",
      "Loss at step 642: 0.0008982755825854838\n",
      "Loss at step 643: 0.0008288471726700664\n",
      "Loss at step 644: 0.0008148775086738169\n",
      "Loss at step 645: 0.0008941202540881932\n",
      "Loss at step 646: 0.0007884863298386335\n",
      "Loss at step 647: 0.0007125801057554781\n",
      "Loss at step 648: 0.0008281650952994823\n",
      "Loss at step 649: 0.0008617826970294118\n",
      "Loss at step 650: 0.0009030415676534176\n",
      "Loss at step 651: 0.0008592868689447641\n",
      "Loss at step 652: 0.0008880511741153896\n",
      "Loss at step 653: 0.00072770711267367\n",
      "Loss at step 654: 0.000946479442063719\n",
      "Loss at step 655: 0.0007347139762714505\n",
      "Loss at step 656: 0.000680169032420963\n",
      "Loss at step 657: 0.0008559240377508104\n",
      "Loss at step 658: 0.0008925978327170014\n",
      "Loss at step 659: 0.0008417827193625271\n",
      "Loss at step 660: 0.0006391886272467673\n",
      "Loss at step 661: 0.0008307419484481215\n",
      "Loss at step 662: 0.0008146024774760008\n",
      "Loss at step 663: 0.0009652098524384201\n",
      "Loss at step 664: 0.0008195522241294384\n",
      "Loss at step 665: 0.0010080827632918954\n",
      "Loss at step 666: 0.000760331517085433\n",
      "Loss at step 667: 0.0008874558843672276\n",
      "Loss at step 668: 0.0008673258125782013\n",
      "Loss at step 669: 0.000887894828338176\n",
      "Loss at step 670: 0.0008266278309747577\n",
      "Loss at step 671: 0.000822235073428601\n",
      "Loss at step 672: 0.000765876320656389\n",
      "Loss at step 673: 0.0007929622079245746\n",
      "Loss at step 674: 0.0007723836461082101\n",
      "Loss at step 675: 0.000977212330326438\n",
      "Loss at step 676: 0.0007794885896146297\n",
      "Loss at step 677: 0.0008864530827850103\n",
      "Loss at step 678: 0.000898942758794874\n",
      "Loss at step 679: 0.0007403419585898519\n",
      "Loss at step 680: 0.0006874095997773111\n",
      "Loss at step 681: 0.000807559525128454\n",
      "Loss at step 682: 0.0007599135278724134\n",
      "Loss at step 683: 0.0009229363058693707\n",
      "Loss at step 684: 0.0007868845132179558\n",
      "Loss at step 685: 0.0008272835984826088\n",
      "Loss at step 686: 0.0008982426370494068\n",
      "Loss at step 687: 0.0008228151127696037\n",
      "Loss at step 688: 0.0009513024124316871\n",
      "Loss at step 689: 0.0007099209469743073\n",
      "Loss at step 690: 0.0006794127402827144\n",
      "Loss at step 691: 0.0007589609012939036\n",
      "Loss at step 692: 0.0009463898604735732\n",
      "Loss at step 693: 0.000867782102432102\n",
      "Loss at step 694: 0.0008649539086036384\n",
      "Loss at step 695: 0.0009096243884414434\n",
      "Loss at step 696: 0.0009559086756780744\n",
      "Loss at step 697: 0.0008366659749299288\n",
      "Loss at step 698: 0.0008589901262894273\n",
      "Loss at step 699: 0.0009337186347693205\n",
      "Loss at step 700: 0.0008948533213697374\n",
      "Loss at step 701: 0.0006204245728440583\n",
      "Loss at step 702: 0.0009704225813038647\n",
      "Loss at step 703: 0.0009066559723578393\n",
      "Loss at step 704: 0.0006109342211857438\n",
      "Loss at step 705: 0.0009256681660190225\n",
      "train Loss: 0.0008\n",
      "Loss at step 0: 0.0008491167682223022\n",
      "Loss at step 1: 0.0008141687139868736\n",
      "Loss at step 2: 0.0009043110767379403\n",
      "Loss at step 3: 0.0009126781369559467\n",
      "Loss at step 4: 0.0006489321240223944\n",
      "Loss at step 5: 0.0008807067642919719\n",
      "Loss at step 6: 0.0007730593788437545\n",
      "Loss at step 7: 0.0007112073944881558\n",
      "Loss at step 8: 0.0007387938676401973\n",
      "Loss at step 9: 0.0008466351428069174\n",
      "Loss at step 10: 0.0010701818391680717\n",
      "Loss at step 11: 0.0005342806689441204\n",
      "Loss at step 12: 0.0007649065810255706\n",
      "Loss at step 13: 0.0007289532222785056\n",
      "Loss at step 14: 0.0007259188569150865\n",
      "Loss at step 15: 0.0010290571954101324\n",
      "Loss at step 16: 0.0009846702450886369\n",
      "Loss at step 17: 0.0007000003242865205\n",
      "Loss at step 18: 0.0008717445889487863\n",
      "Loss at step 19: 0.0007166556897573173\n",
      "Loss at step 20: 0.0009984311182051897\n",
      "Loss at step 21: 0.0009032490197569132\n",
      "Loss at step 22: 0.0008941942942328751\n",
      "Loss at step 23: 0.0007749331998638809\n",
      "Loss at step 24: 0.0009936988353729248\n",
      "Loss at step 25: 0.0008367346599698067\n",
      "Loss at step 26: 0.0008122364524751902\n",
      "Loss at step 27: 0.0008684368222020566\n",
      "Loss at step 28: 0.0009423904120922089\n",
      "Loss at step 29: 0.0007959685171954334\n",
      "Loss at step 30: 0.0009760333341546357\n",
      "Loss at step 31: 0.0008548923651687801\n",
      "Loss at step 32: 0.0008686327491886914\n",
      "Loss at step 33: 0.0008825543918646872\n",
      "Loss at step 34: 0.000962737191002816\n",
      "Loss at step 35: 0.0010252695064991713\n",
      "Loss at step 36: 0.0007918477058410645\n",
      "Loss at step 37: 0.0009150370606221259\n",
      "Loss at step 38: 0.000771674676798284\n",
      "Loss at step 39: 0.0009595421142876148\n",
      "Loss at step 40: 0.0009011446381919086\n",
      "Loss at step 41: 0.0008151990477927029\n",
      "Loss at step 42: 0.0007900320342741907\n",
      "Loss at step 43: 0.000928733148612082\n",
      "Loss at step 44: 0.0008537835092283785\n",
      "Loss at step 45: 0.0006974665448069572\n",
      "Loss at step 46: 0.0007085844408720732\n",
      "Loss at step 47: 0.0007085959077812731\n",
      "Loss at step 48: 0.000778311223257333\n",
      "Loss at step 49: 0.0009302149992436171\n",
      "Loss at step 50: 0.0007794722332619131\n",
      "Loss at step 51: 0.0008571709040552378\n",
      "Loss at step 52: 0.0009484349866397679\n",
      "Loss at step 53: 0.0007570557645522058\n",
      "Loss at step 54: 0.0008656339487060905\n",
      "Loss at step 55: 0.0008475893991999328\n",
      "Loss at step 56: 0.00069316296139732\n",
      "Loss at step 57: 0.0007915119640529156\n",
      "Loss at step 58: 0.0007218949031084776\n",
      "Loss at step 59: 0.0008276861626654863\n",
      "Loss at step 60: 0.0008125145686790347\n",
      "Loss at step 61: 0.0009223203524015844\n",
      "Loss at step 62: 0.0008397476631216705\n",
      "Loss at step 63: 0.0007523729582317173\n",
      "Loss at step 64: 0.0008496668888255954\n",
      "Loss at step 65: 0.0009148644749075174\n",
      "Loss at step 66: 0.000839381362311542\n",
      "Loss at step 67: 0.0009274398908019066\n",
      "Loss at step 68: 0.0007493207813240588\n",
      "Loss at step 69: 0.0009465007460676134\n",
      "Loss at step 70: 0.0009763226262293756\n",
      "Loss at step 71: 0.000809889636002481\n",
      "Loss at step 72: 0.000840272638015449\n",
      "Loss at step 73: 0.0008012975449673831\n",
      "Loss at step 74: 0.0010446193628013134\n",
      "Loss at step 75: 0.000947162916418165\n",
      "Loss at step 76: 0.0009394937660545111\n",
      "Loss at step 77: 0.0007148197619244456\n",
      "Loss at step 78: 0.0008803546079434454\n",
      "Loss at step 79: 0.0009130873950198293\n",
      "Loss at step 80: 0.0008340187487192452\n",
      "Loss at step 81: 0.0006185451056808233\n",
      "Loss at step 82: 0.0009560795733705163\n",
      "Loss at step 83: 0.0009536481811664999\n",
      "Loss at step 84: 0.0009884032187983394\n",
      "Loss at step 85: 0.000829764234367758\n",
      "Loss at step 86: 0.000950789893977344\n",
      "Loss at step 87: 0.0008087387541308999\n",
      "Loss at step 88: 0.0007740859291516244\n",
      "Loss at step 89: 0.0008470739703625441\n",
      "Loss at step 90: 0.0007825053762644529\n",
      "Loss at step 91: 0.000974662892986089\n",
      "Loss at step 92: 0.0006711025489494205\n",
      "Loss at step 93: 0.0010254373773932457\n",
      "Loss at step 94: 0.0006831931532360613\n",
      "Loss at step 95: 0.0009054830297827721\n",
      "Loss at step 96: 0.0008144484600052238\n",
      "Loss at step 97: 0.0009213521843776107\n",
      "Loss at step 98: 0.0007623315905220807\n",
      "Loss at step 99: 0.0007737437263131142\n",
      "Loss at step 100: 0.0007419174071401358\n",
      "Loss at step 101: 0.000797508517280221\n",
      "Loss at step 102: 0.0008568867342546582\n",
      "Loss at step 103: 0.0008728415123187006\n",
      "Loss at step 104: 0.0008499947725795209\n",
      "Loss at step 105: 0.0009369401959702373\n",
      "Loss at step 106: 0.000723080534953624\n",
      "Loss at step 107: 0.0009070931118912995\n",
      "Loss at step 108: 0.0009325562277808785\n",
      "Loss at step 109: 0.0009336841758340597\n",
      "Loss at step 110: 0.000867895723786205\n",
      "Loss at step 111: 0.0007897954783402383\n",
      "Loss at step 112: 0.0007171037723310292\n",
      "Loss at step 113: 0.0010407798690721393\n",
      "Loss at step 114: 0.0006989959510974586\n",
      "Loss at step 115: 0.0007548417197540402\n",
      "Loss at step 116: 0.0008540041162632406\n",
      "Loss at step 117: 0.0008328695548698306\n",
      "Loss at step 118: 0.0007888168911449611\n",
      "Loss at step 119: 0.0008962567080743611\n",
      "Loss at step 120: 0.0008262202609330416\n",
      "Loss at step 121: 0.0008248207159340382\n",
      "Loss at step 122: 0.000905700377188623\n",
      "Loss at step 123: 0.0007678989204578102\n",
      "Loss at step 124: 0.0008092778734862804\n",
      "Loss at step 125: 0.001005599508062005\n",
      "Loss at step 126: 0.0008909304742701352\n",
      "Loss at step 127: 0.0008600500877946615\n",
      "Loss at step 128: 0.0008185008773580194\n",
      "Loss at step 129: 0.0008168925414793193\n",
      "Loss at step 130: 0.0006477363640442491\n",
      "Loss at step 131: 0.0008965918095782399\n",
      "Loss at step 132: 0.0007700684363953769\n",
      "Loss at step 133: 0.0006496317218989134\n",
      "Loss at step 134: 0.000671455985866487\n",
      "Loss at step 135: 0.0008477876544930041\n",
      "Loss at step 136: 0.0008187017519958317\n",
      "Loss at step 137: 0.0007632278720848262\n",
      "Loss at step 138: 0.0007396524306386709\n",
      "Loss at step 139: 0.0008447247091680765\n",
      "Loss at step 140: 0.0009502705652266741\n",
      "Loss at step 141: 0.0008297965978272259\n",
      "Loss at step 142: 0.0008816944900900126\n",
      "Loss at step 143: 0.0007381325121968985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 144: 0.0009418336558155715\n",
      "Loss at step 145: 0.001013810047879815\n",
      "Loss at step 146: 0.000831460754852742\n",
      "Loss at step 147: 0.0008177119889296591\n",
      "Loss at step 148: 0.0007962503586895764\n",
      "Loss at step 149: 0.0008107306784950197\n",
      "Loss at step 150: 0.0007209171890281141\n",
      "Loss at step 151: 0.0007516323821619153\n",
      "Loss at step 152: 0.0008621005690656602\n",
      "Loss at step 153: 0.001065160846337676\n",
      "Loss at step 154: 0.000763069954700768\n",
      "Loss at step 155: 0.0008157535339705646\n",
      "Loss at step 156: 0.0008206847705878317\n",
      "Loss at step 157: 0.0007535695331171155\n",
      "Loss at step 158: 0.0008194230031222105\n",
      "Loss at step 159: 0.0008756323368288577\n",
      "Loss at step 160: 0.0007612524786964059\n",
      "Loss at step 161: 0.0009488746291026473\n",
      "Loss at step 162: 0.0007042624056339264\n",
      "Loss at step 163: 0.00091220298781991\n",
      "Loss at step 164: 0.0007423169445246458\n",
      "Loss at step 165: 0.0010736392578110099\n",
      "Loss at step 166: 0.0008508070022799075\n",
      "Loss at step 167: 0.0010491885477676988\n",
      "Loss at step 168: 0.000698864518199116\n",
      "Loss at step 169: 0.0008821492665447295\n",
      "Loss at step 170: 0.000942342565394938\n",
      "Loss at step 171: 0.0007270493661053479\n",
      "Loss at step 172: 0.0008514593355357647\n",
      "Loss at step 173: 0.0008934635552577674\n",
      "Loss at step 174: 0.00081971863983199\n",
      "Loss at step 175: 0.0009418870322406292\n",
      "Loss at step 176: 0.0008495769579894841\n",
      "val Loss: 0.0008\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'since' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-24d2247e8003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msince\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m print('Training complete in {:.0f}m {:.0f}s'.format(\n\u001b[1;32m     55\u001b[0m     time_elapsed // 60, time_elapsed % 60))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'since' is not defined"
     ]
    }
   ],
   "source": [
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = 50000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i, sample in enumerate(dataloaders[phase]):\n",
    "            inputs, labels = sample['x'], sample['y']\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = torch.sqrt(criterion(outputs, labels))\n",
    "#                 if(i % 10000 == 0):\n",
    "                print(\"Loss at step {}: {}\".format(i, loss/batch_size))\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "        print('{} Loss: {:.4f}'.format(\n",
    "            phase, epoch_loss))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "# load best model weights\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_batch(idx):\n",
    "    sample = train_ds[idx]\n",
    "    inputs, labels = sample['x'], sample['y']\n",
    "    inputs.to(device)\n",
    "    labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    loss = torch.sqrt(criterion(outputs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f one_batch one_batch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #zero the gradient buffers\n",
    "# net.zero_grad()\n",
    "\n",
    "    \n",
    "# # create the optimizer\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# BATCH_SIZE = 100\n",
    "# # training loop\n",
    "# for epoch in range(5):\n",
    "#     print(\"Beginning epoch \", epoch)\n",
    "#     order = numpy.random.choice(training_data.shape[0], size=training_data.shape[0], replace=False)\n",
    "#     for i in range(0, len(order) - BATCH_SIZE, BATCH_SIZE):\n",
    "#         miniBatch = training_data.iloc[order[i:i+BATCH_SIZE]]\n",
    "#         miniBatch = miniBatch.to(device)\n",
    "#         optimizer.zero_grad()   # zero the gradient buffers\n",
    "#         loss = torch.sqrt(criterion(net(miniBatch), torch.tensor(miniBatch[output].values, dtype=torch.float32)))\n",
    "#         if(i % 10000 == 0):\n",
    "#             print(\"Loss at step {}: {}\".format(i, loss))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()    # Does the update\n",
    "\n",
    "# #testing loop\n",
    "# output = net(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save output\n",
    "# testing_data.loc[:,\"Prediction\"] = output.detach().tolist()\n",
    "# testing_data.loc[:,[outputId, \"Prediction\"]].to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
